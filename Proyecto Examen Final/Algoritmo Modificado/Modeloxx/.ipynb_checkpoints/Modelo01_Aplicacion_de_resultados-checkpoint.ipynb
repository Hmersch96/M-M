{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93694814",
   "metadata": {},
   "source": [
    "# Modelo #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c1850a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asignatura</th>\n",
       "      <th>Cod.Car.Sec</th>\n",
       "      <th>1P</th>\n",
       "      <th>2P</th>\n",
       "      <th>Taller</th>\n",
       "      <th>Aprobado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Asignatura  Cod.Car.Sec  1P  2P  Taller  Aprobado\n",
       "0           2            0   8  10       2         0\n",
       "1           2            6  15   7       5         0\n",
       "2           2            0  17   3       6         0\n",
       "3           2            1   9  15       4         0\n",
       "4           2            1   7  11       5         0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Librerias necesarias para trabajar con datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Abrimos el modelo procesado en la aplicacion del algoritmo genetico\n",
    "df= pd.read_csv(\"Modelo01.csv\", sep=\",\",index_col=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13dc305b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1992,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1992, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data=df[['Asignatura','Cod.Car.Sec','1P','2P','Taller']]\n",
    "[filas,columnas]=data.shape\n",
    "labels=df[['Aprobado']]\n",
    "\n",
    "#Como labels figura como string, es necesario cambiarlos a valores enteros\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "labels=np.ravel(labels)\n",
    "\n",
    "#Verificamos las dimensiones de data y labels\n",
    "display(np.shape(labels))\n",
    "display(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1cea91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe619959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias necesarias para realizar una red neuronal con keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model, model_selection\n",
    "import seaborn as sns\n",
    "#import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models         import Sequential\n",
    "from keras.layers         import Dense, Dropout, Flatten\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks      import EarlyStopping, Callback\n",
    "from keras.layers         import Conv2D, MaxPooling2D\n",
    "from keras                import backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pickle import dump,load\n",
    "\n",
    "y=load( open('labels.pkl', 'rb'))\n",
    "x_train=load( open('x_train.pkl', 'rb'))\n",
    "x_test=load( open('x_test.pkl', 'rb'))\n",
    "y_train=load( open('y_train.pkl', 'rb'))\n",
    "y_test=load( open('y_test.pkl', 'rb'))\n",
    "\n",
    "yLR_train =load( open('y_trainLR.pkl', 'rb'))\n",
    "yLR_test =load( open('y_testLR.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d3706",
   "metadata": {},
   "source": [
    "Una vez definido los datos, se procede a crear el modelo a entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "746fc4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este modelo se cargo manualmente y esta basado en los resultados obtenidos en el algoritmo genetico\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(columnas,),activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "\n",
    "# Output layer.\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64285eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.7561 - val_loss: 0.5150 - val_accuracy: 0.7469\n",
      "Epoch 2/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.7883 - val_loss: 0.3167 - val_accuracy: 0.8598\n",
      "Epoch 3/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.3360 - accuracy: 0.8466 - val_loss: 0.2878 - val_accuracy: 0.8431\n",
      "Epoch 4/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2907 - accuracy: 0.8646 - val_loss: 0.2976 - val_accuracy: 0.8577\n",
      "Epoch 5/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2982 - accuracy: 0.8574 - val_loss: 0.2915 - val_accuracy: 0.8494\n",
      "Epoch 6/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2727 - accuracy: 0.8726 - val_loss: 0.3095 - val_accuracy: 0.8703\n",
      "Epoch 7/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2748 - accuracy: 0.8717 - val_loss: 0.3137 - val_accuracy: 0.8619\n",
      "Epoch 8/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2713 - accuracy: 0.8717 - val_loss: 0.3165 - val_accuracy: 0.8515\n",
      "Epoch 9/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2663 - accuracy: 0.8816 - val_loss: 0.2723 - val_accuracy: 0.8724\n",
      "Epoch 10/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.8888 - val_loss: 0.2839 - val_accuracy: 0.8556\n",
      "Epoch 11/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2334 - accuracy: 0.8915 - val_loss: 0.2719 - val_accuracy: 0.8703\n",
      "Epoch 12/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2519 - accuracy: 0.8933 - val_loss: 0.2793 - val_accuracy: 0.8682\n",
      "Epoch 13/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.8843 - val_loss: 0.2811 - val_accuracy: 0.8703\n",
      "Epoch 14/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.8861 - val_loss: 0.3236 - val_accuracy: 0.8536\n",
      "Epoch 15/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.8879 - val_loss: 0.2753 - val_accuracy: 0.8703\n",
      "Epoch 16/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.8789 - val_loss: 0.2838 - val_accuracy: 0.8724\n",
      "Epoch 17/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.8906 - val_loss: 0.2801 - val_accuracy: 0.8724\n",
      "Epoch 18/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2370 - accuracy: 0.8897 - val_loss: 0.2782 - val_accuracy: 0.8515\n",
      "Epoch 19/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.8933 - val_loss: 0.2837 - val_accuracy: 0.8556\n",
      "Epoch 20/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.8987 - val_loss: 0.2831 - val_accuracy: 0.8703\n",
      "Epoch 21/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2378 - accuracy: 0.8933 - val_loss: 0.2840 - val_accuracy: 0.8724\n",
      "Epoch 22/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2389 - accuracy: 0.8906 - val_loss: 0.2881 - val_accuracy: 0.8577\n",
      "Epoch 23/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2287 - accuracy: 0.8960 - val_loss: 0.2758 - val_accuracy: 0.8724\n",
      "Epoch 24/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.8978 - val_loss: 0.2811 - val_accuracy: 0.8640\n",
      "Epoch 25/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.8933 - val_loss: 0.3095 - val_accuracy: 0.8682\n",
      "Epoch 26/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2420 - accuracy: 0.8879 - val_loss: 0.2784 - val_accuracy: 0.8640\n",
      "Epoch 27/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.8942 - val_loss: 0.2780 - val_accuracy: 0.8682\n",
      "Epoch 28/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.8933 - val_loss: 0.2835 - val_accuracy: 0.8556\n",
      "Epoch 29/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2221 - accuracy: 0.9022 - val_loss: 0.2891 - val_accuracy: 0.8661\n",
      "Epoch 30/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2352 - accuracy: 0.9022 - val_loss: 0.2942 - val_accuracy: 0.8703\n",
      "Epoch 31/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2273 - accuracy: 0.8942 - val_loss: 0.3105 - val_accuracy: 0.8598\n",
      "Epoch 32/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9004 - val_loss: 0.3133 - val_accuracy: 0.8703\n",
      "Epoch 33/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2200 - accuracy: 0.8996 - val_loss: 0.2831 - val_accuracy: 0.8787\n",
      "Epoch 34/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2232 - accuracy: 0.8960 - val_loss: 0.2882 - val_accuracy: 0.8703\n",
      "Epoch 35/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2400 - accuracy: 0.8942 - val_loss: 0.2787 - val_accuracy: 0.8703\n",
      "Epoch 36/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.8960 - val_loss: 0.2799 - val_accuracy: 0.8703\n",
      "Epoch 37/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2110 - accuracy: 0.9013 - val_loss: 0.2896 - val_accuracy: 0.8640\n",
      "Epoch 38/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2275 - accuracy: 0.8978 - val_loss: 0.2860 - val_accuracy: 0.8640\n",
      "Epoch 39/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2302 - accuracy: 0.8942 - val_loss: 0.2949 - val_accuracy: 0.8619\n",
      "Epoch 40/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.8951 - val_loss: 0.2853 - val_accuracy: 0.8619\n",
      "Epoch 41/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2261 - accuracy: 0.8879 - val_loss: 0.2960 - val_accuracy: 0.8598\n",
      "Epoch 42/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.8969 - val_loss: 0.2848 - val_accuracy: 0.8745\n",
      "Epoch 43/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2188 - accuracy: 0.9013 - val_loss: 0.2853 - val_accuracy: 0.8745\n",
      "Epoch 44/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.8915 - val_loss: 0.2889 - val_accuracy: 0.8703\n",
      "Epoch 45/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2165 - accuracy: 0.9049 - val_loss: 0.2959 - val_accuracy: 0.8703\n",
      "Epoch 46/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.8960 - val_loss: 0.2951 - val_accuracy: 0.8724\n",
      "Epoch 47/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2079 - accuracy: 0.9022 - val_loss: 0.2946 - val_accuracy: 0.8724\n",
      "Epoch 48/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2148 - accuracy: 0.8897 - val_loss: 0.2997 - val_accuracy: 0.8598\n",
      "Epoch 49/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2100 - accuracy: 0.9004 - val_loss: 0.3049 - val_accuracy: 0.8703\n",
      "Epoch 50/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.8996 - val_loss: 0.2943 - val_accuracy: 0.8661\n",
      "Epoch 51/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2082 - accuracy: 0.9076 - val_loss: 0.2934 - val_accuracy: 0.8703\n",
      "Epoch 52/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.9004 - val_loss: 0.3048 - val_accuracy: 0.8703\n",
      "Epoch 53/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.9076 - val_loss: 0.2923 - val_accuracy: 0.8703\n",
      "Epoch 54/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.8870 - val_loss: 0.3029 - val_accuracy: 0.8703\n",
      "Epoch 55/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2137 - accuracy: 0.8951 - val_loss: 0.2967 - val_accuracy: 0.8682\n",
      "Epoch 56/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2098 - accuracy: 0.9049 - val_loss: 0.3004 - val_accuracy: 0.8745\n",
      "Epoch 57/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 0.8987 - val_loss: 0.2966 - val_accuracy: 0.8745\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.9112 - val_loss: 0.2910 - val_accuracy: 0.8724\n",
      "Epoch 59/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2004 - accuracy: 0.9094 - val_loss: 0.3078 - val_accuracy: 0.8682\n",
      "Epoch 60/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.9031 - val_loss: 0.3113 - val_accuracy: 0.8766\n",
      "Epoch 61/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2035 - accuracy: 0.9058 - val_loss: 0.2926 - val_accuracy: 0.8745\n",
      "Epoch 62/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2197 - accuracy: 0.8969 - val_loss: 0.3053 - val_accuracy: 0.8661\n",
      "Epoch 63/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2078 - accuracy: 0.8996 - val_loss: 0.2938 - val_accuracy: 0.8787\n",
      "Epoch 64/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2048 - accuracy: 0.8987 - val_loss: 0.2909 - val_accuracy: 0.8745\n",
      "Epoch 65/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.9022 - val_loss: 0.3239 - val_accuracy: 0.8703\n",
      "Epoch 66/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.9049 - val_loss: 0.2952 - val_accuracy: 0.8724\n",
      "Epoch 67/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.9031 - val_loss: 0.3261 - val_accuracy: 0.8682\n",
      "Epoch 68/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2096 - accuracy: 0.9004 - val_loss: 0.3078 - val_accuracy: 0.8640\n",
      "Epoch 69/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 0.9067 - val_loss: 0.3033 - val_accuracy: 0.8640\n",
      "Epoch 70/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2051 - accuracy: 0.8996 - val_loss: 0.3097 - val_accuracy: 0.8661\n",
      "Epoch 71/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.9022 - val_loss: 0.3210 - val_accuracy: 0.8619\n",
      "Epoch 72/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.9022 - val_loss: 0.3281 - val_accuracy: 0.8682\n",
      "Epoch 73/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.9040 - val_loss: 0.3003 - val_accuracy: 0.8745\n",
      "Epoch 74/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.9031 - val_loss: 0.3035 - val_accuracy: 0.8766\n",
      "Epoch 75/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2079 - accuracy: 0.9067 - val_loss: 0.2991 - val_accuracy: 0.8745\n",
      "Epoch 76/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.8978 - val_loss: 0.2955 - val_accuracy: 0.8682\n",
      "Epoch 77/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.9031 - val_loss: 0.2977 - val_accuracy: 0.8724\n",
      "Epoch 78/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2034 - accuracy: 0.8996 - val_loss: 0.3145 - val_accuracy: 0.8766\n",
      "Epoch 79/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 0.9094 - val_loss: 0.3239 - val_accuracy: 0.8640\n",
      "Epoch 80/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1991 - accuracy: 0.8969 - val_loss: 0.2955 - val_accuracy: 0.8703\n",
      "Epoch 81/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.9121 - val_loss: 0.3032 - val_accuracy: 0.8745\n",
      "Epoch 82/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2043 - accuracy: 0.8996 - val_loss: 0.3139 - val_accuracy: 0.8703\n",
      "Epoch 83/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 0.9040 - val_loss: 0.3383 - val_accuracy: 0.8577\n",
      "Epoch 84/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 0.9022 - val_loss: 0.3110 - val_accuracy: 0.8787\n",
      "Epoch 85/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.9058 - val_loss: 0.3233 - val_accuracy: 0.8640\n",
      "Epoch 86/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1971 - accuracy: 0.9022 - val_loss: 0.3127 - val_accuracy: 0.8682\n",
      "Epoch 87/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.9022 - val_loss: 0.3024 - val_accuracy: 0.8640\n",
      "Epoch 88/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.8978 - val_loss: 0.2942 - val_accuracy: 0.8703\n",
      "Epoch 89/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1959 - accuracy: 0.9031 - val_loss: 0.3024 - val_accuracy: 0.8724\n",
      "Epoch 90/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.9076 - val_loss: 0.3247 - val_accuracy: 0.8661\n",
      "Epoch 91/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.9058 - val_loss: 0.3038 - val_accuracy: 0.8703\n",
      "Epoch 92/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.9040 - val_loss: 0.3423 - val_accuracy: 0.8619\n",
      "Epoch 93/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.9076 - val_loss: 0.3190 - val_accuracy: 0.8703\n",
      "Epoch 94/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.9067 - val_loss: 0.2988 - val_accuracy: 0.8661\n",
      "Epoch 95/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.9004 - val_loss: 0.2981 - val_accuracy: 0.8766\n",
      "Epoch 96/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1962 - accuracy: 0.9040 - val_loss: 0.3078 - val_accuracy: 0.8766\n",
      "Epoch 97/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.9013 - val_loss: 0.3006 - val_accuracy: 0.8703\n",
      "Epoch 98/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.9148 - val_loss: 0.3315 - val_accuracy: 0.8745\n",
      "Epoch 99/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.8996 - val_loss: 0.2886 - val_accuracy: 0.8745\n",
      "Epoch 100/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.8987 - val_loss: 0.3219 - val_accuracy: 0.8598\n",
      "Epoch 101/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.9076 - val_loss: 0.2986 - val_accuracy: 0.8724\n",
      "Epoch 102/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1959 - accuracy: 0.9058 - val_loss: 0.2898 - val_accuracy: 0.8619\n",
      "Epoch 103/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.9049 - val_loss: 0.3358 - val_accuracy: 0.8703\n",
      "Epoch 104/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.9112 - val_loss: 0.3049 - val_accuracy: 0.8724\n",
      "Epoch 105/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.9148 - val_loss: 0.3231 - val_accuracy: 0.8661\n",
      "Epoch 106/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.9013 - val_loss: 0.2904 - val_accuracy: 0.8619\n",
      "Epoch 107/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.9004 - val_loss: 0.3017 - val_accuracy: 0.8745\n",
      "Epoch 108/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.9112 - val_loss: 0.3164 - val_accuracy: 0.8724\n",
      "Epoch 109/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.9076 - val_loss: 0.3024 - val_accuracy: 0.8703\n",
      "Epoch 110/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.9040 - val_loss: 0.3270 - val_accuracy: 0.8724\n",
      "Epoch 111/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.9112 - val_loss: 0.3123 - val_accuracy: 0.8682\n",
      "Epoch 112/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.9103 - val_loss: 0.3186 - val_accuracy: 0.8703\n",
      "Epoch 113/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2016 - accuracy: 0.9076 - val_loss: 0.3233 - val_accuracy: 0.8724\n",
      "Epoch 114/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.9094 - val_loss: 0.2993 - val_accuracy: 0.8640\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.9085 - val_loss: 0.3442 - val_accuracy: 0.8640\n",
      "Epoch 116/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.2005 - accuracy: 0.9085 - val_loss: 0.3135 - val_accuracy: 0.8766\n",
      "Epoch 117/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.9085 - val_loss: 0.3061 - val_accuracy: 0.8640\n",
      "Epoch 118/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.9040 - val_loss: 0.3173 - val_accuracy: 0.8703\n",
      "Epoch 119/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.9094 - val_loss: 0.3065 - val_accuracy: 0.8640\n",
      "Epoch 120/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.9076 - val_loss: 0.3116 - val_accuracy: 0.8577\n",
      "Epoch 121/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.9139 - val_loss: 0.3278 - val_accuracy: 0.8577\n",
      "Epoch 122/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.9121 - val_loss: 0.3025 - val_accuracy: 0.8724\n",
      "Epoch 123/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1698 - accuracy: 0.9139 - val_loss: 0.3175 - val_accuracy: 0.8724\n",
      "Epoch 124/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1683 - accuracy: 0.9157 - val_loss: 0.3462 - val_accuracy: 0.8745\n",
      "Epoch 125/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1919 - accuracy: 0.8960 - val_loss: 0.3071 - val_accuracy: 0.8598\n",
      "Epoch 126/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.9112 - val_loss: 0.3174 - val_accuracy: 0.8724\n",
      "Epoch 127/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1713 - accuracy: 0.9049 - val_loss: 0.3096 - val_accuracy: 0.8745\n",
      "Epoch 128/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9067 - val_loss: 0.3310 - val_accuracy: 0.8703\n",
      "Epoch 129/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.9148 - val_loss: 0.3140 - val_accuracy: 0.8640\n",
      "Epoch 130/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1781 - accuracy: 0.9076 - val_loss: 0.3188 - val_accuracy: 0.8745\n",
      "Epoch 131/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.9058 - val_loss: 0.3317 - val_accuracy: 0.8703\n",
      "Epoch 132/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.9103 - val_loss: 0.3702 - val_accuracy: 0.8682\n",
      "Epoch 133/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.9112 - val_loss: 0.3499 - val_accuracy: 0.8724\n",
      "Epoch 134/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9157 - val_loss: 0.3791 - val_accuracy: 0.8640\n",
      "Epoch 135/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.9076 - val_loss: 0.3116 - val_accuracy: 0.8724\n",
      "Epoch 136/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.9130 - val_loss: 0.3629 - val_accuracy: 0.8661\n",
      "Epoch 137/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9121 - val_loss: 0.2898 - val_accuracy: 0.8724\n",
      "Epoch 138/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.9112 - val_loss: 0.3476 - val_accuracy: 0.8703\n",
      "Epoch 139/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1767 - accuracy: 0.9094 - val_loss: 0.3637 - val_accuracy: 0.8703\n",
      "Epoch 140/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.9076 - val_loss: 0.3790 - val_accuracy: 0.8598\n",
      "Epoch 141/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.9058 - val_loss: 0.3257 - val_accuracy: 0.8682\n",
      "Epoch 142/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.9049 - val_loss: 0.3637 - val_accuracy: 0.8577\n",
      "Epoch 143/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.9130 - val_loss: 0.3279 - val_accuracy: 0.8536\n",
      "Epoch 144/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.9049 - val_loss: 0.2983 - val_accuracy: 0.8619\n",
      "Epoch 145/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.9202 - val_loss: 0.3138 - val_accuracy: 0.8724\n",
      "Epoch 146/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.9184 - val_loss: 0.3627 - val_accuracy: 0.8682\n",
      "Epoch 147/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.9175 - val_loss: 0.3375 - val_accuracy: 0.8787\n",
      "Epoch 148/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1733 - accuracy: 0.9157 - val_loss: 0.3557 - val_accuracy: 0.8724\n",
      "Epoch 149/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.9157 - val_loss: 0.3016 - val_accuracy: 0.8640\n",
      "Epoch 150/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.9166 - val_loss: 0.3649 - val_accuracy: 0.8640\n",
      "Epoch 151/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1688 - accuracy: 0.9175 - val_loss: 0.3451 - val_accuracy: 0.8703\n",
      "Epoch 152/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9076 - val_loss: 0.3313 - val_accuracy: 0.8640\n",
      "Epoch 153/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9094 - val_loss: 0.3467 - val_accuracy: 0.8724\n",
      "Epoch 154/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.9166 - val_loss: 0.3323 - val_accuracy: 0.8703\n",
      "Epoch 155/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.9202 - val_loss: 0.3882 - val_accuracy: 0.8724\n",
      "Epoch 156/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1714 - accuracy: 0.9067 - val_loss: 0.3623 - val_accuracy: 0.8703\n",
      "Epoch 157/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9112 - val_loss: 0.3107 - val_accuracy: 0.8640\n",
      "Epoch 158/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.9130 - val_loss: 0.3378 - val_accuracy: 0.8682\n",
      "Epoch 159/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1776 - accuracy: 0.9220 - val_loss: 0.3272 - val_accuracy: 0.8703\n",
      "Epoch 160/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.9112 - val_loss: 0.3252 - val_accuracy: 0.8598\n",
      "Epoch 161/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.9112 - val_loss: 0.3314 - val_accuracy: 0.8745\n",
      "Epoch 162/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.9157 - val_loss: 0.3308 - val_accuracy: 0.8640\n",
      "Epoch 163/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1727 - accuracy: 0.9148 - val_loss: 0.3610 - val_accuracy: 0.8598\n",
      "Epoch 164/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1708 - accuracy: 0.9238 - val_loss: 0.3619 - val_accuracy: 0.8640\n",
      "Epoch 165/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.9157 - val_loss: 0.3144 - val_accuracy: 0.8598\n",
      "Epoch 166/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1608 - accuracy: 0.9166 - val_loss: 0.3310 - val_accuracy: 0.8598\n",
      "Epoch 167/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9256 - val_loss: 0.3888 - val_accuracy: 0.8661\n",
      "Epoch 168/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.9103 - val_loss: 0.3364 - val_accuracy: 0.8661\n",
      "Epoch 169/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.9112 - val_loss: 0.3108 - val_accuracy: 0.8661\n",
      "Epoch 170/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1651 - accuracy: 0.9229 - val_loss: 0.3379 - val_accuracy: 0.8661\n",
      "Epoch 171/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1700 - accuracy: 0.9166 - val_loss: 0.3652 - val_accuracy: 0.8619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1689 - accuracy: 0.9175 - val_loss: 0.3007 - val_accuracy: 0.8515\n",
      "Epoch 173/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.9121 - val_loss: 0.3310 - val_accuracy: 0.8598\n",
      "Epoch 174/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1687 - accuracy: 0.9175 - val_loss: 0.3260 - val_accuracy: 0.8556\n",
      "Epoch 175/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.9148 - val_loss: 0.3172 - val_accuracy: 0.8577\n",
      "Epoch 176/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.9157 - val_loss: 0.3485 - val_accuracy: 0.8556\n",
      "Epoch 177/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9166 - val_loss: 0.3651 - val_accuracy: 0.8619\n",
      "Epoch 178/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1678 - accuracy: 0.9211 - val_loss: 0.3265 - val_accuracy: 0.8494\n",
      "Epoch 179/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.9220 - val_loss: 0.2972 - val_accuracy: 0.8536\n",
      "Epoch 180/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9175 - val_loss: 0.3700 - val_accuracy: 0.8640\n",
      "Epoch 181/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.9103 - val_loss: 0.3249 - val_accuracy: 0.8619\n",
      "Epoch 182/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9238 - val_loss: 0.3350 - val_accuracy: 0.8661\n",
      "Epoch 183/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1653 - accuracy: 0.9166 - val_loss: 0.3701 - val_accuracy: 0.8577\n",
      "Epoch 184/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9229 - val_loss: 0.3687 - val_accuracy: 0.8515\n",
      "Epoch 185/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1709 - accuracy: 0.9148 - val_loss: 0.3846 - val_accuracy: 0.8577\n",
      "Epoch 186/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.9166 - val_loss: 0.3148 - val_accuracy: 0.8661\n",
      "Epoch 187/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1672 - accuracy: 0.9175 - val_loss: 0.3248 - val_accuracy: 0.8598\n",
      "Epoch 188/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9211 - val_loss: 0.3874 - val_accuracy: 0.8598\n",
      "Epoch 189/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9247 - val_loss: 0.3362 - val_accuracy: 0.8661\n",
      "Epoch 190/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9247 - val_loss: 0.3468 - val_accuracy: 0.8661\n",
      "Epoch 191/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9283 - val_loss: 0.3752 - val_accuracy: 0.8619\n",
      "Epoch 192/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1662 - accuracy: 0.9202 - val_loss: 0.3143 - val_accuracy: 0.8619\n",
      "Epoch 193/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1735 - accuracy: 0.9193 - val_loss: 0.3107 - val_accuracy: 0.8640\n",
      "Epoch 194/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9193 - val_loss: 0.3322 - val_accuracy: 0.8661\n",
      "Epoch 195/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9247 - val_loss: 0.3485 - val_accuracy: 0.8640\n",
      "Epoch 196/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9220 - val_loss: 0.4260 - val_accuracy: 0.8577\n",
      "Epoch 197/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9220 - val_loss: 0.3767 - val_accuracy: 0.8577\n",
      "Epoch 198/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1619 - accuracy: 0.9175 - val_loss: 0.3789 - val_accuracy: 0.8536\n",
      "Epoch 199/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1648 - accuracy: 0.9193 - val_loss: 0.3867 - val_accuracy: 0.8619\n",
      "Epoch 200/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9247 - val_loss: 0.2975 - val_accuracy: 0.8536\n",
      "Epoch 201/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1697 - accuracy: 0.9211 - val_loss: 0.3374 - val_accuracy: 0.8494\n",
      "Epoch 202/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1683 - accuracy: 0.9247 - val_loss: 0.3382 - val_accuracy: 0.8577\n",
      "Epoch 203/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1569 - accuracy: 0.9202 - val_loss: 0.3387 - val_accuracy: 0.8598\n",
      "Epoch 204/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.9094 - val_loss: 0.3471 - val_accuracy: 0.8598\n",
      "Epoch 205/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9345 - val_loss: 0.4048 - val_accuracy: 0.8661\n",
      "Epoch 206/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1610 - accuracy: 0.9202 - val_loss: 0.3176 - val_accuracy: 0.8556\n",
      "Epoch 207/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.9220 - val_loss: 0.3315 - val_accuracy: 0.8556\n",
      "Epoch 208/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9238 - val_loss: 0.3544 - val_accuracy: 0.8598\n",
      "Epoch 209/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1666 - accuracy: 0.9094 - val_loss: 0.3576 - val_accuracy: 0.8515\n",
      "Epoch 210/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.9130 - val_loss: 0.3260 - val_accuracy: 0.8640\n",
      "Epoch 211/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9238 - val_loss: 0.3136 - val_accuracy: 0.8640\n",
      "Epoch 212/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.9211 - val_loss: 0.3199 - val_accuracy: 0.8619\n",
      "Epoch 213/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1570 - accuracy: 0.9291 - val_loss: 0.3501 - val_accuracy: 0.8640\n",
      "Epoch 214/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9193 - val_loss: 0.3356 - val_accuracy: 0.8619\n",
      "Epoch 215/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.9363 - val_loss: 0.3786 - val_accuracy: 0.8598\n",
      "Epoch 216/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1702 - accuracy: 0.9193 - val_loss: 0.3091 - val_accuracy: 0.8536\n",
      "Epoch 217/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1655 - accuracy: 0.9211 - val_loss: 0.3327 - val_accuracy: 0.8619\n",
      "Epoch 218/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.9220 - val_loss: 0.3115 - val_accuracy: 0.8766\n",
      "Epoch 219/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1593 - accuracy: 0.9247 - val_loss: 0.3510 - val_accuracy: 0.8745\n",
      "Epoch 220/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 0.9265 - val_loss: 0.3606 - val_accuracy: 0.8703\n",
      "Epoch 221/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1715 - accuracy: 0.9202 - val_loss: 0.3221 - val_accuracy: 0.8682\n",
      "Epoch 222/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9300 - val_loss: 0.3711 - val_accuracy: 0.8619\n",
      "Epoch 223/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9274 - val_loss: 0.3312 - val_accuracy: 0.8682\n",
      "Epoch 224/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9229 - val_loss: 0.3635 - val_accuracy: 0.8410\n",
      "Epoch 225/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1593 - accuracy: 0.9166 - val_loss: 0.3384 - val_accuracy: 0.8577\n",
      "Epoch 226/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1505 - accuracy: 0.9166 - val_loss: 0.3948 - val_accuracy: 0.8766\n",
      "Epoch 227/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1442 - accuracy: 0.9309 - val_loss: 0.3708 - val_accuracy: 0.8494\n",
      "Epoch 228/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9112 - val_loss: 0.3730 - val_accuracy: 0.8619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9283 - val_loss: 0.3698 - val_accuracy: 0.8724\n",
      "Epoch 230/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9283 - val_loss: 0.3899 - val_accuracy: 0.8577\n",
      "Epoch 231/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9336 - val_loss: 0.4024 - val_accuracy: 0.8682\n",
      "Epoch 232/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.9220 - val_loss: 0.3871 - val_accuracy: 0.8598\n",
      "Epoch 233/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9229 - val_loss: 0.4044 - val_accuracy: 0.8619\n",
      "Epoch 234/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9247 - val_loss: 0.3816 - val_accuracy: 0.8682\n",
      "Epoch 235/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.9318 - val_loss: 0.3812 - val_accuracy: 0.8724\n",
      "Epoch 236/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9363 - val_loss: 0.3625 - val_accuracy: 0.8494\n",
      "Epoch 237/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.9274 - val_loss: 0.3535 - val_accuracy: 0.8640\n",
      "Epoch 238/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9345 - val_loss: 0.3893 - val_accuracy: 0.8640\n",
      "Epoch 239/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1487 - accuracy: 0.9238 - val_loss: 0.3531 - val_accuracy: 0.8619\n",
      "Epoch 240/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9300 - val_loss: 0.4412 - val_accuracy: 0.8640\n",
      "Epoch 241/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1384 - accuracy: 0.9354 - val_loss: 0.4176 - val_accuracy: 0.8703\n",
      "Epoch 242/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9256 - val_loss: 0.4181 - val_accuracy: 0.8661\n",
      "Epoch 243/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.9238 - val_loss: 0.3244 - val_accuracy: 0.8640\n",
      "Epoch 244/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1579 - accuracy: 0.9184 - val_loss: 0.3333 - val_accuracy: 0.8724\n",
      "Epoch 245/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1587 - accuracy: 0.9256 - val_loss: 0.3330 - val_accuracy: 0.8619\n",
      "Epoch 246/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9318 - val_loss: 0.3577 - val_accuracy: 0.8577\n",
      "Epoch 247/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.9354 - val_loss: 0.3443 - val_accuracy: 0.8724\n",
      "Epoch 248/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.9220 - val_loss: 0.2948 - val_accuracy: 0.8745\n",
      "Epoch 249/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9193 - val_loss: 0.3568 - val_accuracy: 0.8682\n",
      "Epoch 250/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1497 - accuracy: 0.9327 - val_loss: 0.3554 - val_accuracy: 0.8619\n",
      "Epoch 251/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1572 - accuracy: 0.9247 - val_loss: 0.3842 - val_accuracy: 0.8619\n",
      "Epoch 252/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9265 - val_loss: 0.3608 - val_accuracy: 0.8745\n",
      "Epoch 253/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.9139 - val_loss: 0.3877 - val_accuracy: 0.8703\n",
      "Epoch 254/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1317 - accuracy: 0.9462 - val_loss: 0.4088 - val_accuracy: 0.8661\n",
      "Epoch 255/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9211 - val_loss: 0.3819 - val_accuracy: 0.8661\n",
      "Epoch 256/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9283 - val_loss: 0.3921 - val_accuracy: 0.8619\n",
      "Epoch 257/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1506 - accuracy: 0.9309 - val_loss: 0.3705 - val_accuracy: 0.8619\n",
      "Epoch 258/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9265 - val_loss: 0.3871 - val_accuracy: 0.8661\n",
      "Epoch 259/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9238 - val_loss: 0.3923 - val_accuracy: 0.8473\n",
      "Epoch 260/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1550 - accuracy: 0.9300 - val_loss: 0.3521 - val_accuracy: 0.8682\n",
      "Epoch 261/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9372 - val_loss: 0.3746 - val_accuracy: 0.8661\n",
      "Epoch 262/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.9247 - val_loss: 0.4045 - val_accuracy: 0.8619\n",
      "Epoch 263/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9202 - val_loss: 0.3445 - val_accuracy: 0.8619\n",
      "Epoch 264/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1519 - accuracy: 0.9265 - val_loss: 0.3944 - val_accuracy: 0.8619\n",
      "Epoch 265/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9354 - val_loss: 0.3889 - val_accuracy: 0.8661\n",
      "Epoch 266/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9283 - val_loss: 0.3524 - val_accuracy: 0.8808\n",
      "Epoch 267/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9327 - val_loss: 0.3878 - val_accuracy: 0.8682\n",
      "Epoch 268/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9202 - val_loss: 0.3986 - val_accuracy: 0.8682\n",
      "Epoch 269/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9265 - val_loss: 0.4138 - val_accuracy: 0.8598\n",
      "Epoch 270/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.9417 - val_loss: 0.4288 - val_accuracy: 0.8661\n",
      "Epoch 271/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1434 - accuracy: 0.9354 - val_loss: 0.4766 - val_accuracy: 0.8598\n",
      "Epoch 272/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9309 - val_loss: 0.3304 - val_accuracy: 0.8515\n",
      "Epoch 273/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1293 - accuracy: 0.9417 - val_loss: 0.4515 - val_accuracy: 0.8640\n",
      "Epoch 274/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1476 - accuracy: 0.9291 - val_loss: 0.3913 - val_accuracy: 0.8515\n",
      "Epoch 275/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1441 - accuracy: 0.9327 - val_loss: 0.4044 - val_accuracy: 0.8682\n",
      "Epoch 276/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9157 - val_loss: 0.3598 - val_accuracy: 0.8766\n",
      "Epoch 277/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9300 - val_loss: 0.3411 - val_accuracy: 0.8745\n",
      "Epoch 278/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1465 - accuracy: 0.9327 - val_loss: 0.3773 - val_accuracy: 0.8640\n",
      "Epoch 279/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9300 - val_loss: 0.3778 - val_accuracy: 0.8703\n",
      "Epoch 280/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1572 - accuracy: 0.9318 - val_loss: 0.3413 - val_accuracy: 0.8598\n",
      "Epoch 281/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9184 - val_loss: 0.4055 - val_accuracy: 0.8619\n",
      "Epoch 282/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9274 - val_loss: 0.3358 - val_accuracy: 0.8473\n",
      "Epoch 283/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.9336 - val_loss: 0.4100 - val_accuracy: 0.8598\n",
      "Epoch 284/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.9265 - val_loss: 0.3838 - val_accuracy: 0.8536\n",
      "Epoch 285/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1376 - accuracy: 0.9327 - val_loss: 0.4822 - val_accuracy: 0.8661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9399 - val_loss: 0.4339 - val_accuracy: 0.8661\n",
      "Epoch 287/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9309 - val_loss: 0.4234 - val_accuracy: 0.8661\n",
      "Epoch 288/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9256 - val_loss: 0.4320 - val_accuracy: 0.8682\n",
      "Epoch 289/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1487 - accuracy: 0.9336 - val_loss: 0.3604 - val_accuracy: 0.8577\n",
      "Epoch 290/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9274 - val_loss: 0.3479 - val_accuracy: 0.8619\n",
      "Epoch 291/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9300 - val_loss: 0.4221 - val_accuracy: 0.8619\n",
      "Epoch 292/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9363 - val_loss: 0.3236 - val_accuracy: 0.8787\n",
      "Epoch 293/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9390 - val_loss: 0.4013 - val_accuracy: 0.8640\n",
      "Epoch 294/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1398 - accuracy: 0.9399 - val_loss: 0.4209 - val_accuracy: 0.8703\n",
      "Epoch 295/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9283 - val_loss: 0.3682 - val_accuracy: 0.8598\n",
      "Epoch 296/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1409 - accuracy: 0.9345 - val_loss: 0.3769 - val_accuracy: 0.8682\n",
      "Epoch 297/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9327 - val_loss: 0.3650 - val_accuracy: 0.8598\n",
      "Epoch 298/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1472 - accuracy: 0.9336 - val_loss: 0.3583 - val_accuracy: 0.8494\n",
      "Epoch 299/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.9399 - val_loss: 0.3604 - val_accuracy: 0.8577\n",
      "Epoch 300/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1485 - accuracy: 0.9417 - val_loss: 0.3780 - val_accuracy: 0.8640\n",
      "Epoch 301/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1522 - accuracy: 0.9336 - val_loss: 0.3956 - val_accuracy: 0.8640\n",
      "Epoch 302/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9327 - val_loss: 0.4209 - val_accuracy: 0.8640\n",
      "Epoch 303/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9309 - val_loss: 0.4159 - val_accuracy: 0.8577\n",
      "Epoch 304/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.9354 - val_loss: 0.4549 - val_accuracy: 0.8745\n",
      "Epoch 305/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1376 - accuracy: 0.9372 - val_loss: 0.3750 - val_accuracy: 0.8619\n",
      "Epoch 306/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1378 - accuracy: 0.9354 - val_loss: 0.4059 - val_accuracy: 0.8619\n",
      "Epoch 307/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.9417 - val_loss: 0.4505 - val_accuracy: 0.8515\n",
      "Epoch 308/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9390 - val_loss: 0.4363 - val_accuracy: 0.8556\n",
      "Epoch 309/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9229 - val_loss: 0.4461 - val_accuracy: 0.8640\n",
      "Epoch 310/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1405 - accuracy: 0.9354 - val_loss: 0.4260 - val_accuracy: 0.8640\n",
      "Epoch 311/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9318 - val_loss: 0.4113 - val_accuracy: 0.8703\n",
      "Epoch 312/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9345 - val_loss: 0.4036 - val_accuracy: 0.8556\n",
      "Epoch 313/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9444 - val_loss: 0.4655 - val_accuracy: 0.8598\n",
      "Epoch 314/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1281 - accuracy: 0.9408 - val_loss: 0.4472 - val_accuracy: 0.8619\n",
      "Epoch 315/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9247 - val_loss: 0.3402 - val_accuracy: 0.8724\n",
      "Epoch 316/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9327 - val_loss: 0.3659 - val_accuracy: 0.8598\n",
      "Epoch 317/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9300 - val_loss: 0.3479 - val_accuracy: 0.8515\n",
      "Epoch 318/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9381 - val_loss: 0.3652 - val_accuracy: 0.8577\n",
      "Epoch 319/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9381 - val_loss: 0.4012 - val_accuracy: 0.8640\n",
      "Epoch 320/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1258 - accuracy: 0.9426 - val_loss: 0.3942 - val_accuracy: 0.8619\n",
      "Epoch 321/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9381 - val_loss: 0.3772 - val_accuracy: 0.8640\n",
      "Epoch 322/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1370 - accuracy: 0.9381 - val_loss: 0.3739 - val_accuracy: 0.8577\n",
      "Epoch 323/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.9426 - val_loss: 0.3915 - val_accuracy: 0.8724\n",
      "Epoch 324/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9408 - val_loss: 0.3558 - val_accuracy: 0.8640\n",
      "Epoch 325/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.9327 - val_loss: 0.3862 - val_accuracy: 0.8640\n",
      "Epoch 326/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9309 - val_loss: 0.4279 - val_accuracy: 0.8577\n",
      "Epoch 327/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1173 - accuracy: 0.9453 - val_loss: 0.4462 - val_accuracy: 0.8661\n",
      "Epoch 328/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.9408 - val_loss: 0.3978 - val_accuracy: 0.8703\n",
      "Epoch 329/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1460 - accuracy: 0.9327 - val_loss: 0.3623 - val_accuracy: 0.8661\n",
      "Epoch 330/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9462 - val_loss: 0.4167 - val_accuracy: 0.8515\n",
      "Epoch 331/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9354 - val_loss: 0.4517 - val_accuracy: 0.8536\n",
      "Epoch 332/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1304 - accuracy: 0.9462 - val_loss: 0.4519 - val_accuracy: 0.8640\n",
      "Epoch 333/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1501 - accuracy: 0.9283 - val_loss: 0.3554 - val_accuracy: 0.8703\n",
      "Epoch 334/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1493 - accuracy: 0.9265 - val_loss: 0.3651 - val_accuracy: 0.8619\n",
      "Epoch 335/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1302 - accuracy: 0.9426 - val_loss: 0.4615 - val_accuracy: 0.8473\n",
      "Epoch 336/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9363 - val_loss: 0.3751 - val_accuracy: 0.8577\n",
      "Epoch 337/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.9381 - val_loss: 0.4341 - val_accuracy: 0.8661\n",
      "Epoch 338/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1287 - accuracy: 0.9417 - val_loss: 0.4701 - val_accuracy: 0.8577\n",
      "Epoch 339/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9408 - val_loss: 0.4306 - val_accuracy: 0.8703\n",
      "Epoch 340/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9426 - val_loss: 0.4251 - val_accuracy: 0.8598\n",
      "Epoch 341/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1377 - accuracy: 0.9435 - val_loss: 0.4277 - val_accuracy: 0.8515\n",
      "Epoch 342/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9435 - val_loss: 0.3542 - val_accuracy: 0.8745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9444 - val_loss: 0.4492 - val_accuracy: 0.8556\n",
      "Epoch 344/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1368 - accuracy: 0.9399 - val_loss: 0.4199 - val_accuracy: 0.8598\n",
      "Epoch 345/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.9444 - val_loss: 0.3977 - val_accuracy: 0.8703\n",
      "Epoch 346/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1226 - accuracy: 0.9417 - val_loss: 0.4431 - val_accuracy: 0.8703\n",
      "Epoch 347/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9363 - val_loss: 0.3951 - val_accuracy: 0.8661\n",
      "Epoch 348/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1376 - accuracy: 0.9336 - val_loss: 0.4042 - val_accuracy: 0.8619\n",
      "Epoch 349/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1441 - accuracy: 0.9363 - val_loss: 0.3870 - val_accuracy: 0.8745\n",
      "Epoch 350/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9336 - val_loss: 0.4063 - val_accuracy: 0.8703\n",
      "Epoch 351/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9435 - val_loss: 0.4165 - val_accuracy: 0.8494\n",
      "Epoch 352/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1229 - accuracy: 0.9453 - val_loss: 0.4483 - val_accuracy: 0.8598\n",
      "Epoch 353/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1302 - accuracy: 0.9408 - val_loss: 0.4374 - val_accuracy: 0.8661\n",
      "Epoch 354/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9417 - val_loss: 0.4025 - val_accuracy: 0.8724\n",
      "Epoch 355/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9399 - val_loss: 0.4078 - val_accuracy: 0.8556\n",
      "Epoch 356/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1370 - accuracy: 0.9381 - val_loss: 0.3997 - val_accuracy: 0.8640\n",
      "Epoch 357/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9318 - val_loss: 0.4081 - val_accuracy: 0.8703\n",
      "Epoch 358/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.9435 - val_loss: 0.4238 - val_accuracy: 0.8682\n",
      "Epoch 359/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1476 - accuracy: 0.9283 - val_loss: 0.3666 - val_accuracy: 0.8661\n",
      "Epoch 360/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9498 - val_loss: 0.4806 - val_accuracy: 0.8577\n",
      "Epoch 361/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.9498 - val_loss: 0.4871 - val_accuracy: 0.8536\n",
      "Epoch 362/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1263 - accuracy: 0.9489 - val_loss: 0.4400 - val_accuracy: 0.8640\n",
      "Epoch 363/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.9399 - val_loss: 0.5048 - val_accuracy: 0.8640\n",
      "Epoch 364/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1274 - accuracy: 0.9408 - val_loss: 0.4197 - val_accuracy: 0.8598\n",
      "Epoch 365/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1281 - accuracy: 0.9444 - val_loss: 0.4491 - val_accuracy: 0.8556\n",
      "Epoch 366/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.9507 - val_loss: 0.4449 - val_accuracy: 0.8640\n",
      "Epoch 367/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.9444 - val_loss: 0.4440 - val_accuracy: 0.8640\n",
      "Epoch 368/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9381 - val_loss: 0.4475 - val_accuracy: 0.8640\n",
      "Epoch 369/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9309 - val_loss: 0.3594 - val_accuracy: 0.8536\n",
      "Epoch 370/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.9444 - val_loss: 0.4668 - val_accuracy: 0.8577\n",
      "Epoch 371/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1322 - accuracy: 0.9417 - val_loss: 0.4352 - val_accuracy: 0.8577\n",
      "Epoch 372/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.9444 - val_loss: 0.4699 - val_accuracy: 0.8661\n",
      "Epoch 373/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.9363 - val_loss: 0.4298 - val_accuracy: 0.8640\n",
      "Epoch 374/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.9390 - val_loss: 0.3732 - val_accuracy: 0.8640\n",
      "Epoch 375/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1354 - accuracy: 0.9372 - val_loss: 0.4346 - val_accuracy: 0.8640\n",
      "Epoch 376/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9435 - val_loss: 0.4552 - val_accuracy: 0.8766\n",
      "Epoch 377/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.9471 - val_loss: 0.4278 - val_accuracy: 0.8494\n",
      "Epoch 378/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1322 - accuracy: 0.9408 - val_loss: 0.3827 - val_accuracy: 0.8473\n",
      "Epoch 379/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1426 - accuracy: 0.9327 - val_loss: 0.3607 - val_accuracy: 0.8619\n",
      "Epoch 380/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9426 - val_loss: 0.4819 - val_accuracy: 0.8494\n",
      "Epoch 381/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1302 - accuracy: 0.9399 - val_loss: 0.3654 - val_accuracy: 0.8577\n",
      "Epoch 382/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9363 - val_loss: 0.4297 - val_accuracy: 0.8724\n",
      "Epoch 383/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9426 - val_loss: 0.4047 - val_accuracy: 0.8661\n",
      "Epoch 384/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9507 - val_loss: 0.4578 - val_accuracy: 0.8619\n",
      "Epoch 385/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9480 - val_loss: 0.4868 - val_accuracy: 0.8661\n",
      "Epoch 386/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9381 - val_loss: 0.4326 - val_accuracy: 0.8598\n",
      "Epoch 387/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9408 - val_loss: 0.3971 - val_accuracy: 0.8598\n",
      "Epoch 388/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1144 - accuracy: 0.9498 - val_loss: 0.4832 - val_accuracy: 0.8703\n",
      "Epoch 389/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1341 - accuracy: 0.9390 - val_loss: 0.4260 - val_accuracy: 0.8640\n",
      "Epoch 390/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9408 - val_loss: 0.4088 - val_accuracy: 0.8556\n",
      "Epoch 391/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.9507 - val_loss: 0.4631 - val_accuracy: 0.8682\n",
      "Epoch 392/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9462 - val_loss: 0.4793 - val_accuracy: 0.8577\n",
      "Epoch 393/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.9596 - val_loss: 0.4621 - val_accuracy: 0.8682\n",
      "Epoch 394/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.9336 - val_loss: 0.4641 - val_accuracy: 0.8619\n",
      "Epoch 395/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9426 - val_loss: 0.3534 - val_accuracy: 0.8640\n",
      "Epoch 396/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1412 - accuracy: 0.9381 - val_loss: 0.4419 - val_accuracy: 0.8536\n",
      "Epoch 397/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9480 - val_loss: 0.4454 - val_accuracy: 0.8536\n",
      "Epoch 398/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9507 - val_loss: 0.4724 - val_accuracy: 0.8515\n",
      "Epoch 399/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9471 - val_loss: 0.3760 - val_accuracy: 0.8598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1302 - accuracy: 0.9399 - val_loss: 0.4088 - val_accuracy: 0.8703\n",
      "Epoch 401/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1235 - accuracy: 0.9498 - val_loss: 0.5057 - val_accuracy: 0.8619\n",
      "Epoch 402/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1231 - accuracy: 0.9453 - val_loss: 0.4024 - val_accuracy: 0.8598\n",
      "Epoch 403/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.9444 - val_loss: 0.4243 - val_accuracy: 0.8682\n",
      "Epoch 404/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.9498 - val_loss: 0.4017 - val_accuracy: 0.8703\n",
      "Epoch 405/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.9462 - val_loss: 0.4445 - val_accuracy: 0.8745\n",
      "Epoch 406/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.9525 - val_loss: 0.4344 - val_accuracy: 0.8640\n",
      "Epoch 407/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.9489 - val_loss: 0.4296 - val_accuracy: 0.8640\n",
      "Epoch 408/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9462 - val_loss: 0.4765 - val_accuracy: 0.8577\n",
      "Epoch 409/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1358 - accuracy: 0.9372 - val_loss: 0.4385 - val_accuracy: 0.8766\n",
      "Epoch 410/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9435 - val_loss: 0.4117 - val_accuracy: 0.8536\n",
      "Epoch 411/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.9480 - val_loss: 0.4482 - val_accuracy: 0.8536\n",
      "Epoch 412/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9453 - val_loss: 0.4470 - val_accuracy: 0.8619\n",
      "Epoch 413/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.9498 - val_loss: 0.4928 - val_accuracy: 0.8556\n",
      "Epoch 414/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9291 - val_loss: 0.4163 - val_accuracy: 0.8703\n",
      "Epoch 415/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1341 - accuracy: 0.9399 - val_loss: 0.4186 - val_accuracy: 0.8661\n",
      "Epoch 416/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9453 - val_loss: 0.4361 - val_accuracy: 0.8640\n",
      "Epoch 417/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.9525 - val_loss: 0.4500 - val_accuracy: 0.8682\n",
      "Epoch 418/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9498 - val_loss: 0.4822 - val_accuracy: 0.8619\n",
      "Epoch 419/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1245 - accuracy: 0.9426 - val_loss: 0.4529 - val_accuracy: 0.8661\n",
      "Epoch 420/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9489 - val_loss: 0.4785 - val_accuracy: 0.8682\n",
      "Epoch 421/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9498 - val_loss: 0.4766 - val_accuracy: 0.8598\n",
      "Epoch 422/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9498 - val_loss: 0.4321 - val_accuracy: 0.8598\n",
      "Epoch 423/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9552 - val_loss: 0.4939 - val_accuracy: 0.8556\n",
      "Epoch 424/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.9435 - val_loss: 0.4642 - val_accuracy: 0.8598\n",
      "Epoch 425/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.9471 - val_loss: 0.4341 - val_accuracy: 0.8619\n",
      "Epoch 426/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9453 - val_loss: 0.4295 - val_accuracy: 0.8577\n",
      "Epoch 427/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9462 - val_loss: 0.4701 - val_accuracy: 0.8494\n",
      "Epoch 428/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9444 - val_loss: 0.4480 - val_accuracy: 0.8682\n",
      "Epoch 429/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9408 - val_loss: 0.4252 - val_accuracy: 0.8703\n",
      "Epoch 430/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.9462 - val_loss: 0.4794 - val_accuracy: 0.8703\n",
      "Epoch 431/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.9435 - val_loss: 0.4969 - val_accuracy: 0.8556\n",
      "Epoch 432/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.9462 - val_loss: 0.4395 - val_accuracy: 0.8619\n",
      "Epoch 433/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1156 - accuracy: 0.9543 - val_loss: 0.4243 - val_accuracy: 0.8556\n",
      "Epoch 434/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1187 - accuracy: 0.9507 - val_loss: 0.4878 - val_accuracy: 0.8598\n",
      "Epoch 435/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.9435 - val_loss: 0.4668 - val_accuracy: 0.8745\n",
      "Epoch 436/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1004 - accuracy: 0.9578 - val_loss: 0.4517 - val_accuracy: 0.8577\n",
      "Epoch 437/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.9525 - val_loss: 0.4907 - val_accuracy: 0.8577\n",
      "Epoch 438/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0988 - accuracy: 0.9570 - val_loss: 0.4711 - val_accuracy: 0.8682\n",
      "Epoch 439/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1416 - accuracy: 0.9435 - val_loss: 0.4553 - val_accuracy: 0.8682\n",
      "Epoch 440/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.9480 - val_loss: 0.4467 - val_accuracy: 0.8577\n",
      "Epoch 441/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.9552 - val_loss: 0.4312 - val_accuracy: 0.8556\n",
      "Epoch 442/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.9480 - val_loss: 0.4431 - val_accuracy: 0.8640\n",
      "Epoch 443/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9498 - val_loss: 0.4908 - val_accuracy: 0.8577\n",
      "Epoch 444/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9489 - val_loss: 0.4914 - val_accuracy: 0.8556\n",
      "Epoch 445/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9525 - val_loss: 0.4731 - val_accuracy: 0.8494\n",
      "Epoch 446/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.9480 - val_loss: 0.4653 - val_accuracy: 0.8598\n",
      "Epoch 447/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9489 - val_loss: 0.4991 - val_accuracy: 0.8598\n",
      "Epoch 448/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1278 - accuracy: 0.9345 - val_loss: 0.4709 - val_accuracy: 0.8577\n",
      "Epoch 449/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1409 - accuracy: 0.9390 - val_loss: 0.3392 - val_accuracy: 0.8682\n",
      "Epoch 450/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.9543 - val_loss: 0.4563 - val_accuracy: 0.8661\n",
      "Epoch 451/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9480 - val_loss: 0.4695 - val_accuracy: 0.8703\n",
      "Epoch 452/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9435 - val_loss: 0.4801 - val_accuracy: 0.8536\n",
      "Epoch 453/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9471 - val_loss: 0.4703 - val_accuracy: 0.8556\n",
      "Epoch 454/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9552 - val_loss: 0.4916 - val_accuracy: 0.8766\n",
      "Epoch 455/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1306 - accuracy: 0.9480 - val_loss: 0.4773 - val_accuracy: 0.8766\n",
      "Epoch 456/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.9525 - val_loss: 0.4762 - val_accuracy: 0.8619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9552 - val_loss: 0.4966 - val_accuracy: 0.8661\n",
      "Epoch 458/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9507 - val_loss: 0.5294 - val_accuracy: 0.8598\n",
      "Epoch 459/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1316 - accuracy: 0.9417 - val_loss: 0.4653 - val_accuracy: 0.8619\n",
      "Epoch 460/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9552 - val_loss: 0.4430 - val_accuracy: 0.8766\n",
      "Epoch 461/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9489 - val_loss: 0.5080 - val_accuracy: 0.8640\n",
      "Epoch 462/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9498 - val_loss: 0.4699 - val_accuracy: 0.8515\n",
      "Epoch 463/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9498 - val_loss: 0.4948 - val_accuracy: 0.8640\n",
      "Epoch 464/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9596 - val_loss: 0.4502 - val_accuracy: 0.8703\n",
      "Epoch 465/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.9462 - val_loss: 0.4398 - val_accuracy: 0.8682\n",
      "Epoch 466/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1277 - accuracy: 0.9471 - val_loss: 0.4989 - val_accuracy: 0.8556\n",
      "Epoch 467/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9426 - val_loss: 0.4261 - val_accuracy: 0.8661\n",
      "Epoch 468/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9453 - val_loss: 0.4643 - val_accuracy: 0.8745\n",
      "Epoch 469/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1126 - accuracy: 0.9596 - val_loss: 0.5222 - val_accuracy: 0.8431\n",
      "Epoch 470/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.9534 - val_loss: 0.5093 - val_accuracy: 0.8577\n",
      "Epoch 471/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9534 - val_loss: 0.4723 - val_accuracy: 0.8766\n",
      "Epoch 472/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9480 - val_loss: 0.5863 - val_accuracy: 0.8640\n",
      "Epoch 473/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9390 - val_loss: 0.4966 - val_accuracy: 0.8619\n",
      "Epoch 474/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9534 - val_loss: 0.4954 - val_accuracy: 0.8682\n",
      "Epoch 475/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0984 - accuracy: 0.9534 - val_loss: 0.5053 - val_accuracy: 0.8640\n",
      "Epoch 476/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.9516 - val_loss: 0.5292 - val_accuracy: 0.8640\n",
      "Epoch 477/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.9507 - val_loss: 0.4928 - val_accuracy: 0.8703\n",
      "Epoch 478/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.9489 - val_loss: 0.4155 - val_accuracy: 0.8556\n",
      "Epoch 479/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.9435 - val_loss: 0.3472 - val_accuracy: 0.8766\n",
      "Epoch 480/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.9507 - val_loss: 0.4448 - val_accuracy: 0.8598\n",
      "Epoch 481/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9525 - val_loss: 0.5266 - val_accuracy: 0.8536\n",
      "Epoch 482/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9596 - val_loss: 0.5135 - val_accuracy: 0.8556\n",
      "Epoch 483/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.9516 - val_loss: 0.5351 - val_accuracy: 0.8703\n",
      "Epoch 484/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9489 - val_loss: 0.4779 - val_accuracy: 0.8577\n",
      "Epoch 485/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1037 - accuracy: 0.9543 - val_loss: 0.4935 - val_accuracy: 0.8494\n",
      "Epoch 486/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1007 - accuracy: 0.9596 - val_loss: 0.4428 - val_accuracy: 0.8431\n",
      "Epoch 487/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.9498 - val_loss: 0.4440 - val_accuracy: 0.8724\n",
      "Epoch 488/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1245 - accuracy: 0.9435 - val_loss: 0.4585 - val_accuracy: 0.8619\n",
      "Epoch 489/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.9453 - val_loss: 0.4879 - val_accuracy: 0.8577\n",
      "Epoch 490/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9543 - val_loss: 0.4571 - val_accuracy: 0.8619\n",
      "Epoch 491/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9552 - val_loss: 0.5030 - val_accuracy: 0.8515\n",
      "Epoch 492/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9498 - val_loss: 0.5049 - val_accuracy: 0.8703\n",
      "Epoch 493/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9561 - val_loss: 0.4332 - val_accuracy: 0.8536\n",
      "Epoch 494/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9552 - val_loss: 0.5576 - val_accuracy: 0.8515\n",
      "Epoch 495/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0927 - accuracy: 0.9641 - val_loss: 0.5380 - val_accuracy: 0.8515\n",
      "Epoch 496/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9462 - val_loss: 0.4572 - val_accuracy: 0.8661\n",
      "Epoch 497/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9489 - val_loss: 0.5066 - val_accuracy: 0.8598\n",
      "Epoch 498/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9498 - val_loss: 0.4809 - val_accuracy: 0.8556\n",
      "Epoch 499/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9596 - val_loss: 0.5134 - val_accuracy: 0.8640\n",
      "Epoch 500/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0943 - accuracy: 0.9596 - val_loss: 0.4811 - val_accuracy: 0.8556\n",
      "Epoch 501/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.9444 - val_loss: 0.4729 - val_accuracy: 0.8556\n",
      "Epoch 502/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9605 - val_loss: 0.5428 - val_accuracy: 0.8577\n",
      "Epoch 503/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1028 - accuracy: 0.9561 - val_loss: 0.5362 - val_accuracy: 0.8598\n",
      "Epoch 504/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.9507 - val_loss: 0.4953 - val_accuracy: 0.8556\n",
      "Epoch 505/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1263 - accuracy: 0.9417 - val_loss: 0.5394 - val_accuracy: 0.8640\n",
      "Epoch 506/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9525 - val_loss: 0.5458 - val_accuracy: 0.8661\n",
      "Epoch 507/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0996 - accuracy: 0.9605 - val_loss: 0.5453 - val_accuracy: 0.8640\n",
      "Epoch 508/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.9498 - val_loss: 0.5137 - val_accuracy: 0.8473\n",
      "Epoch 509/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.9462 - val_loss: 0.4804 - val_accuracy: 0.8724\n",
      "Epoch 510/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.9507 - val_loss: 0.5009 - val_accuracy: 0.8661\n",
      "Epoch 511/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.9480 - val_loss: 0.4539 - val_accuracy: 0.8598\n",
      "Epoch 512/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9543 - val_loss: 0.4814 - val_accuracy: 0.8745\n",
      "Epoch 513/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9570 - val_loss: 0.5065 - val_accuracy: 0.8619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.9552 - val_loss: 0.4840 - val_accuracy: 0.8619\n",
      "Epoch 515/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0948 - accuracy: 0.9605 - val_loss: 0.5188 - val_accuracy: 0.8703\n",
      "Epoch 516/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.9507 - val_loss: 0.4722 - val_accuracy: 0.8724\n",
      "Epoch 517/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0861 - accuracy: 0.9668 - val_loss: 0.5393 - val_accuracy: 0.8682\n",
      "Epoch 518/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0969 - accuracy: 0.9596 - val_loss: 0.5157 - val_accuracy: 0.8661\n",
      "Epoch 519/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9507 - val_loss: 0.5291 - val_accuracy: 0.8682\n",
      "Epoch 520/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0984 - accuracy: 0.9587 - val_loss: 0.5129 - val_accuracy: 0.8745\n",
      "Epoch 521/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9623 - val_loss: 0.4816 - val_accuracy: 0.8598\n",
      "Epoch 522/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1012 - accuracy: 0.9516 - val_loss: 0.4639 - val_accuracy: 0.8473\n",
      "Epoch 523/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9596 - val_loss: 0.5513 - val_accuracy: 0.8661\n",
      "Epoch 524/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9525 - val_loss: 0.5162 - val_accuracy: 0.8619\n",
      "Epoch 525/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1028 - accuracy: 0.9507 - val_loss: 0.5320 - val_accuracy: 0.8682\n",
      "Epoch 526/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9578 - val_loss: 0.5196 - val_accuracy: 0.8619\n",
      "Epoch 527/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.9471 - val_loss: 0.5166 - val_accuracy: 0.8577\n",
      "Epoch 528/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9516 - val_loss: 0.5456 - val_accuracy: 0.8577\n",
      "Epoch 529/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0887 - accuracy: 0.9614 - val_loss: 0.6068 - val_accuracy: 0.8515\n",
      "Epoch 530/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.9480 - val_loss: 0.4704 - val_accuracy: 0.8577\n",
      "Epoch 531/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9453 - val_loss: 0.4346 - val_accuracy: 0.8619\n",
      "Epoch 532/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.9480 - val_loss: 0.4882 - val_accuracy: 0.8619\n",
      "Epoch 533/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.9561 - val_loss: 0.5427 - val_accuracy: 0.8536\n",
      "Epoch 534/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.9534 - val_loss: 0.5501 - val_accuracy: 0.8577\n",
      "Epoch 535/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9570 - val_loss: 0.5422 - val_accuracy: 0.8598\n",
      "Epoch 536/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9417 - val_loss: 0.4510 - val_accuracy: 0.8556\n",
      "Epoch 537/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.9596 - val_loss: 0.4977 - val_accuracy: 0.8536\n",
      "Epoch 538/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0988 - accuracy: 0.9543 - val_loss: 0.5773 - val_accuracy: 0.8640\n",
      "Epoch 539/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9668 - val_loss: 0.5655 - val_accuracy: 0.8577\n",
      "Epoch 540/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9614 - val_loss: 0.5124 - val_accuracy: 0.8577\n",
      "Epoch 541/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9543 - val_loss: 0.5074 - val_accuracy: 0.8745\n",
      "Epoch 542/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9570 - val_loss: 0.5389 - val_accuracy: 0.8703\n",
      "Epoch 543/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.9578 - val_loss: 0.5532 - val_accuracy: 0.8640\n",
      "Epoch 544/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1017 - accuracy: 0.9525 - val_loss: 0.5002 - val_accuracy: 0.8536\n",
      "Epoch 545/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.9543 - val_loss: 0.4438 - val_accuracy: 0.8619\n",
      "Epoch 546/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9605 - val_loss: 0.4988 - val_accuracy: 0.8745\n",
      "Epoch 547/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.9507 - val_loss: 0.5999 - val_accuracy: 0.8494\n",
      "Epoch 548/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9507 - val_loss: 0.4750 - val_accuracy: 0.8661\n",
      "Epoch 549/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9480 - val_loss: 0.4818 - val_accuracy: 0.8703\n",
      "Epoch 550/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1173 - accuracy: 0.9543 - val_loss: 0.5144 - val_accuracy: 0.8661\n",
      "Epoch 551/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.9534 - val_loss: 0.4790 - val_accuracy: 0.8619\n",
      "Epoch 552/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9498 - val_loss: 0.5589 - val_accuracy: 0.8556\n",
      "Epoch 553/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0879 - accuracy: 0.9578 - val_loss: 0.5415 - val_accuracy: 0.8577\n",
      "Epoch 554/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9534 - val_loss: 0.5203 - val_accuracy: 0.8619\n",
      "Epoch 555/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9561 - val_loss: 0.6092 - val_accuracy: 0.8536\n",
      "Epoch 556/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9435 - val_loss: 0.5353 - val_accuracy: 0.8682\n",
      "Epoch 557/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.9480 - val_loss: 0.5048 - val_accuracy: 0.8661\n",
      "Epoch 558/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9587 - val_loss: 0.5269 - val_accuracy: 0.8598\n",
      "Epoch 559/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0786 - accuracy: 0.9641 - val_loss: 0.5810 - val_accuracy: 0.8577\n",
      "Epoch 560/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9462 - val_loss: 0.5052 - val_accuracy: 0.8598\n",
      "Epoch 561/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9578 - val_loss: 0.5238 - val_accuracy: 0.8598\n",
      "Epoch 562/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.9614 - val_loss: 0.4752 - val_accuracy: 0.8556\n",
      "Epoch 563/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0908 - accuracy: 0.9632 - val_loss: 0.4941 - val_accuracy: 0.8661\n",
      "Epoch 564/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9516 - val_loss: 0.5231 - val_accuracy: 0.8619\n",
      "Epoch 565/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9525 - val_loss: 0.5045 - val_accuracy: 0.8515\n",
      "Epoch 566/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.9632 - val_loss: 0.5970 - val_accuracy: 0.8556\n",
      "Epoch 567/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0878 - accuracy: 0.9561 - val_loss: 0.5662 - val_accuracy: 0.8682\n",
      "Epoch 568/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.9489 - val_loss: 0.5241 - val_accuracy: 0.8494\n",
      "Epoch 569/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0952 - accuracy: 0.9596 - val_loss: 0.5268 - val_accuracy: 0.8682\n",
      "Epoch 570/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1364 - accuracy: 0.9399 - val_loss: 0.4924 - val_accuracy: 0.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9570 - val_loss: 0.5085 - val_accuracy: 0.8598\n",
      "Epoch 572/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0990 - accuracy: 0.9659 - val_loss: 0.5434 - val_accuracy: 0.8619\n",
      "Epoch 573/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0932 - accuracy: 0.9587 - val_loss: 0.4554 - val_accuracy: 0.8536\n",
      "Epoch 574/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9525 - val_loss: 0.5256 - val_accuracy: 0.8682\n",
      "Epoch 575/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1041 - accuracy: 0.9534 - val_loss: 0.4526 - val_accuracy: 0.8640\n",
      "Epoch 576/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9587 - val_loss: 0.5073 - val_accuracy: 0.8661\n",
      "Epoch 577/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9543 - val_loss: 0.5232 - val_accuracy: 0.8703\n",
      "Epoch 578/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.9525 - val_loss: 0.4812 - val_accuracy: 0.8619\n",
      "Epoch 579/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9605 - val_loss: 0.4664 - val_accuracy: 0.8682\n",
      "Epoch 580/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9605 - val_loss: 0.5122 - val_accuracy: 0.8682\n",
      "Epoch 581/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.9632 - val_loss: 0.5848 - val_accuracy: 0.8640\n",
      "Epoch 582/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1269 - accuracy: 0.9525 - val_loss: 0.4532 - val_accuracy: 0.8431\n",
      "Epoch 583/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.9516 - val_loss: 0.4463 - val_accuracy: 0.8598\n",
      "Epoch 584/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9561 - val_loss: 0.4435 - val_accuracy: 0.8619\n",
      "Epoch 585/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9516 - val_loss: 0.4913 - val_accuracy: 0.8494\n",
      "Epoch 586/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9552 - val_loss: 0.5264 - val_accuracy: 0.8556\n",
      "Epoch 587/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.9632 - val_loss: 0.5440 - val_accuracy: 0.8619\n",
      "Epoch 588/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9543 - val_loss: 0.4068 - val_accuracy: 0.8703\n",
      "Epoch 589/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9525 - val_loss: 0.4264 - val_accuracy: 0.8640\n",
      "Epoch 590/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9596 - val_loss: 0.5206 - val_accuracy: 0.8661\n",
      "Epoch 591/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9570 - val_loss: 0.5625 - val_accuracy: 0.8556\n",
      "Epoch 592/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1003 - accuracy: 0.9587 - val_loss: 0.5123 - val_accuracy: 0.8556\n",
      "Epoch 593/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0782 - accuracy: 0.9614 - val_loss: 0.5019 - val_accuracy: 0.8619\n",
      "Epoch 594/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0925 - accuracy: 0.9534 - val_loss: 0.5752 - val_accuracy: 0.8577\n",
      "Epoch 595/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.9587 - val_loss: 0.5672 - val_accuracy: 0.8556\n",
      "Epoch 596/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0880 - accuracy: 0.9578 - val_loss: 0.5842 - val_accuracy: 0.8556\n",
      "Epoch 597/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0818 - accuracy: 0.9632 - val_loss: 0.6310 - val_accuracy: 0.8640\n",
      "Epoch 598/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9587 - val_loss: 0.5316 - val_accuracy: 0.8661\n",
      "Epoch 599/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9570 - val_loss: 0.5049 - val_accuracy: 0.8640\n",
      "Epoch 600/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9525 - val_loss: 0.4705 - val_accuracy: 0.8661\n",
      "Epoch 601/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9534 - val_loss: 0.4805 - val_accuracy: 0.8536\n",
      "Epoch 602/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9408 - val_loss: 0.4574 - val_accuracy: 0.8640\n",
      "Epoch 603/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0979 - accuracy: 0.9552 - val_loss: 0.5436 - val_accuracy: 0.8536\n",
      "Epoch 604/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0886 - accuracy: 0.9614 - val_loss: 0.4924 - val_accuracy: 0.8556\n",
      "Epoch 605/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0868 - accuracy: 0.9659 - val_loss: 0.5532 - val_accuracy: 0.8536\n",
      "Epoch 606/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.9543 - val_loss: 0.5741 - val_accuracy: 0.8577\n",
      "Epoch 607/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9570 - val_loss: 0.5202 - val_accuracy: 0.8619\n",
      "Epoch 608/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.9507 - val_loss: 0.5518 - val_accuracy: 0.8515\n",
      "Epoch 609/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9668 - val_loss: 0.5783 - val_accuracy: 0.8536\n",
      "Epoch 610/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9561 - val_loss: 0.5054 - val_accuracy: 0.8494\n",
      "Epoch 611/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0881 - accuracy: 0.9659 - val_loss: 0.5263 - val_accuracy: 0.8536\n",
      "Epoch 612/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0833 - accuracy: 0.9623 - val_loss: 0.6069 - val_accuracy: 0.8598\n",
      "Epoch 613/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0884 - accuracy: 0.9623 - val_loss: 0.4615 - val_accuracy: 0.8410\n",
      "Epoch 614/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.9498 - val_loss: 0.4463 - val_accuracy: 0.8577\n",
      "Epoch 615/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9587 - val_loss: 0.5434 - val_accuracy: 0.8368\n",
      "Epoch 616/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0943 - accuracy: 0.9605 - val_loss: 0.4960 - val_accuracy: 0.8494\n",
      "Epoch 617/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0889 - accuracy: 0.9623 - val_loss: 0.5039 - val_accuracy: 0.8452\n",
      "Epoch 618/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9552 - val_loss: 0.4426 - val_accuracy: 0.8598\n",
      "Epoch 619/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9480 - val_loss: 0.4314 - val_accuracy: 0.8682\n",
      "Epoch 620/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9480 - val_loss: 0.4982 - val_accuracy: 0.8577\n",
      "Epoch 621/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9498 - val_loss: 0.4534 - val_accuracy: 0.8494\n",
      "Epoch 622/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.9587 - val_loss: 0.4784 - val_accuracy: 0.8598\n",
      "Epoch 623/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.9507 - val_loss: 0.4587 - val_accuracy: 0.8682\n",
      "Epoch 624/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1026 - accuracy: 0.9605 - val_loss: 0.4762 - val_accuracy: 0.8598\n",
      "Epoch 625/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9623 - val_loss: 0.5068 - val_accuracy: 0.8556\n",
      "Epoch 626/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1003 - accuracy: 0.9650 - val_loss: 0.4704 - val_accuracy: 0.8556\n",
      "Epoch 627/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9525 - val_loss: 0.4340 - val_accuracy: 0.8515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0979 - accuracy: 0.9552 - val_loss: 0.4793 - val_accuracy: 0.8640\n",
      "Epoch 629/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9534 - val_loss: 0.4718 - val_accuracy: 0.8556\n",
      "Epoch 630/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1021 - accuracy: 0.9516 - val_loss: 0.4626 - val_accuracy: 0.8640\n",
      "Epoch 631/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.9623 - val_loss: 0.5213 - val_accuracy: 0.8577\n",
      "Epoch 632/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.9552 - val_loss: 0.4268 - val_accuracy: 0.8640\n",
      "Epoch 633/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1020 - accuracy: 0.9561 - val_loss: 0.4600 - val_accuracy: 0.8682\n",
      "Epoch 634/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0936 - accuracy: 0.9534 - val_loss: 0.4727 - val_accuracy: 0.8577\n",
      "Epoch 635/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9516 - val_loss: 0.4514 - val_accuracy: 0.8556\n",
      "Epoch 636/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1010 - accuracy: 0.9561 - val_loss: 0.4638 - val_accuracy: 0.8515\n",
      "Epoch 637/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9525 - val_loss: 0.4525 - val_accuracy: 0.8661\n",
      "Epoch 638/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9489 - val_loss: 0.4591 - val_accuracy: 0.8661\n",
      "Epoch 639/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9578 - val_loss: 0.4952 - val_accuracy: 0.8598\n",
      "Epoch 640/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1012 - accuracy: 0.9543 - val_loss: 0.4636 - val_accuracy: 0.8640\n",
      "Epoch 641/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0844 - accuracy: 0.9623 - val_loss: 0.5456 - val_accuracy: 0.8661\n",
      "Epoch 642/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0988 - accuracy: 0.9561 - val_loss: 0.5377 - val_accuracy: 0.8598\n",
      "Epoch 643/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9561 - val_loss: 0.4710 - val_accuracy: 0.8577\n",
      "Epoch 644/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.9534 - val_loss: 0.5070 - val_accuracy: 0.8682\n",
      "Epoch 645/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0807 - accuracy: 0.9632 - val_loss: 0.5448 - val_accuracy: 0.8640\n",
      "Epoch 646/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.9605 - val_loss: 0.5423 - val_accuracy: 0.8556\n",
      "Epoch 647/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0843 - accuracy: 0.9668 - val_loss: 0.5885 - val_accuracy: 0.8619\n",
      "Epoch 648/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9570 - val_loss: 0.5339 - val_accuracy: 0.8724\n",
      "Epoch 649/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0868 - accuracy: 0.9659 - val_loss: 0.5872 - val_accuracy: 0.8556\n",
      "Epoch 650/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9659 - val_loss: 0.5985 - val_accuracy: 0.8494\n",
      "Epoch 651/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.9650 - val_loss: 0.6932 - val_accuracy: 0.8473\n",
      "Epoch 652/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1004 - accuracy: 0.9534 - val_loss: 0.5315 - val_accuracy: 0.8619\n",
      "Epoch 653/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0739 - accuracy: 0.9713 - val_loss: 0.6171 - val_accuracy: 0.8703\n",
      "Epoch 654/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9614 - val_loss: 0.5307 - val_accuracy: 0.8640\n",
      "Epoch 655/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9596 - val_loss: 0.5754 - val_accuracy: 0.8661\n",
      "Epoch 656/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.9596 - val_loss: 0.4933 - val_accuracy: 0.8703\n",
      "Epoch 657/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0818 - accuracy: 0.9632 - val_loss: 0.5280 - val_accuracy: 0.8661\n",
      "Epoch 658/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0881 - accuracy: 0.9578 - val_loss: 0.5223 - val_accuracy: 0.8661\n",
      "Epoch 659/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9641 - val_loss: 0.6133 - val_accuracy: 0.8598\n",
      "Epoch 660/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9686 - val_loss: 0.5776 - val_accuracy: 0.8661\n",
      "Epoch 661/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9534 - val_loss: 0.5330 - val_accuracy: 0.8724\n",
      "Epoch 662/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0826 - accuracy: 0.9695 - val_loss: 0.5893 - val_accuracy: 0.8682\n",
      "Epoch 663/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.9570 - val_loss: 0.5468 - val_accuracy: 0.8389\n",
      "Epoch 664/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.9489 - val_loss: 0.4909 - val_accuracy: 0.8556\n",
      "Epoch 665/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0890 - accuracy: 0.9641 - val_loss: 0.5420 - val_accuracy: 0.8494\n",
      "Epoch 666/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9641 - val_loss: 0.5206 - val_accuracy: 0.8598\n",
      "Epoch 667/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0928 - accuracy: 0.9570 - val_loss: 0.5093 - val_accuracy: 0.8598\n",
      "Epoch 668/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9480 - val_loss: 0.4848 - val_accuracy: 0.8536\n",
      "Epoch 669/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 0.9650 - val_loss: 0.6203 - val_accuracy: 0.8598\n",
      "Epoch 670/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9632 - val_loss: 0.6021 - val_accuracy: 0.8577\n",
      "Epoch 671/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.9668 - val_loss: 0.5864 - val_accuracy: 0.8724\n",
      "Epoch 672/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0804 - accuracy: 0.9668 - val_loss: 0.6662 - val_accuracy: 0.8598\n",
      "Epoch 673/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9534 - val_loss: 0.5969 - val_accuracy: 0.8640\n",
      "Epoch 674/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0807 - accuracy: 0.9641 - val_loss: 0.5846 - val_accuracy: 0.8745\n",
      "Epoch 675/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0889 - accuracy: 0.9650 - val_loss: 0.5615 - val_accuracy: 0.8724\n",
      "Epoch 676/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9578 - val_loss: 0.5762 - val_accuracy: 0.8703\n",
      "Epoch 677/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9561 - val_loss: 0.5678 - val_accuracy: 0.8682\n",
      "Epoch 678/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.9668 - val_loss: 0.5972 - val_accuracy: 0.8556\n",
      "Epoch 679/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9570 - val_loss: 0.5710 - val_accuracy: 0.8577\n",
      "Epoch 680/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9641 - val_loss: 0.5656 - val_accuracy: 0.8703\n",
      "Epoch 681/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.9704 - val_loss: 0.6030 - val_accuracy: 0.8619\n",
      "Epoch 682/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1156 - accuracy: 0.9578 - val_loss: 0.5129 - val_accuracy: 0.8640\n",
      "Epoch 683/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1031 - accuracy: 0.9578 - val_loss: 0.5954 - val_accuracy: 0.8556\n",
      "Epoch 684/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0949 - accuracy: 0.9578 - val_loss: 0.5714 - val_accuracy: 0.8536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0746 - accuracy: 0.9659 - val_loss: 0.6112 - val_accuracy: 0.8556\n",
      "Epoch 686/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0927 - accuracy: 0.9596 - val_loss: 0.5474 - val_accuracy: 0.8536\n",
      "Epoch 687/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9561 - val_loss: 0.5493 - val_accuracy: 0.8556\n",
      "Epoch 688/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.9641 - val_loss: 0.5411 - val_accuracy: 0.8410\n",
      "Epoch 689/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9570 - val_loss: 0.5496 - val_accuracy: 0.8598\n",
      "Epoch 690/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9659 - val_loss: 0.5494 - val_accuracy: 0.8452\n",
      "Epoch 691/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9605 - val_loss: 0.4833 - val_accuracy: 0.8598\n",
      "Epoch 692/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0827 - accuracy: 0.9641 - val_loss: 0.5873 - val_accuracy: 0.8556\n",
      "Epoch 693/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0896 - accuracy: 0.9614 - val_loss: 0.6132 - val_accuracy: 0.8745\n",
      "Epoch 694/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.9641 - val_loss: 0.6228 - val_accuracy: 0.8556\n",
      "Epoch 695/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9435 - val_loss: 0.4074 - val_accuracy: 0.8598\n",
      "Epoch 696/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.9507 - val_loss: 0.4407 - val_accuracy: 0.8619\n",
      "Epoch 697/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9605 - val_loss: 0.5552 - val_accuracy: 0.8556\n",
      "Epoch 698/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0854 - accuracy: 0.9650 - val_loss: 0.5657 - val_accuracy: 0.8536\n",
      "Epoch 699/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0873 - accuracy: 0.9605 - val_loss: 0.5801 - val_accuracy: 0.8515\n",
      "Epoch 700/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0886 - accuracy: 0.9605 - val_loss: 0.5282 - val_accuracy: 0.8577\n",
      "Epoch 701/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.9704 - val_loss: 0.5790 - val_accuracy: 0.8640\n",
      "Epoch 702/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0851 - accuracy: 0.9605 - val_loss: 0.6205 - val_accuracy: 0.8515\n",
      "Epoch 703/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1012 - accuracy: 0.9570 - val_loss: 0.5191 - val_accuracy: 0.8556\n",
      "Epoch 704/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1368 - accuracy: 0.9534 - val_loss: 0.4447 - val_accuracy: 0.8661\n",
      "Epoch 705/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.9570 - val_loss: 0.5000 - val_accuracy: 0.8682\n",
      "Epoch 706/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9605 - val_loss: 0.5180 - val_accuracy: 0.8431\n",
      "Epoch 707/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9578 - val_loss: 0.5399 - val_accuracy: 0.8703\n",
      "Epoch 708/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0915 - accuracy: 0.9659 - val_loss: 0.5822 - val_accuracy: 0.8661\n",
      "Epoch 709/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9731 - val_loss: 0.5893 - val_accuracy: 0.8703\n",
      "Epoch 710/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0975 - accuracy: 0.9587 - val_loss: 0.5988 - val_accuracy: 0.8619\n",
      "Epoch 711/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9570 - val_loss: 0.5738 - val_accuracy: 0.8724\n",
      "Epoch 712/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.9713 - val_loss: 0.5849 - val_accuracy: 0.8682\n",
      "Epoch 713/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0864 - accuracy: 0.9632 - val_loss: 0.5405 - val_accuracy: 0.8682\n",
      "Epoch 714/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9561 - val_loss: 0.5044 - val_accuracy: 0.8703\n",
      "Epoch 715/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.9561 - val_loss: 0.5274 - val_accuracy: 0.8536\n",
      "Epoch 716/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.9605 - val_loss: 0.5613 - val_accuracy: 0.8682\n",
      "Epoch 717/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.9614 - val_loss: 0.5583 - val_accuracy: 0.8577\n",
      "Epoch 718/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9578 - val_loss: 0.5481 - val_accuracy: 0.8556\n",
      "Epoch 719/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.9641 - val_loss: 0.5617 - val_accuracy: 0.8640\n",
      "Epoch 720/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9641 - val_loss: 0.4835 - val_accuracy: 0.8619\n",
      "Epoch 721/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9578 - val_loss: 0.4640 - val_accuracy: 0.8577\n",
      "Epoch 722/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9552 - val_loss: 0.5035 - val_accuracy: 0.8682\n",
      "Epoch 723/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9749 - val_loss: 0.5339 - val_accuracy: 0.8556\n",
      "Epoch 724/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0890 - accuracy: 0.9614 - val_loss: 0.4601 - val_accuracy: 0.8577\n",
      "Epoch 725/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.9623 - val_loss: 0.5425 - val_accuracy: 0.8640\n",
      "Epoch 726/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9614 - val_loss: 0.4994 - val_accuracy: 0.8682\n",
      "Epoch 727/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.9462 - val_loss: 0.4474 - val_accuracy: 0.8619\n",
      "Epoch 728/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0840 - accuracy: 0.9561 - val_loss: 0.5299 - val_accuracy: 0.8703\n",
      "Epoch 729/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.9677 - val_loss: 0.5364 - val_accuracy: 0.8661\n",
      "Epoch 730/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0834 - accuracy: 0.9614 - val_loss: 0.5559 - val_accuracy: 0.8494\n",
      "Epoch 731/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0876 - accuracy: 0.9695 - val_loss: 0.5535 - val_accuracy: 0.8556\n",
      "Epoch 732/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9578 - val_loss: 0.5432 - val_accuracy: 0.8536\n",
      "Epoch 733/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0856 - accuracy: 0.9650 - val_loss: 0.5029 - val_accuracy: 0.8640\n",
      "Epoch 734/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9713 - val_loss: 0.5769 - val_accuracy: 0.8515\n",
      "Epoch 735/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9641 - val_loss: 0.4409 - val_accuracy: 0.8577\n",
      "Epoch 736/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9498 - val_loss: 0.4871 - val_accuracy: 0.8431\n",
      "Epoch 737/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1009 - accuracy: 0.9570 - val_loss: 0.5045 - val_accuracy: 0.8619\n",
      "Epoch 738/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9668 - val_loss: 0.5285 - val_accuracy: 0.8577\n",
      "Epoch 739/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9614 - val_loss: 0.4670 - val_accuracy: 0.8682\n",
      "Epoch 740/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0826 - accuracy: 0.9641 - val_loss: 0.5620 - val_accuracy: 0.8577\n",
      "Epoch 741/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9686 - val_loss: 0.5967 - val_accuracy: 0.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9713 - val_loss: 0.5694 - val_accuracy: 0.8515\n",
      "Epoch 743/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1015 - accuracy: 0.9587 - val_loss: 0.4827 - val_accuracy: 0.8556\n",
      "Epoch 744/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0799 - accuracy: 0.9623 - val_loss: 0.5781 - val_accuracy: 0.8640\n",
      "Epoch 745/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9650 - val_loss: 0.5335 - val_accuracy: 0.8682\n",
      "Epoch 746/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9821 - val_loss: 0.5885 - val_accuracy: 0.8661\n",
      "Epoch 747/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0852 - accuracy: 0.9695 - val_loss: 0.5871 - val_accuracy: 0.8661\n",
      "Epoch 748/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.9498 - val_loss: 0.4945 - val_accuracy: 0.8640\n",
      "Epoch 749/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9578 - val_loss: 0.5866 - val_accuracy: 0.8556\n",
      "Epoch 750/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9587 - val_loss: 0.5387 - val_accuracy: 0.8619\n",
      "Epoch 751/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0858 - accuracy: 0.9659 - val_loss: 0.5379 - val_accuracy: 0.8577\n",
      "Epoch 752/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 0.9677 - val_loss: 0.5428 - val_accuracy: 0.8515\n",
      "Epoch 753/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0980 - accuracy: 0.9632 - val_loss: 0.4926 - val_accuracy: 0.8640\n",
      "Epoch 754/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0924 - accuracy: 0.9623 - val_loss: 0.5036 - val_accuracy: 0.8536\n",
      "Epoch 755/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9498 - val_loss: 0.4699 - val_accuracy: 0.8661\n",
      "Epoch 756/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9578 - val_loss: 0.5597 - val_accuracy: 0.8682\n",
      "Epoch 757/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0878 - accuracy: 0.9641 - val_loss: 0.5544 - val_accuracy: 0.8724\n",
      "Epoch 758/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9570 - val_loss: 0.5413 - val_accuracy: 0.8640\n",
      "Epoch 759/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9704 - val_loss: 0.6535 - val_accuracy: 0.8536\n",
      "Epoch 760/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0849 - accuracy: 0.9650 - val_loss: 0.5676 - val_accuracy: 0.8682\n",
      "Epoch 761/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1037 - accuracy: 0.9587 - val_loss: 0.5386 - val_accuracy: 0.8536\n",
      "Epoch 762/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9605 - val_loss: 0.5608 - val_accuracy: 0.8661\n",
      "Epoch 763/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9623 - val_loss: 0.5544 - val_accuracy: 0.8598\n",
      "Epoch 764/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9650 - val_loss: 0.5897 - val_accuracy: 0.8640\n",
      "Epoch 765/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0890 - accuracy: 0.9596 - val_loss: 0.5431 - val_accuracy: 0.8640\n",
      "Epoch 766/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9614 - val_loss: 0.4916 - val_accuracy: 0.8640\n",
      "Epoch 767/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9713 - val_loss: 0.5553 - val_accuracy: 0.8682\n",
      "Epoch 768/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0657 - accuracy: 0.9767 - val_loss: 0.6219 - val_accuracy: 0.8619\n",
      "Epoch 769/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9632 - val_loss: 0.5399 - val_accuracy: 0.8640\n",
      "Epoch 770/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9695 - val_loss: 0.6209 - val_accuracy: 0.8682\n",
      "Epoch 771/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9722 - val_loss: 0.6127 - val_accuracy: 0.8661\n",
      "Epoch 772/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9641 - val_loss: 0.6253 - val_accuracy: 0.8682\n",
      "Epoch 773/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.9578 - val_loss: 0.4201 - val_accuracy: 0.8515\n",
      "Epoch 774/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0787 - accuracy: 0.9686 - val_loss: 0.5522 - val_accuracy: 0.8556\n",
      "Epoch 775/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9578 - val_loss: 0.4985 - val_accuracy: 0.8598\n",
      "Epoch 776/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9695 - val_loss: 0.5471 - val_accuracy: 0.8577\n",
      "Epoch 777/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9623 - val_loss: 0.5369 - val_accuracy: 0.8682\n",
      "Epoch 778/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 0.9704 - val_loss: 0.5483 - val_accuracy: 0.8577\n",
      "Epoch 779/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9596 - val_loss: 0.5520 - val_accuracy: 0.8724\n",
      "Epoch 780/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0854 - accuracy: 0.9605 - val_loss: 0.5694 - val_accuracy: 0.8577\n",
      "Epoch 781/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0771 - accuracy: 0.9641 - val_loss: 0.6029 - val_accuracy: 0.8682\n",
      "Epoch 782/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9650 - val_loss: 0.6080 - val_accuracy: 0.8619\n",
      "Epoch 783/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.9632 - val_loss: 0.5880 - val_accuracy: 0.8556\n",
      "Epoch 784/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0884 - accuracy: 0.9686 - val_loss: 0.5515 - val_accuracy: 0.8577\n",
      "Epoch 785/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0963 - accuracy: 0.9641 - val_loss: 0.5547 - val_accuracy: 0.8536\n",
      "Epoch 786/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0788 - accuracy: 0.9677 - val_loss: 0.5730 - val_accuracy: 0.8598\n",
      "Epoch 787/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9695 - val_loss: 0.5827 - val_accuracy: 0.8556\n",
      "Epoch 788/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9614 - val_loss: 0.5602 - val_accuracy: 0.8556\n",
      "Epoch 789/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.9632 - val_loss: 0.5455 - val_accuracy: 0.8724\n",
      "Epoch 790/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.9677 - val_loss: 0.6420 - val_accuracy: 0.8598\n",
      "Epoch 791/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9686 - val_loss: 0.5923 - val_accuracy: 0.8556\n",
      "Epoch 792/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9623 - val_loss: 0.5838 - val_accuracy: 0.8473\n",
      "Epoch 793/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0788 - accuracy: 0.9659 - val_loss: 0.5605 - val_accuracy: 0.8598\n",
      "Epoch 794/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9758 - val_loss: 0.6512 - val_accuracy: 0.8682\n",
      "Epoch 795/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9614 - val_loss: 0.5814 - val_accuracy: 0.8536\n",
      "Epoch 796/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9686 - val_loss: 0.7066 - val_accuracy: 0.8473\n",
      "Epoch 797/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0932 - accuracy: 0.9659 - val_loss: 0.5213 - val_accuracy: 0.8494\n",
      "Epoch 798/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 0.9623 - val_loss: 0.5248 - val_accuracy: 0.8515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.9785 - val_loss: 0.6964 - val_accuracy: 0.8536\n",
      "Epoch 800/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9668 - val_loss: 0.6975 - val_accuracy: 0.8473\n",
      "Epoch 801/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9570 - val_loss: 0.5566 - val_accuracy: 0.8661\n",
      "Epoch 802/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9659 - val_loss: 0.6586 - val_accuracy: 0.8661\n",
      "Epoch 803/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9704 - val_loss: 0.6318 - val_accuracy: 0.8556\n",
      "Epoch 804/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0817 - accuracy: 0.9632 - val_loss: 0.6102 - val_accuracy: 0.8661\n",
      "Epoch 805/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9668 - val_loss: 0.5792 - val_accuracy: 0.8661\n",
      "Epoch 806/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9713 - val_loss: 0.6703 - val_accuracy: 0.8515\n",
      "Epoch 807/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0718 - accuracy: 0.9704 - val_loss: 0.6879 - val_accuracy: 0.8326\n",
      "Epoch 808/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.9704 - val_loss: 0.6506 - val_accuracy: 0.8619\n",
      "Epoch 809/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.9722 - val_loss: 0.6863 - val_accuracy: 0.8536\n",
      "Epoch 810/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9561 - val_loss: 0.5498 - val_accuracy: 0.8598\n",
      "Epoch 811/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9641 - val_loss: 0.5215 - val_accuracy: 0.8640\n",
      "Epoch 812/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9561 - val_loss: 0.5643 - val_accuracy: 0.8431\n",
      "Epoch 813/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0817 - accuracy: 0.9677 - val_loss: 0.5980 - val_accuracy: 0.8640\n",
      "Epoch 814/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.9695 - val_loss: 0.6214 - val_accuracy: 0.8556\n",
      "Epoch 815/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9614 - val_loss: 0.5520 - val_accuracy: 0.8640\n",
      "Epoch 816/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9570 - val_loss: 0.5938 - val_accuracy: 0.8556\n",
      "Epoch 817/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9614 - val_loss: 0.5772 - val_accuracy: 0.8703\n",
      "Epoch 818/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9713 - val_loss: 0.6203 - val_accuracy: 0.8494\n",
      "Epoch 819/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9668 - val_loss: 0.6021 - val_accuracy: 0.8515\n",
      "Epoch 820/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9668 - val_loss: 0.6468 - val_accuracy: 0.8494\n",
      "Epoch 821/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9686 - val_loss: 0.6273 - val_accuracy: 0.8536\n",
      "Epoch 822/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9534 - val_loss: 0.5449 - val_accuracy: 0.8431\n",
      "Epoch 823/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0757 - accuracy: 0.9695 - val_loss: 0.5743 - val_accuracy: 0.8515\n",
      "Epoch 824/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0777 - accuracy: 0.9650 - val_loss: 0.5727 - val_accuracy: 0.8494\n",
      "Epoch 825/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0948 - accuracy: 0.9614 - val_loss: 0.5534 - val_accuracy: 0.8577\n",
      "Epoch 826/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 0.9704 - val_loss: 0.5855 - val_accuracy: 0.8536\n",
      "Epoch 827/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0734 - accuracy: 0.9713 - val_loss: 0.5342 - val_accuracy: 0.8431\n",
      "Epoch 828/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.9552 - val_loss: 0.5481 - val_accuracy: 0.8640\n",
      "Epoch 829/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.9632 - val_loss: 0.6086 - val_accuracy: 0.8577\n",
      "Epoch 830/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0778 - accuracy: 0.9668 - val_loss: 0.6101 - val_accuracy: 0.8494\n",
      "Epoch 831/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0951 - accuracy: 0.9614 - val_loss: 0.6142 - val_accuracy: 0.8326\n",
      "Epoch 832/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9498 - val_loss: 0.4611 - val_accuracy: 0.8598\n",
      "Epoch 833/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9677 - val_loss: 0.5819 - val_accuracy: 0.8473\n",
      "Epoch 834/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0878 - accuracy: 0.9650 - val_loss: 0.5989 - val_accuracy: 0.8556\n",
      "Epoch 835/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9668 - val_loss: 0.6019 - val_accuracy: 0.8452\n",
      "Epoch 836/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9561 - val_loss: 0.5678 - val_accuracy: 0.8515\n",
      "Epoch 837/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9668 - val_loss: 0.5327 - val_accuracy: 0.8347\n",
      "Epoch 838/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9650 - val_loss: 0.6418 - val_accuracy: 0.8515\n",
      "Epoch 839/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0787 - accuracy: 0.9695 - val_loss: 0.6125 - val_accuracy: 0.8494\n",
      "Epoch 840/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0782 - accuracy: 0.9686 - val_loss: 0.5531 - val_accuracy: 0.8326\n",
      "Epoch 841/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0768 - accuracy: 0.9596 - val_loss: 0.6266 - val_accuracy: 0.8515\n",
      "Epoch 842/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0861 - accuracy: 0.9632 - val_loss: 0.6267 - val_accuracy: 0.8640\n",
      "Epoch 843/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9659 - val_loss: 0.5506 - val_accuracy: 0.8640\n",
      "Epoch 844/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0933 - accuracy: 0.9552 - val_loss: 0.4564 - val_accuracy: 0.8619\n",
      "Epoch 845/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9632 - val_loss: 0.5618 - val_accuracy: 0.8536\n",
      "Epoch 846/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0880 - accuracy: 0.9587 - val_loss: 0.5426 - val_accuracy: 0.8577\n",
      "Epoch 847/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0713 - accuracy: 0.9749 - val_loss: 0.5918 - val_accuracy: 0.8640\n",
      "Epoch 848/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0585 - accuracy: 0.9758 - val_loss: 0.6592 - val_accuracy: 0.8577\n",
      "Epoch 849/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9731 - val_loss: 0.6309 - val_accuracy: 0.8347\n",
      "Epoch 850/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0892 - accuracy: 0.9578 - val_loss: 0.6065 - val_accuracy: 0.8368\n",
      "Epoch 851/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.9552 - val_loss: 0.5491 - val_accuracy: 0.8640\n",
      "Epoch 852/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0981 - accuracy: 0.9570 - val_loss: 0.5705 - val_accuracy: 0.8619\n",
      "Epoch 853/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9507 - val_loss: 0.5639 - val_accuracy: 0.8640\n",
      "Epoch 854/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9713 - val_loss: 0.6033 - val_accuracy: 0.8598\n",
      "Epoch 855/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0729 - accuracy: 0.9731 - val_loss: 0.6001 - val_accuracy: 0.8787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0739 - accuracy: 0.9695 - val_loss: 0.5754 - val_accuracy: 0.8556\n",
      "Epoch 857/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.9722 - val_loss: 0.6279 - val_accuracy: 0.8473\n",
      "Epoch 858/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9677 - val_loss: 0.6829 - val_accuracy: 0.8536\n",
      "Epoch 859/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9587 - val_loss: 0.5580 - val_accuracy: 0.8577\n",
      "Epoch 860/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9650 - val_loss: 0.5509 - val_accuracy: 0.8640\n",
      "Epoch 861/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9749 - val_loss: 0.6678 - val_accuracy: 0.8536\n",
      "Epoch 862/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0820 - accuracy: 0.9722 - val_loss: 0.5669 - val_accuracy: 0.8452\n",
      "Epoch 863/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9695 - val_loss: 0.5865 - val_accuracy: 0.8515\n",
      "Epoch 864/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0720 - accuracy: 0.9758 - val_loss: 0.6757 - val_accuracy: 0.8556\n",
      "Epoch 865/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9695 - val_loss: 0.6142 - val_accuracy: 0.8452\n",
      "Epoch 866/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0726 - accuracy: 0.9686 - val_loss: 0.5575 - val_accuracy: 0.8619\n",
      "Epoch 867/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0813 - accuracy: 0.9668 - val_loss: 0.5631 - val_accuracy: 0.8536\n",
      "Epoch 868/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9641 - val_loss: 0.6038 - val_accuracy: 0.8431\n",
      "Epoch 869/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0807 - accuracy: 0.9668 - val_loss: 0.6197 - val_accuracy: 0.8619\n",
      "Epoch 870/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9686 - val_loss: 0.7122 - val_accuracy: 0.8577\n",
      "Epoch 871/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 0.9749 - val_loss: 0.6538 - val_accuracy: 0.8515\n",
      "Epoch 872/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9695 - val_loss: 0.6927 - val_accuracy: 0.8494\n",
      "Epoch 873/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.9632 - val_loss: 0.6908 - val_accuracy: 0.8473\n",
      "Epoch 874/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9659 - val_loss: 0.6247 - val_accuracy: 0.8452\n",
      "Epoch 875/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9570 - val_loss: 0.5743 - val_accuracy: 0.8536\n",
      "Epoch 876/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.9749 - val_loss: 0.6606 - val_accuracy: 0.8494\n",
      "Epoch 877/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0464 - accuracy: 0.9857 - val_loss: 0.6583 - val_accuracy: 0.8494\n",
      "Epoch 878/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0705 - accuracy: 0.9686 - val_loss: 0.6621 - val_accuracy: 0.8515\n",
      "Epoch 879/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0825 - accuracy: 0.9596 - val_loss: 0.6878 - val_accuracy: 0.8536\n",
      "Epoch 880/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0815 - accuracy: 0.9677 - val_loss: 0.5817 - val_accuracy: 0.8494\n",
      "Epoch 881/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0821 - accuracy: 0.9668 - val_loss: 0.5568 - val_accuracy: 0.8473\n",
      "Epoch 882/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9632 - val_loss: 0.5653 - val_accuracy: 0.8473\n",
      "Epoch 883/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9543 - val_loss: 0.5403 - val_accuracy: 0.8556\n",
      "Epoch 884/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9632 - val_loss: 0.5974 - val_accuracy: 0.8640\n",
      "Epoch 885/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.9749 - val_loss: 0.5661 - val_accuracy: 0.8598\n",
      "Epoch 886/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9695 - val_loss: 0.5808 - val_accuracy: 0.8410\n",
      "Epoch 887/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0650 - accuracy: 0.9749 - val_loss: 0.6004 - val_accuracy: 0.8536\n",
      "Epoch 888/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0862 - accuracy: 0.9641 - val_loss: 0.6303 - val_accuracy: 0.8410\n",
      "Epoch 889/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0936 - accuracy: 0.9570 - val_loss: 0.5914 - val_accuracy: 0.8556\n",
      "Epoch 890/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9668 - val_loss: 0.5964 - val_accuracy: 0.8556\n",
      "Epoch 891/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0729 - accuracy: 0.9641 - val_loss: 0.6454 - val_accuracy: 0.8536\n",
      "Epoch 892/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9641 - val_loss: 0.5851 - val_accuracy: 0.8577\n",
      "Epoch 893/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0908 - accuracy: 0.9596 - val_loss: 0.5546 - val_accuracy: 0.8577\n",
      "Epoch 894/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0827 - accuracy: 0.9605 - val_loss: 0.6220 - val_accuracy: 0.8536\n",
      "Epoch 895/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0658 - accuracy: 0.9740 - val_loss: 0.6404 - val_accuracy: 0.8619\n",
      "Epoch 896/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0718 - accuracy: 0.9704 - val_loss: 0.6868 - val_accuracy: 0.8494\n",
      "Epoch 897/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9677 - val_loss: 0.6707 - val_accuracy: 0.8598\n",
      "Epoch 898/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.9695 - val_loss: 0.6562 - val_accuracy: 0.8536\n",
      "Epoch 899/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0891 - accuracy: 0.9561 - val_loss: 0.5389 - val_accuracy: 0.8577\n",
      "Epoch 900/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0675 - accuracy: 0.9722 - val_loss: 0.5971 - val_accuracy: 0.8619\n",
      "Epoch 901/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0755 - accuracy: 0.9704 - val_loss: 0.6063 - val_accuracy: 0.8577\n",
      "Epoch 902/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.9650 - val_loss: 0.6213 - val_accuracy: 0.8264\n",
      "Epoch 903/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0876 - accuracy: 0.9650 - val_loss: 0.5490 - val_accuracy: 0.8556\n",
      "Epoch 904/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0740 - accuracy: 0.9704 - val_loss: 0.5704 - val_accuracy: 0.8515\n",
      "Epoch 905/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0614 - accuracy: 0.9731 - val_loss: 0.6599 - val_accuracy: 0.8515\n",
      "Epoch 906/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0925 - accuracy: 0.9623 - val_loss: 0.5642 - val_accuracy: 0.8494\n",
      "Epoch 907/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9695 - val_loss: 0.6171 - val_accuracy: 0.8473\n",
      "Epoch 908/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0995 - accuracy: 0.9578 - val_loss: 0.5140 - val_accuracy: 0.8494\n",
      "Epoch 909/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0839 - accuracy: 0.9614 - val_loss: 0.5640 - val_accuracy: 0.8473\n",
      "Epoch 910/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.9695 - val_loss: 0.5640 - val_accuracy: 0.8556\n",
      "Epoch 911/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0758 - accuracy: 0.9704 - val_loss: 0.5788 - val_accuracy: 0.8536\n",
      "Epoch 912/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9758 - val_loss: 0.6637 - val_accuracy: 0.8598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0821 - accuracy: 0.9677 - val_loss: 0.6167 - val_accuracy: 0.8598\n",
      "Epoch 914/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0726 - accuracy: 0.9686 - val_loss: 0.5850 - val_accuracy: 0.8619\n",
      "Epoch 915/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0794 - accuracy: 0.9677 - val_loss: 0.5192 - val_accuracy: 0.8577\n",
      "Epoch 916/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0729 - accuracy: 0.9677 - val_loss: 0.5611 - val_accuracy: 0.8515\n",
      "Epoch 917/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.9704 - val_loss: 0.5932 - val_accuracy: 0.8536\n",
      "Epoch 918/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9704 - val_loss: 0.5886 - val_accuracy: 0.8577\n",
      "Epoch 919/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9839 - val_loss: 0.6884 - val_accuracy: 0.8577\n",
      "Epoch 920/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9704 - val_loss: 0.6388 - val_accuracy: 0.8410\n",
      "Epoch 921/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0693 - accuracy: 0.9758 - val_loss: 0.5968 - val_accuracy: 0.8598\n",
      "Epoch 922/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 0.9713 - val_loss: 0.6451 - val_accuracy: 0.8556\n",
      "Epoch 923/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0668 - accuracy: 0.9731 - val_loss: 0.6558 - val_accuracy: 0.8577\n",
      "Epoch 924/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0849 - accuracy: 0.9695 - val_loss: 0.5588 - val_accuracy: 0.8598\n",
      "Epoch 925/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9767 - val_loss: 0.6757 - val_accuracy: 0.8410\n",
      "Epoch 926/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0889 - accuracy: 0.9668 - val_loss: 0.6231 - val_accuracy: 0.8431\n",
      "Epoch 927/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0801 - accuracy: 0.9632 - val_loss: 0.6046 - val_accuracy: 0.8473\n",
      "Epoch 928/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0768 - accuracy: 0.9641 - val_loss: 0.6348 - val_accuracy: 0.8473\n",
      "Epoch 929/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9713 - val_loss: 0.6541 - val_accuracy: 0.8473\n",
      "Epoch 930/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.9650 - val_loss: 0.6217 - val_accuracy: 0.8494\n",
      "Epoch 931/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9686 - val_loss: 0.6121 - val_accuracy: 0.8661\n",
      "Epoch 932/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0635 - accuracy: 0.9740 - val_loss: 0.6923 - val_accuracy: 0.8598\n",
      "Epoch 933/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0925 - accuracy: 0.9641 - val_loss: 0.5665 - val_accuracy: 0.8661\n",
      "Epoch 934/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9623 - val_loss: 0.5482 - val_accuracy: 0.8577\n",
      "Epoch 935/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9650 - val_loss: 0.5643 - val_accuracy: 0.8577\n",
      "Epoch 936/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.9695 - val_loss: 0.6102 - val_accuracy: 0.8556\n",
      "Epoch 937/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9722 - val_loss: 0.5267 - val_accuracy: 0.8515\n",
      "Epoch 938/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9740 - val_loss: 0.5425 - val_accuracy: 0.8577\n",
      "Epoch 939/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0660 - accuracy: 0.9677 - val_loss: 0.6253 - val_accuracy: 0.8640\n",
      "Epoch 940/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0467 - accuracy: 0.9821 - val_loss: 0.7271 - val_accuracy: 0.8556\n",
      "Epoch 941/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 0.9677 - val_loss: 0.6178 - val_accuracy: 0.8368\n",
      "Epoch 942/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9659 - val_loss: 0.6084 - val_accuracy: 0.8556\n",
      "Epoch 943/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0699 - accuracy: 0.9677 - val_loss: 0.7032 - val_accuracy: 0.8536\n",
      "Epoch 944/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0890 - accuracy: 0.9623 - val_loss: 0.6080 - val_accuracy: 0.8556\n",
      "Epoch 945/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9740 - val_loss: 0.6083 - val_accuracy: 0.8389\n",
      "Epoch 946/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.9641 - val_loss: 0.6410 - val_accuracy: 0.8515\n",
      "Epoch 947/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9722 - val_loss: 0.6082 - val_accuracy: 0.8494\n",
      "Epoch 948/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0849 - accuracy: 0.9677 - val_loss: 0.5982 - val_accuracy: 0.8556\n",
      "Epoch 949/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0861 - accuracy: 0.9659 - val_loss: 0.6109 - val_accuracy: 0.8536\n",
      "Epoch 950/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.9695 - val_loss: 0.5905 - val_accuracy: 0.8515\n",
      "Epoch 951/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0647 - accuracy: 0.9740 - val_loss: 0.6353 - val_accuracy: 0.8640\n",
      "Epoch 952/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0828 - accuracy: 0.9731 - val_loss: 0.5172 - val_accuracy: 0.8598\n",
      "Epoch 953/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0840 - accuracy: 0.9641 - val_loss: 0.5087 - val_accuracy: 0.8536\n",
      "Epoch 954/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.9704 - val_loss: 0.5423 - val_accuracy: 0.8515\n",
      "Epoch 955/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0788 - accuracy: 0.9677 - val_loss: 0.5320 - val_accuracy: 0.8577\n",
      "Epoch 956/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0777 - accuracy: 0.9695 - val_loss: 0.5241 - val_accuracy: 0.8473\n",
      "Epoch 957/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0733 - accuracy: 0.9677 - val_loss: 0.6221 - val_accuracy: 0.8661\n",
      "Epoch 958/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 0.9650 - val_loss: 0.5351 - val_accuracy: 0.8536\n",
      "Epoch 959/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0673 - accuracy: 0.9695 - val_loss: 0.5820 - val_accuracy: 0.8640\n",
      "Epoch 960/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9704 - val_loss: 0.5228 - val_accuracy: 0.8515\n",
      "Epoch 961/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0758 - accuracy: 0.9695 - val_loss: 0.5965 - val_accuracy: 0.8598\n",
      "Epoch 962/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.9758 - val_loss: 0.6054 - val_accuracy: 0.8598\n",
      "Epoch 963/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9623 - val_loss: 0.5954 - val_accuracy: 0.8577\n",
      "Epoch 964/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.9713 - val_loss: 0.5551 - val_accuracy: 0.8473\n",
      "Epoch 965/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0768 - accuracy: 0.9695 - val_loss: 0.5203 - val_accuracy: 0.8556\n",
      "Epoch 966/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0695 - accuracy: 0.9722 - val_loss: 0.5810 - val_accuracy: 0.8536\n",
      "Epoch 967/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9749 - val_loss: 0.6381 - val_accuracy: 0.8452\n",
      "Epoch 968/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9686 - val_loss: 0.6306 - val_accuracy: 0.8494\n",
      "Epoch 969/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0903 - accuracy: 0.9632 - val_loss: 0.4881 - val_accuracy: 0.8661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0664 - accuracy: 0.9713 - val_loss: 0.5732 - val_accuracy: 0.8515\n",
      "Epoch 971/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9668 - val_loss: 0.5388 - val_accuracy: 0.8598\n",
      "Epoch 972/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9623 - val_loss: 0.5515 - val_accuracy: 0.8661\n",
      "Epoch 973/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0707 - accuracy: 0.9677 - val_loss: 0.6297 - val_accuracy: 0.8640\n",
      "Epoch 974/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0711 - accuracy: 0.9704 - val_loss: 0.5686 - val_accuracy: 0.8536\n",
      "Epoch 975/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0681 - accuracy: 0.9767 - val_loss: 0.5852 - val_accuracy: 0.8556\n",
      "Epoch 976/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9722 - val_loss: 0.5772 - val_accuracy: 0.8640\n",
      "Epoch 977/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0718 - accuracy: 0.9731 - val_loss: 0.5749 - val_accuracy: 0.8556\n",
      "Epoch 978/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 0.9758 - val_loss: 0.6621 - val_accuracy: 0.8494\n",
      "Epoch 979/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.9749 - val_loss: 0.5743 - val_accuracy: 0.8661\n",
      "Epoch 980/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0648 - accuracy: 0.9704 - val_loss: 0.5614 - val_accuracy: 0.8661\n",
      "Epoch 981/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9641 - val_loss: 0.5370 - val_accuracy: 0.8598\n",
      "Epoch 982/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.9722 - val_loss: 0.5532 - val_accuracy: 0.8619\n",
      "Epoch 983/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0685 - accuracy: 0.9740 - val_loss: 0.5628 - val_accuracy: 0.8640\n",
      "Epoch 984/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9740 - val_loss: 0.5651 - val_accuracy: 0.8682\n",
      "Epoch 985/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0740 - accuracy: 0.9704 - val_loss: 0.6256 - val_accuracy: 0.8619\n",
      "Epoch 986/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9794 - val_loss: 0.6377 - val_accuracy: 0.8515\n",
      "Epoch 987/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0517 - accuracy: 0.9785 - val_loss: 0.7366 - val_accuracy: 0.8640\n",
      "Epoch 988/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9552 - val_loss: 0.5778 - val_accuracy: 0.8473\n",
      "Epoch 989/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0692 - accuracy: 0.9722 - val_loss: 0.6314 - val_accuracy: 0.8494\n",
      "Epoch 990/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0753 - accuracy: 0.9668 - val_loss: 0.5492 - val_accuracy: 0.8494\n",
      "Epoch 991/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.9713 - val_loss: 0.5960 - val_accuracy: 0.8577\n",
      "Epoch 992/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0735 - accuracy: 0.9695 - val_loss: 0.5367 - val_accuracy: 0.8556\n",
      "Epoch 993/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.9758 - val_loss: 0.6024 - val_accuracy: 0.8556\n",
      "Epoch 994/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0621 - accuracy: 0.9740 - val_loss: 0.6526 - val_accuracy: 0.8556\n",
      "Epoch 995/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9686 - val_loss: 0.6573 - val_accuracy: 0.8431\n",
      "Epoch 996/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0976 - accuracy: 0.9659 - val_loss: 0.5558 - val_accuracy: 0.8473\n",
      "Epoch 997/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9605 - val_loss: 0.5625 - val_accuracy: 0.8389\n",
      "Epoch 998/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9731 - val_loss: 0.6284 - val_accuracy: 0.8598\n",
      "Epoch 999/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.9650 - val_loss: 0.6077 - val_accuracy: 0.8536\n",
      "Epoch 1000/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.0692 - accuracy: 0.9731 - val_loss: 0.6762 - val_accuracy: 0.8598\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               768       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               2176      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 30,850\n",
      "Trainable params: 30,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Las siguientes dos lineas se anhadieron luego de la presentacion del trabajo por recomendacion del Dr. Stalder\n",
    "from keras.callbacks      import EarlyStopping, Callback\n",
    "EarlyStopping(monitor='val_loss', patience=30, verbose=0)\n",
    "\n",
    "#Procedemos a entrenar al modelo\n",
    "history = model.fit(x_train, y_train, epochs=1000, batch_size=16, verbose=1, validation_split=0.3)\n",
    "\n",
    "model.summary()\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8049b1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/63 [..............................] - ETA: 0s - loss: 7.6246 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "63/63 [==============================] - 0s 635us/step - loss: 7.6453 - accuracy: 5.0201e-04\n",
      "[7.645313739776611, 0.0005020080134272575]\n",
      "['loss', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "#Se evalua el modelo\n",
    "\n",
    "print(model.evaluate(data, labels))\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47180214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Matriz de Confusion:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 76  26]\n",
      "  [ 24 273]]\n",
      "\n",
      " [[273  24]\n",
      "  [ 26  76]]]\n"
     ]
    }
   ],
   "source": [
    "#Creamos la matriz de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "#Una vez entrenado el modelo, se realizan las predicciones\n",
    "predictions=model.predict(x_test)\n",
    "\n",
    "predict_label = predictions.round()\n",
    "\n",
    "#Dimensiones de los datos que influyen en la matriz\n",
    "#print(np.shape(x_test))\n",
    "#print(np.shape(y_test))\n",
    "#print(np.shape(predictions))\n",
    "#print(np.shape(predict_label))\n",
    "\n",
    "#Creacion de la matriz\n",
    "matriz1=multilabel_confusion_matrix(y_test,predict_label)\n",
    "\n",
    "display('Matriz de Confusion:')\n",
    "print(matriz1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe20b300",
   "metadata": {},
   "source": [
    "Como se puede apreciar, se generaron dos matrices de confusion. La primera es la matriz que predijo que alumnos pasan la materia. La segunda es la matriz que predijo que alumnos no pasan la materia. A nosotros nos interesa solo la primera. Es necesario extraerla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aff2e98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 76  26]\n",
      " [ 24 273]]\n"
     ]
    }
   ],
   "source": [
    "#Extraemos una submatriz con los datos deseados\n",
    "M=matriz1\n",
    "\n",
    "#Convertimos la matriz creada en un array\n",
    "M=M.reshape(-1)\n",
    "\n",
    "#Eliminamos los elementos que no necesitamos\n",
    "M=np.delete(M,[4,5,6,7])\n",
    "#Redimensionamos para visualizar la matriz de confusion deseada\n",
    "M=M.reshape(2,2)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44857c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(color_codes=True)\n",
    "sns.heatmap(M, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60525dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo:  87.468671679198  %\n"
     ]
    }
   ],
   "source": [
    "#Ahora calculamos la exactitud del modelo, para ello, se importa la siguiente libreria\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud=accuracy_score(y_test,predict_label)*100\n",
    "print('Exactitud del modelo: ',exactitud,' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b96d4f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       297\n",
      "           1       0.76      0.75      0.75       102\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       399\n",
      "   macro avg       0.84      0.83      0.83       399\n",
      "weighted avg       0.87      0.87      0.87       399\n",
      " samples avg       0.87      0.87      0.87       399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report  \n",
    "reporte=classification_report(y_test, predict_label)\n",
    "print(reporte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db551e7a",
   "metadata": {},
   "source": [
    "Ahora que tenemos los resultados con el algoritmo genetico. Es necesario realizar el mismo estudio empleando una regresion logistica para poder compararlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1264aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estas librerias son necesarias para implementar la regresion logistica\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e06a23ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Matriz de Confusion:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[286  11]\n",
      " [ 25  77]]\n",
      "Exactitud del modelo:  90.97744360902256  %\n"
     ]
    }
   ],
   "source": [
    "#Se crea el modelo de regresion logaritmica\n",
    "logreg1 = LogisticRegression()\n",
    "\n",
    "logreg1.fit(x_train,yLR_train)\n",
    "\n",
    "y_pred=logreg1.predict(x_test)\n",
    "matriz1=confusion_matrix(yLR_test,y_pred)\n",
    "display('Matriz de Confusion:')\n",
    "print(matriz1)\n",
    "\n",
    "exactitudRL=accuracy_score(yLR_test,y_pred)*100\n",
    "print('Exactitud del modelo: ',exactitudRL,' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4640f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

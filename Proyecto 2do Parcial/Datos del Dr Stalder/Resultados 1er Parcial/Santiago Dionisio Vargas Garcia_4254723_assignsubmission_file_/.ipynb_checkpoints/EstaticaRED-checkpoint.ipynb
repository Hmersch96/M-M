{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWRMRBPjfo-r"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "VgOD8kKYf5in",
    "outputId": "ad96e04c-c631-4d3a-90f3-e26d477bdd2e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-e7722c96-996f-4b58-b56c-337105a5e70d\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-e7722c96-996f-4b58-b56c-337105a5e70d\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving DatosfiltradosII.csv to DatosfiltradosII.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qphE2Z5Eg1y1"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "df2 = pd.read_csv(io.BytesIO(uploaded['DatosfiltradosII.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtC2aELGhDWy"
   },
   "outputs": [],
   "source": [
    "data=df2\n",
    "data=data.drop(columns=['Cod.Car.Sec','Unnamed: 0','Nota.Final'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAi4R_pSnhGW"
   },
   "outputs": [],
   "source": [
    "data['Anho.Firma']=np.where(data['Anho.Firma']>0,1,data['Anho.Firma'])\n",
    "#for x in range(1897):\n",
    " #   data['Nota.Final'].values[x]= str(data['Nota.Final'].values[x]).split(\",\")[-1].split(\"-\")[-1]\n",
    "#data['Nota.Final']=np.where(data['Nota.Final']=='nan',0,data['Nota.Final'])\n",
    "#data['Nota.Final']=data['Nota.Final'].apply(pd.to_numeric) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAhYe0YjhdPe"
   },
   "outputs": [],
   "source": [
    "data_train, data_test, labels_train, labels_test = train_test_split(data.drop('Aprobado',axis=1),data['Aprobado'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BPNTpD6ehuGf",
    "outputId": "3465a94f-643f-496f-a87f-09f658f03d4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1517, 6)"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8K2xzUT2hv8"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(15, activation='linear' , input_shape=(6,), name = \"Capa_de_Entrada\"))\n",
    "model.add(Dense(5, activation='tanh'   , name = \"Capa_de_Oculta0\"))\n",
    "model.add(Dense(5, activation='relu'   , name = \"Capa_de_Oculta\"))\n",
    "model.add(Dense(2, activation='sigmoid', name = \"Capa_de_Salida\"))\n",
    "model.add(Dense(1, activation='softmax'   , name = \"Capa_de_Ocultaii\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxYrwFeQh0xl"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4IjnPwUjYFn",
    "outputId": "6ec5e5c6-3d6f-48ac-8fd0-f87d9e2514ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Capa_de_Entrada (Dense)      (None, 15)                105       \n",
      "_________________________________________________________________\n",
      "Capa_de_Oculta0 (Dense)      (None, 5)                 80        \n",
      "_________________________________________________________________\n",
      "Capa_de_Oculta (Dense)       (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "Capa_de_Salida (Dense)       (None, 2)                 12        \n",
      "_________________________________________________________________\n",
      "Capa_de_Ocultaii (Dense)     (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 230\n",
      "Trainable params: 230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WBOnoq-ajtni",
    "outputId": "d5d08a92-3a3e-47e8-b62b-443102dbdaaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "38/38 [==============================] - 1s 7ms/step - loss: 0.6445 - val_loss: 0.5610\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5877 - val_loss: 0.5451\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5821 - val_loss: 0.5324\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5701 - val_loss: 0.5214\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5433 - val_loss: 0.5132\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5494 - val_loss: 0.5030\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5285 - val_loss: 0.4941\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5516 - val_loss: 0.4865\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5103 - val_loss: 0.4822\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5217 - val_loss: 0.4773\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5079 - val_loss: 0.4673\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4689 - val_loss: 0.4653\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4863 - val_loss: 0.4557\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4930 - val_loss: 0.4504\n",
      "Epoch 15/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4738 - val_loss: 0.4444\n",
      "Epoch 16/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4736 - val_loss: 0.4417\n",
      "Epoch 17/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4667 - val_loss: 0.4365\n",
      "Epoch 18/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4454 - val_loss: 0.4284\n",
      "Epoch 19/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4510 - val_loss: 0.4235\n",
      "Epoch 20/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4497 - val_loss: 0.4232\n",
      "Epoch 21/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4394 - val_loss: 0.4091\n",
      "Epoch 22/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4060 - val_loss: 0.3995\n",
      "Epoch 23/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4180 - val_loss: 0.3995\n",
      "Epoch 24/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3809 - val_loss: 0.3943\n",
      "Epoch 25/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3852 - val_loss: 0.3976\n",
      "Epoch 26/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3951 - val_loss: 0.3869\n",
      "Epoch 27/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3930 - val_loss: 0.3890\n",
      "Epoch 28/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3619 - val_loss: 0.3939\n",
      "Epoch 29/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3764 - val_loss: 0.3832\n",
      "Epoch 30/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4003 - val_loss: 0.3874\n",
      "Epoch 31/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3761 - val_loss: 0.3783\n",
      "Epoch 32/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3935 - val_loss: 0.3778\n",
      "Epoch 33/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3686 - val_loss: 0.3909\n",
      "Epoch 34/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3943 - val_loss: 0.3832\n",
      "Epoch 35/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3593 - val_loss: 0.3787\n",
      "Epoch 36/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3502 - val_loss: 0.3807\n",
      "Epoch 37/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3820 - val_loss: 0.3739\n",
      "Epoch 38/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3707 - val_loss: 0.3717\n",
      "Epoch 39/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3573 - val_loss: 0.3774\n",
      "Epoch 40/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3629 - val_loss: 0.3737\n",
      "Epoch 41/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3644 - val_loss: 0.3763\n",
      "Epoch 42/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3727 - val_loss: 0.3769\n",
      "Epoch 43/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3781 - val_loss: 0.3790\n",
      "Epoch 44/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3867 - val_loss: 0.3704\n",
      "Epoch 45/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3866 - val_loss: 0.3783\n",
      "Epoch 46/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3529 - val_loss: 0.3797\n",
      "Epoch 47/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3725 - val_loss: 0.3787\n",
      "Epoch 48/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.3872\n",
      "Epoch 49/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3506 - val_loss: 0.3717\n",
      "Epoch 50/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3740 - val_loss: 0.3720\n",
      "Epoch 51/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3478 - val_loss: 0.4035\n",
      "Epoch 52/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3450 - val_loss: 0.3706\n",
      "Epoch 53/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3596 - val_loss: 0.3687\n",
      "Epoch 54/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3562 - val_loss: 0.3713\n",
      "Epoch 55/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3452 - val_loss: 0.3686\n",
      "Epoch 56/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3458 - val_loss: 0.3870\n",
      "Epoch 57/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3536 - val_loss: 0.3764\n",
      "Epoch 58/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3743 - val_loss: 0.3769\n",
      "Epoch 59/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3478 - val_loss: 0.3687\n",
      "Epoch 60/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3514 - val_loss: 0.3830\n",
      "Epoch 61/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3837 - val_loss: 0.3729\n",
      "Epoch 62/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3633 - val_loss: 0.3697\n",
      "Epoch 63/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3523 - val_loss: 0.3709\n",
      "Epoch 64/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3361 - val_loss: 0.3818\n",
      "Epoch 65/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3794 - val_loss: 0.3735\n",
      "Epoch 66/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3754 - val_loss: 0.3742\n",
      "Epoch 67/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3476 - val_loss: 0.3717\n",
      "Epoch 68/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3581 - val_loss: 0.3710\n",
      "Epoch 69/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3813 - val_loss: 0.3682\n",
      "Epoch 70/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3296 - val_loss: 0.3651\n",
      "Epoch 71/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3403 - val_loss: 0.3695\n",
      "Epoch 72/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3404 - val_loss: 0.3817\n",
      "Epoch 73/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3708 - val_loss: 0.3714\n",
      "Epoch 74/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3452 - val_loss: 0.3827\n",
      "Epoch 75/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3673 - val_loss: 0.3801\n",
      "Epoch 76/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3480 - val_loss: 0.3712\n",
      "Epoch 77/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3475 - val_loss: 0.3718\n",
      "Epoch 78/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3409 - val_loss: 0.3802\n",
      "Epoch 79/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3540 - val_loss: 0.3666\n",
      "Epoch 80/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3313 - val_loss: 0.3730\n",
      "Epoch 81/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3368 - val_loss: 0.3700\n",
      "Epoch 82/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3677 - val_loss: 0.3669\n",
      "Epoch 83/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3226 - val_loss: 0.3710\n",
      "Epoch 84/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3464 - val_loss: 0.3770\n",
      "Epoch 85/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3594 - val_loss: 0.3695\n",
      "Epoch 86/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3499 - val_loss: 0.3660\n",
      "Epoch 87/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3173 - val_loss: 0.3657\n",
      "Epoch 88/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3393 - val_loss: 0.3672\n",
      "Epoch 89/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3593 - val_loss: 0.3750\n",
      "Epoch 90/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3462 - val_loss: 0.3672\n",
      "Epoch 91/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3367 - val_loss: 0.3636\n",
      "Epoch 92/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3380 - val_loss: 0.3684\n",
      "Epoch 93/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3192 - val_loss: 0.3655\n",
      "Epoch 94/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3468 - val_loss: 0.3724\n",
      "Epoch 95/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3575 - val_loss: 0.3645\n",
      "Epoch 96/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3412 - val_loss: 0.3635\n",
      "Epoch 97/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3545 - val_loss: 0.3629\n",
      "Epoch 98/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3470 - val_loss: 0.3655\n",
      "Epoch 99/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3359 - val_loss: 0.3616\n",
      "Epoch 100/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3676 - val_loss: 0.3659\n",
      "Epoch 101/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3546 - val_loss: 0.3630\n",
      "Epoch 102/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3259 - val_loss: 0.3615\n",
      "Epoch 103/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3662 - val_loss: 0.3626\n",
      "Epoch 104/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3350 - val_loss: 0.3615\n",
      "Epoch 105/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3514 - val_loss: 0.3630\n",
      "Epoch 106/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3400 - val_loss: 0.3622\n",
      "Epoch 107/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3263 - val_loss: 0.3658\n",
      "Epoch 108/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3487 - val_loss: 0.3641\n",
      "Epoch 109/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3290 - val_loss: 0.3634\n",
      "Epoch 110/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3373 - val_loss: 0.3606\n",
      "Epoch 111/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3091 - val_loss: 0.3628\n",
      "Epoch 112/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3461 - val_loss: 0.3614\n",
      "Epoch 113/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3582 - val_loss: 0.3605\n",
      "Epoch 114/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3418 - val_loss: 0.3626\n",
      "Epoch 115/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3274 - val_loss: 0.3607\n",
      "Epoch 116/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3408 - val_loss: 0.3639\n",
      "Epoch 117/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3353 - val_loss: 0.3637\n",
      "Epoch 118/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3405 - val_loss: 0.3633\n",
      "Epoch 119/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3240 - val_loss: 0.3658\n",
      "Epoch 120/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3449 - val_loss: 0.3660\n",
      "Epoch 121/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3326 - val_loss: 0.3760\n",
      "Epoch 122/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3309 - val_loss: 0.3637\n",
      "Epoch 123/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3215 - val_loss: 0.3600\n",
      "Epoch 124/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3760 - val_loss: 0.3626\n",
      "Epoch 125/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3590 - val_loss: 0.3637\n",
      "Epoch 126/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3348 - val_loss: 0.3643\n",
      "Epoch 127/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3670 - val_loss: 0.3617\n",
      "Epoch 128/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3246 - val_loss: 0.3604\n",
      "Epoch 129/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3479 - val_loss: 0.3611\n",
      "Epoch 130/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3263 - val_loss: 0.3716\n",
      "Epoch 131/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3626 - val_loss: 0.3606\n",
      "Epoch 132/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3218 - val_loss: 0.3597\n",
      "Epoch 133/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3152 - val_loss: 0.3615\n",
      "Epoch 134/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.3637\n",
      "Epoch 135/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3510 - val_loss: 0.3612\n",
      "Epoch 136/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3202 - val_loss: 0.3621\n",
      "Epoch 137/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3409 - val_loss: 0.3690\n",
      "Epoch 138/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3567 - val_loss: 0.3584\n",
      "Epoch 139/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3298 - val_loss: 0.3607\n",
      "Epoch 140/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3145 - val_loss: 0.3614\n",
      "Epoch 141/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3264 - val_loss: 0.3633\n",
      "Epoch 142/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3097 - val_loss: 0.3616\n",
      "Epoch 143/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3417 - val_loss: 0.3604\n",
      "Epoch 144/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3329 - val_loss: 0.3600\n",
      "Epoch 145/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3229 - val_loss: 0.3624\n",
      "Epoch 146/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3091 - val_loss: 0.3683\n",
      "Epoch 147/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3478 - val_loss: 0.3601\n",
      "Epoch 148/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3466 - val_loss: 0.3605\n",
      "Epoch 149/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3426 - val_loss: 0.3620\n",
      "Epoch 150/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3251 - val_loss: 0.3645\n",
      "Epoch 151/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3265 - val_loss: 0.3609\n",
      "Epoch 152/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3193 - val_loss: 0.3641\n",
      "Epoch 153/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3227 - val_loss: 0.3660\n",
      "Epoch 154/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3598 - val_loss: 0.3604\n",
      "Epoch 155/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3314 - val_loss: 0.3711\n",
      "Epoch 156/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3452 - val_loss: 0.3632\n",
      "Epoch 157/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3166 - val_loss: 0.3645\n",
      "Epoch 158/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3602 - val_loss: 0.3702\n",
      "Epoch 159/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3332 - val_loss: 0.3612\n",
      "Epoch 160/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3206 - val_loss: 0.3719\n",
      "Epoch 161/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3154 - val_loss: 0.3594\n",
      "Epoch 162/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3472 - val_loss: 0.3645\n",
      "Epoch 163/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3559 - val_loss: 0.3662\n",
      "Epoch 164/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3436 - val_loss: 0.3657\n",
      "Epoch 165/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3397 - val_loss: 0.3601\n",
      "Epoch 166/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3228 - val_loss: 0.3614\n",
      "Epoch 167/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3204 - val_loss: 0.3603\n",
      "Epoch 168/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3501 - val_loss: 0.3571\n",
      "Epoch 169/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3427 - val_loss: 0.3636\n",
      "Epoch 170/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3192 - val_loss: 0.3622\n",
      "Epoch 171/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3142 - val_loss: 0.3632\n",
      "Epoch 172/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3392 - val_loss: 0.3623\n",
      "Epoch 173/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3297 - val_loss: 0.3592\n",
      "Epoch 174/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3052 - val_loss: 0.3688\n",
      "Epoch 175/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3193 - val_loss: 0.3611\n",
      "Epoch 176/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3207 - val_loss: 0.3636\n",
      "Epoch 177/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3729 - val_loss: 0.3597\n",
      "Epoch 178/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3353 - val_loss: 0.3591\n",
      "Epoch 179/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3318 - val_loss: 0.3575\n",
      "Epoch 180/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3170 - val_loss: 0.3610\n",
      "Epoch 181/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3461 - val_loss: 0.3609\n",
      "Epoch 182/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3518 - val_loss: 0.3588\n",
      "Epoch 183/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3357 - val_loss: 0.3573\n",
      "Epoch 184/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3088 - val_loss: 0.3605\n",
      "Epoch 185/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3158 - val_loss: 0.3557\n",
      "Epoch 186/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3477 - val_loss: 0.3638\n",
      "Epoch 187/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3173 - val_loss: 0.3558\n",
      "Epoch 188/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3299 - val_loss: 0.3568\n",
      "Epoch 189/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3238 - val_loss: 0.3531\n",
      "Epoch 190/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3259 - val_loss: 0.3540\n",
      "Epoch 191/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3265 - val_loss: 0.3520\n",
      "Epoch 192/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3317 - val_loss: 0.3524\n",
      "Epoch 193/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3122 - val_loss: 0.3534\n",
      "Epoch 194/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3179 - val_loss: 0.3575\n",
      "Epoch 195/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3465 - val_loss: 0.3576\n",
      "Epoch 196/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3164 - val_loss: 0.3490\n",
      "Epoch 197/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3342 - val_loss: 0.3546\n",
      "Epoch 198/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3480 - val_loss: 0.3418\n",
      "Epoch 199/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3240 - val_loss: 0.3479\n",
      "Epoch 200/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3404 - val_loss: 0.3411\n",
      "Epoch 201/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3372 - val_loss: 0.3459\n",
      "Epoch 202/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3397 - val_loss: 0.3402\n",
      "Epoch 203/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3351 - val_loss: 0.3364\n",
      "Epoch 204/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3056 - val_loss: 0.3451\n",
      "Epoch 205/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3217 - val_loss: 0.3365\n",
      "Epoch 206/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3458 - val_loss: 0.3365\n",
      "Epoch 207/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3297 - val_loss: 0.3368\n",
      "Epoch 208/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3057 - val_loss: 0.3311\n",
      "Epoch 209/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3159 - val_loss: 0.3283\n",
      "Epoch 210/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3227 - val_loss: 0.3279\n",
      "Epoch 211/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3103 - val_loss: 0.3312\n",
      "Epoch 212/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3239 - val_loss: 0.3264\n",
      "Epoch 213/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3186 - val_loss: 0.3290\n",
      "Epoch 214/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3142 - val_loss: 0.3321\n",
      "Epoch 215/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3044 - val_loss: 0.3278\n",
      "Epoch 216/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3042 - val_loss: 0.3262\n",
      "Epoch 217/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3162 - val_loss: 0.3233\n",
      "Epoch 218/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3148 - val_loss: 0.3213\n",
      "Epoch 219/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3195 - val_loss: 0.3228\n",
      "Epoch 220/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3116 - val_loss: 0.3228\n",
      "Epoch 221/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2940 - val_loss: 0.3238\n",
      "Epoch 222/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3243 - val_loss: 0.3261\n",
      "Epoch 223/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3204 - val_loss: 0.3206\n",
      "Epoch 224/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3194 - val_loss: 0.3213\n",
      "Epoch 225/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3206 - val_loss: 0.3208\n",
      "Epoch 226/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3173 - val_loss: 0.3239\n",
      "Epoch 227/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2881 - val_loss: 0.3231\n",
      "Epoch 228/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3327 - val_loss: 0.3226\n",
      "Epoch 229/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3100 - val_loss: 0.3219\n",
      "Epoch 230/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3166 - val_loss: 0.3175\n",
      "Epoch 231/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3072 - val_loss: 0.3263\n",
      "Epoch 232/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3432 - val_loss: 0.3198\n",
      "Epoch 233/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3472 - val_loss: 0.3289\n",
      "Epoch 234/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3065 - val_loss: 0.3336\n",
      "Epoch 235/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3217 - val_loss: 0.3184\n",
      "Epoch 236/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3081 - val_loss: 0.3190\n",
      "Epoch 237/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3104 - val_loss: 0.3233\n",
      "Epoch 238/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3042 - val_loss: 0.3175\n",
      "Epoch 239/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3147 - val_loss: 0.3169\n",
      "Epoch 240/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3117 - val_loss: 0.3157\n",
      "Epoch 241/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3144 - val_loss: 0.3245\n",
      "Epoch 242/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3232 - val_loss: 0.3121\n",
      "Epoch 243/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2982 - val_loss: 0.3225\n",
      "Epoch 244/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3210 - val_loss: 0.3165\n",
      "Epoch 245/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3083 - val_loss: 0.3181\n",
      "Epoch 246/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3136\n",
      "Epoch 247/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3214 - val_loss: 0.3294\n",
      "Epoch 248/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3296 - val_loss: 0.3141\n",
      "Epoch 249/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2933 - val_loss: 0.3184\n",
      "Epoch 250/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3122 - val_loss: 0.3144\n",
      "Epoch 251/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2995 - val_loss: 0.3208\n",
      "Epoch 252/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3378 - val_loss: 0.3225\n",
      "Epoch 253/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3229 - val_loss: 0.3196\n",
      "Epoch 254/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3248 - val_loss: 0.3139\n",
      "Epoch 255/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2981 - val_loss: 0.3163\n",
      "Epoch 256/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3059 - val_loss: 0.3146\n",
      "Epoch 257/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3180\n",
      "Epoch 258/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2850 - val_loss: 0.3277\n",
      "Epoch 259/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3319 - val_loss: 0.3229\n",
      "Epoch 260/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3047 - val_loss: 0.3126\n",
      "Epoch 261/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3058 - val_loss: 0.3339\n",
      "Epoch 262/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3362 - val_loss: 0.3096\n",
      "Epoch 263/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3060 - val_loss: 0.3089\n",
      "Epoch 264/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3162 - val_loss: 0.3275\n",
      "Epoch 265/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3194 - val_loss: 0.3086\n",
      "Epoch 266/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3164 - val_loss: 0.3159\n",
      "Epoch 267/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3473 - val_loss: 0.3138\n",
      "Epoch 268/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3236 - val_loss: 0.3101\n",
      "Epoch 269/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3299 - val_loss: 0.3184\n",
      "Epoch 270/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2940 - val_loss: 0.3152\n",
      "Epoch 271/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3158 - val_loss: 0.3187\n",
      "Epoch 272/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2925 - val_loss: 0.3255\n",
      "Epoch 273/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3149\n",
      "Epoch 274/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2887 - val_loss: 0.3155\n",
      "Epoch 275/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3315 - val_loss: 0.3240\n",
      "Epoch 276/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3026 - val_loss: 0.3169\n",
      "Epoch 277/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2789 - val_loss: 0.3188\n",
      "Epoch 278/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3071 - val_loss: 0.3091\n",
      "Epoch 279/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3060 - val_loss: 0.3199\n",
      "Epoch 280/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2881 - val_loss: 0.3112\n",
      "Epoch 281/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2828 - val_loss: 0.3122\n",
      "Epoch 282/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2887 - val_loss: 0.3076\n",
      "Epoch 283/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2887 - val_loss: 0.3119\n",
      "Epoch 284/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3096 - val_loss: 0.3068\n",
      "Epoch 285/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3101 - val_loss: 0.3068\n",
      "Epoch 286/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3389 - val_loss: 0.3127\n",
      "Epoch 287/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3190 - val_loss: 0.3121\n",
      "Epoch 288/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3211 - val_loss: 0.3090\n",
      "Epoch 289/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3146 - val_loss: 0.3046\n",
      "Epoch 290/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2954 - val_loss: 0.3090\n",
      "Epoch 291/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3099 - val_loss: 0.3196\n",
      "Epoch 292/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3291 - val_loss: 0.3066\n",
      "Epoch 293/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3074 - val_loss: 0.3093\n",
      "Epoch 294/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3223 - val_loss: 0.3150\n",
      "Epoch 295/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3135 - val_loss: 0.3184\n",
      "Epoch 296/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3079 - val_loss: 0.3046\n",
      "Epoch 297/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3109 - val_loss: 0.3058\n",
      "Epoch 298/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3150 - val_loss: 0.3165\n",
      "Epoch 299/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2688 - val_loss: 0.3057\n",
      "Epoch 300/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2902 - val_loss: 0.3095\n",
      "Epoch 301/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3133 - val_loss: 0.3005\n",
      "Epoch 302/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3107 - val_loss: 0.3093\n",
      "Epoch 303/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3148 - val_loss: 0.3095\n",
      "Epoch 304/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2858 - val_loss: 0.3118\n",
      "Epoch 305/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3122 - val_loss: 0.3020\n",
      "Epoch 306/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3185 - val_loss: 0.3116\n",
      "Epoch 307/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3042 - val_loss: 0.3116\n",
      "Epoch 308/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2751 - val_loss: 0.3080\n",
      "Epoch 309/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2882 - val_loss: 0.3208\n",
      "Epoch 310/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3057 - val_loss: 0.3017\n",
      "Epoch 311/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2987 - val_loss: 0.3116\n",
      "Epoch 312/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2655 - val_loss: 0.3124\n",
      "Epoch 313/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2955 - val_loss: 0.3143\n",
      "Epoch 314/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2755 - val_loss: 0.3048\n",
      "Epoch 315/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2986 - val_loss: 0.3185\n",
      "Epoch 316/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2992 - val_loss: 0.3022\n",
      "Epoch 317/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3070 - val_loss: 0.3097\n",
      "Epoch 318/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3038 - val_loss: 0.3066\n",
      "Epoch 319/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2898 - val_loss: 0.3121\n",
      "Epoch 320/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2713 - val_loss: 0.3206\n",
      "Epoch 321/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2953 - val_loss: 0.3274\n",
      "Epoch 322/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2840 - val_loss: 0.3016\n",
      "Epoch 323/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3068 - val_loss: 0.3098\n",
      "Epoch 324/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3110 - val_loss: 0.3048\n",
      "Epoch 325/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3269 - val_loss: 0.3017\n",
      "Epoch 326/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2940 - val_loss: 0.3031\n",
      "Epoch 327/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3049 - val_loss: 0.3313\n",
      "Epoch 328/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3044 - val_loss: 0.3079\n",
      "Epoch 329/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2782 - val_loss: 0.3157\n",
      "Epoch 330/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2857 - val_loss: 0.3065\n",
      "Epoch 331/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2868 - val_loss: 0.3233\n",
      "Epoch 332/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3102 - val_loss: 0.3028\n",
      "Epoch 333/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2978 - val_loss: 0.3003\n",
      "Epoch 334/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2817 - val_loss: 0.3078\n",
      "Epoch 335/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2877 - val_loss: 0.3211\n",
      "Epoch 336/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2712 - val_loss: 0.3172\n",
      "Epoch 337/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2879 - val_loss: 0.3083\n",
      "Epoch 338/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2791 - val_loss: 0.3154\n",
      "Epoch 339/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2726 - val_loss: 0.3025\n",
      "Epoch 340/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3060\n",
      "Epoch 341/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2976 - val_loss: 0.3194\n",
      "Epoch 342/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2780 - val_loss: 0.3256\n",
      "Epoch 343/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2981 - val_loss: 0.3145\n",
      "Epoch 344/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3325 - val_loss: 0.3149\n",
      "Epoch 345/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2746 - val_loss: 0.3073\n",
      "Epoch 346/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2858 - val_loss: 0.3132\n",
      "Epoch 347/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3147 - val_loss: 0.3060\n",
      "Epoch 348/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2883 - val_loss: 0.3049\n",
      "Epoch 349/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3123 - val_loss: 0.3170\n",
      "Epoch 350/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3161 - val_loss: 0.3245\n",
      "Epoch 351/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2871 - val_loss: 0.3099\n",
      "Epoch 352/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2952 - val_loss: 0.3108\n",
      "Epoch 353/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3136 - val_loss: 0.3110\n",
      "Epoch 354/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3025 - val_loss: 0.3306\n",
      "Epoch 355/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2823 - val_loss: 0.3007\n",
      "Epoch 356/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2870 - val_loss: 0.3073\n",
      "Epoch 357/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2907 - val_loss: 0.3058\n",
      "Epoch 358/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2817 - val_loss: 0.3153\n",
      "Epoch 359/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3032 - val_loss: 0.3078\n",
      "Epoch 360/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2941 - val_loss: 0.3143\n",
      "Epoch 361/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3080 - val_loss: 0.3074\n",
      "Epoch 362/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2820 - val_loss: 0.3085\n",
      "Epoch 363/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2874 - val_loss: 0.3234\n",
      "Epoch 364/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3198 - val_loss: 0.3179\n",
      "Epoch 365/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2830 - val_loss: 0.3161\n",
      "Epoch 366/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2943 - val_loss: 0.3141\n",
      "Epoch 367/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2888 - val_loss: 0.3039\n",
      "Epoch 368/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3105 - val_loss: 0.3039\n",
      "Epoch 369/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2744 - val_loss: 0.3178\n",
      "Epoch 370/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3224\n",
      "Epoch 371/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3104 - val_loss: 0.3125\n",
      "Epoch 372/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2983 - val_loss: 0.3202\n",
      "Epoch 373/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2719 - val_loss: 0.3104\n",
      "Epoch 374/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2893 - val_loss: 0.3081\n",
      "Epoch 375/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3059 - val_loss: 0.3058\n",
      "Epoch 376/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3333 - val_loss: 0.3222\n",
      "Epoch 377/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2987 - val_loss: 0.3026\n",
      "Epoch 378/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3090 - val_loss: 0.3101\n",
      "Epoch 379/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2749 - val_loss: 0.3006\n",
      "Epoch 380/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3168 - val_loss: 0.3073\n",
      "Epoch 381/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3118 - val_loss: 0.3128\n",
      "Epoch 382/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2994 - val_loss: 0.3052\n",
      "Epoch 383/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3032 - val_loss: 0.3053\n",
      "Epoch 384/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3171 - val_loss: 0.3049\n",
      "Epoch 385/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3443 - val_loss: 0.2982\n",
      "Epoch 386/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2960 - val_loss: 0.3097\n",
      "Epoch 387/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2948 - val_loss: 0.3098\n",
      "Epoch 388/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2831 - val_loss: 0.3213\n",
      "Epoch 389/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2861 - val_loss: 0.3023\n",
      "Epoch 390/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2988 - val_loss: 0.3072\n",
      "Epoch 391/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2983 - val_loss: 0.3150\n",
      "Epoch 392/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2981 - val_loss: 0.3159\n",
      "Epoch 393/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2633 - val_loss: 0.3009\n",
      "Epoch 394/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2977 - val_loss: 0.3209\n",
      "Epoch 395/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2934 - val_loss: 0.3012\n",
      "Epoch 396/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2847 - val_loss: 0.3156\n",
      "Epoch 397/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3110 - val_loss: 0.3342\n",
      "Epoch 398/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2729 - val_loss: 0.3046\n",
      "Epoch 399/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3085\n",
      "Epoch 400/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3096 - val_loss: 0.3045\n",
      "Epoch 401/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3026 - val_loss: 0.3295\n",
      "Epoch 402/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3114 - val_loss: 0.3191\n",
      "Epoch 403/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3099\n",
      "Epoch 404/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2986 - val_loss: 0.3198\n",
      "Epoch 405/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3014 - val_loss: 0.3128\n",
      "Epoch 406/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2751 - val_loss: 0.3016\n",
      "Epoch 407/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2881 - val_loss: 0.3065\n",
      "Epoch 408/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2801 - val_loss: 0.3219\n",
      "Epoch 409/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2760 - val_loss: 0.3146\n",
      "Epoch 410/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2971 - val_loss: 0.3113\n",
      "Epoch 411/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2861 - val_loss: 0.3162\n",
      "Epoch 412/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2688 - val_loss: 0.3219\n",
      "Epoch 413/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2766 - val_loss: 0.3133\n",
      "Epoch 414/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3167 - val_loss: 0.3012\n",
      "Epoch 415/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2864 - val_loss: 0.3094\n",
      "Epoch 416/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2922 - val_loss: 0.3182\n",
      "Epoch 417/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3160 - val_loss: 0.3273\n",
      "Epoch 418/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2818 - val_loss: 0.3072\n",
      "Epoch 419/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2923 - val_loss: 0.3011\n",
      "Epoch 420/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2916 - val_loss: 0.3051\n",
      "Epoch 421/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3051 - val_loss: 0.3241\n",
      "Epoch 422/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3099 - val_loss: 0.3112\n",
      "Epoch 423/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3118\n",
      "Epoch 424/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2876 - val_loss: 0.3206\n",
      "Epoch 425/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3348 - val_loss: 0.3099\n",
      "Epoch 426/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2782 - val_loss: 0.3016\n",
      "Epoch 427/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2895 - val_loss: 0.3029\n",
      "Epoch 428/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2756 - val_loss: 0.3057\n",
      "Epoch 429/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3092 - val_loss: 0.3068\n",
      "Epoch 430/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3031 - val_loss: 0.3075\n",
      "Epoch 431/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2913 - val_loss: 0.3217\n",
      "Epoch 432/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3080 - val_loss: 0.3143\n",
      "Epoch 433/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3033 - val_loss: 0.3231\n",
      "Epoch 434/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2836 - val_loss: 0.3147\n",
      "Epoch 435/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2738 - val_loss: 0.3246\n",
      "Epoch 436/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2909 - val_loss: 0.3144\n",
      "Epoch 437/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3029 - val_loss: 0.3087\n",
      "Epoch 438/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2745 - val_loss: 0.3084\n",
      "Epoch 439/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3035 - val_loss: 0.3036\n",
      "Epoch 440/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3145 - val_loss: 0.3059\n",
      "Epoch 441/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3035 - val_loss: 0.3080\n",
      "Epoch 442/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3085 - val_loss: 0.3018\n",
      "Epoch 443/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2957 - val_loss: 0.3276\n",
      "Epoch 444/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2884 - val_loss: 0.2988\n",
      "Epoch 445/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2762 - val_loss: 0.3160\n",
      "Epoch 446/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3310 - val_loss: 0.3118\n",
      "Epoch 447/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2939 - val_loss: 0.3174\n",
      "Epoch 448/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2753 - val_loss: 0.3140\n",
      "Epoch 449/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2745 - val_loss: 0.3079\n",
      "Epoch 450/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2710 - val_loss: 0.3280\n",
      "Epoch 451/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3179 - val_loss: 0.3048\n",
      "Epoch 452/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3212\n",
      "Epoch 453/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3076 - val_loss: 0.2998\n",
      "Epoch 454/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3034 - val_loss: 0.3066\n",
      "Epoch 455/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3121 - val_loss: 0.3273\n",
      "Epoch 456/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2969 - val_loss: 0.3341\n",
      "Epoch 457/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3034 - val_loss: 0.3374\n",
      "Epoch 458/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3142 - val_loss: 0.3004\n",
      "Epoch 459/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3044\n",
      "Epoch 460/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2944 - val_loss: 0.3064\n",
      "Epoch 461/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2854 - val_loss: 0.2998\n",
      "Epoch 462/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2774 - val_loss: 0.3034\n",
      "Epoch 463/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2808 - val_loss: 0.3095\n",
      "Epoch 464/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2917 - val_loss: 0.3031\n",
      "Epoch 465/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2909 - val_loss: 0.3024\n",
      "Epoch 466/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2879 - val_loss: 0.3160\n",
      "Epoch 467/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3118 - val_loss: 0.3055\n",
      "Epoch 468/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3073 - val_loss: 0.3147\n",
      "Epoch 469/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2817 - val_loss: 0.3231\n",
      "Epoch 470/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3023 - val_loss: 0.3220\n",
      "Epoch 471/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2881 - val_loss: 0.2991\n",
      "Epoch 472/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2902 - val_loss: 0.3108\n",
      "Epoch 473/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3173 - val_loss: 0.3385\n",
      "Epoch 474/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3394 - val_loss: 0.3003\n",
      "Epoch 475/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2942 - val_loss: 0.3132\n",
      "Epoch 476/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2575 - val_loss: 0.3060\n",
      "Epoch 477/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2759 - val_loss: 0.3112\n",
      "Epoch 478/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2975 - val_loss: 0.3002\n",
      "Epoch 479/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3116 - val_loss: 0.3253\n",
      "Epoch 480/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2784 - val_loss: 0.3049\n",
      "Epoch 481/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2845 - val_loss: 0.3179\n",
      "Epoch 482/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2855 - val_loss: 0.3044\n",
      "Epoch 483/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2967 - val_loss: 0.3072\n",
      "Epoch 484/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2867 - val_loss: 0.3091\n",
      "Epoch 485/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2903 - val_loss: 0.3060\n",
      "Epoch 486/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2848 - val_loss: 0.3074\n",
      "Epoch 487/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2751 - val_loss: 0.3060\n",
      "Epoch 488/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3059 - val_loss: 0.3146\n",
      "Epoch 489/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2888 - val_loss: 0.3156\n",
      "Epoch 490/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2851 - val_loss: 0.3065\n",
      "Epoch 491/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2681 - val_loss: 0.3162\n",
      "Epoch 492/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3039 - val_loss: 0.3246\n",
      "Epoch 493/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3107 - val_loss: 0.3253\n",
      "Epoch 494/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3061 - val_loss: 0.3265\n",
      "Epoch 495/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3069 - val_loss: 0.3258\n",
      "Epoch 496/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2795 - val_loss: 0.3053\n",
      "Epoch 497/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2879 - val_loss: 0.3223\n",
      "Epoch 498/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2991 - val_loss: 0.3038\n",
      "Epoch 499/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2737 - val_loss: 0.3105\n",
      "Epoch 500/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2934 - val_loss: 0.3051\n",
      "Epoch 501/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3002\n",
      "Epoch 502/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2809 - val_loss: 0.3285\n",
      "Epoch 503/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2865 - val_loss: 0.3052\n",
      "Epoch 504/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3068 - val_loss: 0.3038\n",
      "Epoch 505/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2926 - val_loss: 0.3060\n",
      "Epoch 506/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2723 - val_loss: 0.3293\n",
      "Epoch 507/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2679 - val_loss: 0.2997\n",
      "Epoch 508/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2912 - val_loss: 0.3091\n",
      "Epoch 509/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2980 - val_loss: 0.3292\n",
      "Epoch 510/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3102 - val_loss: 0.3142\n",
      "Epoch 511/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3090 - val_loss: 0.3098\n",
      "Epoch 512/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2848 - val_loss: 0.3096\n",
      "Epoch 513/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2758 - val_loss: 0.3178\n",
      "Epoch 514/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2894 - val_loss: 0.3140\n",
      "Epoch 515/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2795 - val_loss: 0.3128\n",
      "Epoch 516/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2966 - val_loss: 0.3024\n",
      "Epoch 517/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2772 - val_loss: 0.3098\n",
      "Epoch 518/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2863 - val_loss: 0.3082\n",
      "Epoch 519/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2866 - val_loss: 0.3381\n",
      "Epoch 520/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2926 - val_loss: 0.3272\n",
      "Epoch 521/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3072 - val_loss: 0.3279\n",
      "Epoch 522/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3025 - val_loss: 0.3065\n",
      "Epoch 523/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3045 - val_loss: 0.3005\n",
      "Epoch 524/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2824 - val_loss: 0.3300\n",
      "Epoch 525/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3168 - val_loss: 0.2996\n",
      "Epoch 526/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3073 - val_loss: 0.3068\n",
      "Epoch 527/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2711 - val_loss: 0.3025\n",
      "Epoch 528/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3215 - val_loss: 0.3190\n",
      "Epoch 529/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2942 - val_loss: 0.3037\n",
      "Epoch 530/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3054 - val_loss: 0.3117\n",
      "Epoch 531/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3155\n",
      "Epoch 532/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2873 - val_loss: 0.3147\n",
      "Epoch 533/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2878 - val_loss: 0.3084\n",
      "Epoch 534/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2919 - val_loss: 0.3181\n",
      "Epoch 535/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2844 - val_loss: 0.3047\n",
      "Epoch 536/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3021 - val_loss: 0.3073\n",
      "Epoch 537/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2960 - val_loss: 0.3076\n",
      "Epoch 538/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2824 - val_loss: 0.2979\n",
      "Epoch 539/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2714 - val_loss: 0.3076\n",
      "Epoch 540/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2821 - val_loss: 0.3116\n",
      "Epoch 541/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2944 - val_loss: 0.3020\n",
      "Epoch 542/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2914 - val_loss: 0.3149\n",
      "Epoch 543/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2824 - val_loss: 0.3291\n",
      "Epoch 544/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2980 - val_loss: 0.3075\n",
      "Epoch 545/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2886 - val_loss: 0.3012\n",
      "Epoch 546/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2983 - val_loss: 0.3086\n",
      "Epoch 547/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3085 - val_loss: 0.3121\n",
      "Epoch 548/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3094 - val_loss: 0.3223\n",
      "Epoch 549/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3073 - val_loss: 0.3168\n",
      "Epoch 550/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2729 - val_loss: 0.3159\n",
      "Epoch 551/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2665 - val_loss: 0.3036\n",
      "Epoch 552/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2948 - val_loss: 0.3109\n",
      "Epoch 553/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2976 - val_loss: 0.3131\n",
      "Epoch 554/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2986 - val_loss: 0.3111\n",
      "Epoch 555/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2677 - val_loss: 0.3030\n",
      "Epoch 556/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2961 - val_loss: 0.3268\n",
      "Epoch 557/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3033 - val_loss: 0.3192\n",
      "Epoch 558/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2945 - val_loss: 0.2983\n",
      "Epoch 559/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2896 - val_loss: 0.3172\n",
      "Epoch 560/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3037 - val_loss: 0.3018\n",
      "Epoch 561/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2988 - val_loss: 0.3089\n",
      "Epoch 562/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2716 - val_loss: 0.3079\n",
      "Epoch 563/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3058 - val_loss: 0.3036\n",
      "Epoch 564/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2741 - val_loss: 0.3160\n",
      "Epoch 565/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2943 - val_loss: 0.3297\n",
      "Epoch 566/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2882 - val_loss: 0.3059\n",
      "Epoch 567/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2821 - val_loss: 0.3109\n",
      "Epoch 568/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2891 - val_loss: 0.3360\n",
      "Epoch 569/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2959 - val_loss: 0.3115\n",
      "Epoch 570/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2844 - val_loss: 0.3135\n",
      "Epoch 571/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3039 - val_loss: 0.3059\n",
      "Epoch 572/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2835 - val_loss: 0.3001\n",
      "Epoch 573/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3210 - val_loss: 0.3060\n",
      "Epoch 574/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2997 - val_loss: 0.3128\n",
      "Epoch 575/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2791 - val_loss: 0.2965\n",
      "Epoch 576/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2827 - val_loss: 0.3070\n",
      "Epoch 577/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2702 - val_loss: 0.3024\n",
      "Epoch 578/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2744 - val_loss: 0.2967\n",
      "Epoch 579/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2726 - val_loss: 0.3077\n",
      "Epoch 580/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2929 - val_loss: 0.3004\n",
      "Epoch 581/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2876 - val_loss: 0.3112\n",
      "Epoch 582/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3088 - val_loss: 0.3150\n",
      "Epoch 583/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3032 - val_loss: 0.3003\n",
      "Epoch 584/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2984 - val_loss: 0.3137\n",
      "Epoch 585/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3092 - val_loss: 0.3127\n",
      "Epoch 586/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2945 - val_loss: 0.3111\n",
      "Epoch 587/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2750 - val_loss: 0.3009\n",
      "Epoch 588/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2798 - val_loss: 0.3058\n",
      "Epoch 589/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2914 - val_loss: 0.3057\n",
      "Epoch 590/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3052 - val_loss: 0.3194\n",
      "Epoch 591/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3088 - val_loss: 0.3116\n",
      "Epoch 592/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3167 - val_loss: 0.3181\n",
      "Epoch 593/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3108 - val_loss: 0.2984\n",
      "Epoch 594/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2865 - val_loss: 0.3072\n",
      "Epoch 595/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2976 - val_loss: 0.3017\n",
      "Epoch 596/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2929 - val_loss: 0.3243\n",
      "Epoch 597/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2950 - val_loss: 0.3121\n",
      "Epoch 598/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3146 - val_loss: 0.3000\n",
      "Epoch 599/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2799 - val_loss: 0.3197\n",
      "Epoch 600/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2934 - val_loss: 0.2977\n",
      "Epoch 601/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3018 - val_loss: 0.3023\n",
      "Epoch 602/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3118 - val_loss: 0.3016\n",
      "Epoch 603/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2889 - val_loss: 0.3138\n",
      "Epoch 604/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2946 - val_loss: 0.3081\n",
      "Epoch 605/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3189 - val_loss: 0.3171\n",
      "Epoch 606/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3031 - val_loss: 0.3111\n",
      "Epoch 607/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3052 - val_loss: 0.3060\n",
      "Epoch 608/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2791 - val_loss: 0.3212\n",
      "Epoch 609/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2964 - val_loss: 0.3299\n",
      "Epoch 610/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2930 - val_loss: 0.3073\n",
      "Epoch 611/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2998 - val_loss: 0.3013\n",
      "Epoch 612/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2879 - val_loss: 0.3329\n",
      "Epoch 613/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2935 - val_loss: 0.3135\n",
      "Epoch 614/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3052 - val_loss: 0.3068\n",
      "Epoch 615/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2724 - val_loss: 0.3096\n",
      "Epoch 616/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.2983\n",
      "Epoch 617/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2839 - val_loss: 0.3099\n",
      "Epoch 618/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3112 - val_loss: 0.3124\n",
      "Epoch 619/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3088 - val_loss: 0.2995\n",
      "Epoch 620/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2885 - val_loss: 0.3052\n",
      "Epoch 621/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2868 - val_loss: 0.2965\n",
      "Epoch 622/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2997 - val_loss: 0.3056\n",
      "Epoch 623/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2996 - val_loss: 0.3176\n",
      "Epoch 624/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3176 - val_loss: 0.3187\n",
      "Epoch 625/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2926 - val_loss: 0.3105\n",
      "Epoch 626/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2822 - val_loss: 0.3099\n",
      "Epoch 627/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3089 - val_loss: 0.3055\n",
      "Epoch 628/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2998 - val_loss: 0.3128\n",
      "Epoch 629/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2768 - val_loss: 0.3033\n",
      "Epoch 630/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3028 - val_loss: 0.3111\n",
      "Epoch 631/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2683 - val_loss: 0.3052\n",
      "Epoch 632/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2851 - val_loss: 0.3031\n",
      "Epoch 633/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2907 - val_loss: 0.3190\n",
      "Epoch 634/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2956 - val_loss: 0.3109\n",
      "Epoch 635/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2694 - val_loss: 0.3142\n",
      "Epoch 636/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2771 - val_loss: 0.3017\n",
      "Epoch 637/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3317 - val_loss: 0.3155\n",
      "Epoch 638/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3412 - val_loss: 0.3040\n",
      "Epoch 639/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3437 - val_loss: 0.3080\n",
      "Epoch 640/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3167 - val_loss: 0.3106\n",
      "Epoch 641/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2788 - val_loss: 0.3265\n",
      "Epoch 642/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2925 - val_loss: 0.3105\n",
      "Epoch 643/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2972 - val_loss: 0.2998\n",
      "Epoch 644/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2862 - val_loss: 0.2971\n",
      "Epoch 645/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2965 - val_loss: 0.3112\n",
      "Epoch 646/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2945 - val_loss: 0.3004\n",
      "Epoch 647/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2927 - val_loss: 0.3037\n",
      "Epoch 648/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2953 - val_loss: 0.3289\n",
      "Epoch 649/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2815 - val_loss: 0.2964\n",
      "Epoch 650/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2749 - val_loss: 0.3075\n",
      "Epoch 651/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2849 - val_loss: 0.3047\n",
      "Epoch 652/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2731 - val_loss: 0.2981\n",
      "Epoch 653/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2847 - val_loss: 0.3169\n",
      "Epoch 654/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2844 - val_loss: 0.3263\n",
      "Epoch 655/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2754 - val_loss: 0.3128\n",
      "Epoch 656/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2782 - val_loss: 0.3089\n",
      "Epoch 657/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2974 - val_loss: 0.3043\n",
      "Epoch 658/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2884 - val_loss: 0.3116\n",
      "Epoch 659/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2834 - val_loss: 0.3034\n",
      "Epoch 660/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2923 - val_loss: 0.3541\n",
      "Epoch 661/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3159 - val_loss: 0.3128\n",
      "Epoch 662/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2916 - val_loss: 0.3122\n",
      "Epoch 663/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3062 - val_loss: 0.3020\n",
      "Epoch 664/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2969 - val_loss: 0.3205\n",
      "Epoch 665/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2859 - val_loss: 0.3079\n",
      "Epoch 666/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3015 - val_loss: 0.3111\n",
      "Epoch 667/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2961 - val_loss: 0.3271\n",
      "Epoch 668/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2888 - val_loss: 0.3112\n",
      "Epoch 669/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2948 - val_loss: 0.3085\n",
      "Epoch 670/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2943 - val_loss: 0.3345\n",
      "Epoch 671/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2986 - val_loss: 0.3232\n",
      "Epoch 672/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2789 - val_loss: 0.3298\n",
      "Epoch 673/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2985 - val_loss: 0.3049\n",
      "Epoch 674/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2720 - val_loss: 0.3069\n",
      "Epoch 675/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2866 - val_loss: 0.2982\n",
      "Epoch 676/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2962 - val_loss: 0.3018\n",
      "Epoch 677/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3206 - val_loss: 0.2989\n",
      "Epoch 678/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2945 - val_loss: 0.3173\n",
      "Epoch 679/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3044 - val_loss: 0.3117\n",
      "Epoch 680/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3141 - val_loss: 0.3204\n",
      "Epoch 681/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3093 - val_loss: 0.3264\n",
      "Epoch 682/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2975 - val_loss: 0.3024\n",
      "Epoch 683/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2724 - val_loss: 0.3002\n",
      "Epoch 684/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2992 - val_loss: 0.3110\n",
      "Epoch 685/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3176 - val_loss: 0.3091\n",
      "Epoch 686/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2965 - val_loss: 0.3009\n",
      "Epoch 687/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2958 - val_loss: 0.3275\n",
      "Epoch 688/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2912 - val_loss: 0.3144\n",
      "Epoch 689/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2853 - val_loss: 0.2949\n",
      "Epoch 690/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3073 - val_loss: 0.3074\n",
      "Epoch 691/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2774 - val_loss: 0.3111\n",
      "Epoch 692/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3038 - val_loss: 0.3000\n",
      "Epoch 693/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2899 - val_loss: 0.2984\n",
      "Epoch 694/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2832 - val_loss: 0.3151\n",
      "Epoch 695/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2984 - val_loss: 0.3046\n",
      "Epoch 696/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3086 - val_loss: 0.3023\n",
      "Epoch 697/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3217 - val_loss: 0.3185\n",
      "Epoch 698/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2956 - val_loss: 0.3145\n",
      "Epoch 699/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2917 - val_loss: 0.3034\n",
      "Epoch 700/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2802 - val_loss: 0.3016\n",
      "Epoch 701/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2848 - val_loss: 0.3019\n",
      "Epoch 702/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2909 - val_loss: 0.3038\n",
      "Epoch 703/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3173 - val_loss: 0.3092\n",
      "Epoch 704/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3051 - val_loss: 0.3117\n",
      "Epoch 705/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3021 - val_loss: 0.3062\n",
      "Epoch 706/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2750 - val_loss: 0.3066\n",
      "Epoch 707/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2972 - val_loss: 0.3249\n",
      "Epoch 708/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2774 - val_loss: 0.3177\n",
      "Epoch 709/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2917 - val_loss: 0.3047\n",
      "Epoch 710/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3126 - val_loss: 0.3213\n",
      "Epoch 711/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3194 - val_loss: 0.3145\n",
      "Epoch 712/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2997 - val_loss: 0.3248\n",
      "Epoch 713/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2998 - val_loss: 0.3042\n",
      "Epoch 714/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3049 - val_loss: 0.3109\n",
      "Epoch 715/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3020 - val_loss: 0.3092\n",
      "Epoch 716/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2670 - val_loss: 0.3120\n",
      "Epoch 717/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3069 - val_loss: 0.3153\n",
      "Epoch 718/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.2941\n",
      "Epoch 719/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2990 - val_loss: 0.2967\n",
      "Epoch 720/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2781 - val_loss: 0.3031\n",
      "Epoch 721/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2890 - val_loss: 0.3005\n",
      "Epoch 722/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2764 - val_loss: 0.3106\n",
      "Epoch 723/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2980 - val_loss: 0.2973\n",
      "Epoch 724/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3043 - val_loss: 0.2997\n",
      "Epoch 725/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2684 - val_loss: 0.2979\n",
      "Epoch 726/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2697 - val_loss: 0.3062\n",
      "Epoch 727/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3026 - val_loss: 0.3247\n",
      "Epoch 728/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2733 - val_loss: 0.3030\n",
      "Epoch 729/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3074 - val_loss: 0.2998\n",
      "Epoch 730/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2935 - val_loss: 0.3002\n",
      "Epoch 731/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3083 - val_loss: 0.3077\n",
      "Epoch 732/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2995 - val_loss: 0.3041\n",
      "Epoch 733/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3244 - val_loss: 0.3068\n",
      "Epoch 734/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2879 - val_loss: 0.3108\n",
      "Epoch 735/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2672 - val_loss: 0.2970\n",
      "Epoch 736/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3082 - val_loss: 0.3097\n",
      "Epoch 737/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2978 - val_loss: 0.3137\n",
      "Epoch 738/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2833 - val_loss: 0.3246\n",
      "Epoch 739/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2895 - val_loss: 0.3041\n",
      "Epoch 740/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2995 - val_loss: 0.3024\n",
      "Epoch 741/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2853 - val_loss: 0.3219\n",
      "Epoch 742/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2686 - val_loss: 0.3213\n",
      "Epoch 743/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3132\n",
      "Epoch 744/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3036 - val_loss: 0.3259\n",
      "Epoch 745/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3087 - val_loss: 0.3115\n",
      "Epoch 746/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3016 - val_loss: 0.3043\n",
      "Epoch 747/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3263 - val_loss: 0.3080\n",
      "Epoch 748/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3021 - val_loss: 0.3046\n",
      "Epoch 749/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2918 - val_loss: 0.3065\n",
      "Epoch 750/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3234\n",
      "Epoch 751/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3035 - val_loss: 0.3309\n",
      "Epoch 752/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3083 - val_loss: 0.3108\n",
      "Epoch 753/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3108 - val_loss: 0.3219\n",
      "Epoch 754/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2881 - val_loss: 0.2986\n",
      "Epoch 755/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2931 - val_loss: 0.3021\n",
      "Epoch 756/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2792 - val_loss: 0.2967\n",
      "Epoch 757/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2843 - val_loss: 0.3094\n",
      "Epoch 758/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2860 - val_loss: 0.3037\n",
      "Epoch 759/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2805 - val_loss: 0.3080\n",
      "Epoch 760/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3025 - val_loss: 0.3171\n",
      "Epoch 761/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2913 - val_loss: 0.3151\n",
      "Epoch 762/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3115 - val_loss: 0.3187\n",
      "Epoch 763/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2579 - val_loss: 0.3065\n",
      "Epoch 764/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2862 - val_loss: 0.2973\n",
      "Epoch 765/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2761 - val_loss: 0.3068\n",
      "Epoch 766/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2975 - val_loss: 0.3240\n",
      "Epoch 767/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3155 - val_loss: 0.3182\n",
      "Epoch 768/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.2970\n",
      "Epoch 769/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2772 - val_loss: 0.3103\n",
      "Epoch 770/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2763 - val_loss: 0.3108\n",
      "Epoch 771/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2763 - val_loss: 0.3045\n",
      "Epoch 772/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3294 - val_loss: 0.2979\n",
      "Epoch 773/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2983 - val_loss: 0.3058\n",
      "Epoch 774/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2931 - val_loss: 0.3107\n",
      "Epoch 775/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2706 - val_loss: 0.3067\n",
      "Epoch 776/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2831 - val_loss: 0.2997\n",
      "Epoch 777/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2811 - val_loss: 0.3099\n",
      "Epoch 778/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2850 - val_loss: 0.3119\n",
      "Epoch 779/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2997 - val_loss: 0.3036\n",
      "Epoch 780/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2766 - val_loss: 0.3039\n",
      "Epoch 781/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2773 - val_loss: 0.3053\n",
      "Epoch 782/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2794 - val_loss: 0.3215\n",
      "Epoch 783/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3109\n",
      "Epoch 784/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2756 - val_loss: 0.3076\n",
      "Epoch 785/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2851 - val_loss: 0.3020\n",
      "Epoch 786/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2832 - val_loss: 0.3031\n",
      "Epoch 787/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2840 - val_loss: 0.2998\n",
      "Epoch 788/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2909 - val_loss: 0.3091\n",
      "Epoch 789/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2880 - val_loss: 0.3012\n",
      "Epoch 790/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2902 - val_loss: 0.3158\n",
      "Epoch 791/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3164 - val_loss: 0.3118\n",
      "Epoch 792/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2743 - val_loss: 0.3221\n",
      "Epoch 793/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2907 - val_loss: 0.3003\n",
      "Epoch 794/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2888 - val_loss: 0.2999\n",
      "Epoch 795/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3012\n",
      "Epoch 796/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2898 - val_loss: 0.3264\n",
      "Epoch 797/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3039 - val_loss: 0.2982\n",
      "Epoch 798/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2881 - val_loss: 0.3100\n",
      "Epoch 799/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3033 - val_loss: 0.3101\n",
      "Epoch 800/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3230 - val_loss: 0.3094\n",
      "Epoch 801/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3092 - val_loss: 0.2961\n",
      "Epoch 802/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3180 - val_loss: 0.3023\n",
      "Epoch 803/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2882 - val_loss: 0.3273\n",
      "Epoch 804/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2981 - val_loss: 0.3092\n",
      "Epoch 805/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3155 - val_loss: 0.3016\n",
      "Epoch 806/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2964 - val_loss: 0.3016\n",
      "Epoch 807/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2874 - val_loss: 0.3012\n",
      "Epoch 808/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.2967\n",
      "Epoch 809/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2932 - val_loss: 0.3080\n",
      "Epoch 810/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2703 - val_loss: 0.3330\n",
      "Epoch 811/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3147 - val_loss: 0.2965\n",
      "Epoch 812/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2768 - val_loss: 0.3034\n",
      "Epoch 813/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2690 - val_loss: 0.2961\n",
      "Epoch 814/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2909 - val_loss: 0.3053\n",
      "Epoch 815/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2824 - val_loss: 0.3104\n",
      "Epoch 816/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2918 - val_loss: 0.3010\n",
      "Epoch 817/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2862 - val_loss: 0.2986\n",
      "Epoch 818/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2929 - val_loss: 0.3037\n",
      "Epoch 819/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2935 - val_loss: 0.3038\n",
      "Epoch 820/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2996 - val_loss: 0.3036\n",
      "Epoch 821/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2830 - val_loss: 0.3074\n",
      "Epoch 822/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2957 - val_loss: 0.2988\n",
      "Epoch 823/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2787 - val_loss: 0.3066\n",
      "Epoch 824/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2711 - val_loss: 0.3021\n",
      "Epoch 825/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3059 - val_loss: 0.2961\n",
      "Epoch 826/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2885 - val_loss: 0.3108\n",
      "Epoch 827/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3037 - val_loss: 0.3179\n",
      "Epoch 828/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2849 - val_loss: 0.3098\n",
      "Epoch 829/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2976 - val_loss: 0.3037\n",
      "Epoch 830/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2814 - val_loss: 0.3173\n",
      "Epoch 831/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2951 - val_loss: 0.3047\n",
      "Epoch 832/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2916 - val_loss: 0.3029\n",
      "Epoch 833/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2816 - val_loss: 0.2983\n",
      "Epoch 834/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3135 - val_loss: 0.3096\n",
      "Epoch 835/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2948 - val_loss: 0.3065\n",
      "Epoch 836/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2717 - val_loss: 0.3194\n",
      "Epoch 837/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3135 - val_loss: 0.3085\n",
      "Epoch 838/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2803 - val_loss: 0.3013\n",
      "Epoch 839/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3049\n",
      "Epoch 840/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3113 - val_loss: 0.3135\n",
      "Epoch 841/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3236\n",
      "Epoch 842/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2982 - val_loss: 0.3052\n",
      "Epoch 843/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2802 - val_loss: 0.3023\n",
      "Epoch 844/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3011 - val_loss: 0.3083\n",
      "Epoch 845/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2739 - val_loss: 0.3103\n",
      "Epoch 846/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2979 - val_loss: 0.3019\n",
      "Epoch 847/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3066\n",
      "Epoch 848/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2856 - val_loss: 0.3018\n",
      "Epoch 849/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2857 - val_loss: 0.3181\n",
      "Epoch 850/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3096 - val_loss: 0.3091\n",
      "Epoch 851/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2878 - val_loss: 0.2976\n",
      "Epoch 852/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2913 - val_loss: 0.2977\n",
      "Epoch 853/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2958 - val_loss: 0.3025\n",
      "Epoch 854/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2998 - val_loss: 0.2991\n",
      "Epoch 855/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2923 - val_loss: 0.2986\n",
      "Epoch 856/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3079 - val_loss: 0.3094\n",
      "Epoch 857/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3239 - val_loss: 0.2964\n",
      "Epoch 858/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3120\n",
      "Epoch 859/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2724 - val_loss: 0.3025\n",
      "Epoch 860/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2775 - val_loss: 0.3067\n",
      "Epoch 861/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2979 - val_loss: 0.3006\n",
      "Epoch 862/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3041\n",
      "Epoch 863/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2759 - val_loss: 0.3008\n",
      "Epoch 864/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2983 - val_loss: 0.2988\n",
      "Epoch 865/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3084 - val_loss: 0.3074\n",
      "Epoch 866/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2831 - val_loss: 0.3245\n",
      "Epoch 867/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2987 - val_loss: 0.3071\n",
      "Epoch 868/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2851 - val_loss: 0.2983\n",
      "Epoch 869/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3023 - val_loss: 0.2980\n",
      "Epoch 870/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3070 - val_loss: 0.2975\n",
      "Epoch 871/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2762 - val_loss: 0.3094\n",
      "Epoch 872/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3019 - val_loss: 0.3071\n",
      "Epoch 873/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3029 - val_loss: 0.3281\n",
      "Epoch 874/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3081\n",
      "Epoch 875/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3033 - val_loss: 0.3219\n",
      "Epoch 876/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2810 - val_loss: 0.3056\n",
      "Epoch 877/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2753 - val_loss: 0.2999\n",
      "Epoch 878/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2947 - val_loss: 0.2990\n",
      "Epoch 879/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2961 - val_loss: 0.3342\n",
      "Epoch 880/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3149\n",
      "Epoch 881/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2793 - val_loss: 0.3033\n",
      "Epoch 882/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2977 - val_loss: 0.3054\n",
      "Epoch 883/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2954 - val_loss: 0.2967\n",
      "Epoch 884/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2824 - val_loss: 0.3059\n",
      "Epoch 885/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3108 - val_loss: 0.3138\n",
      "Epoch 886/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2647 - val_loss: 0.3037\n",
      "Epoch 887/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2764 - val_loss: 0.3123\n",
      "Epoch 888/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2881 - val_loss: 0.3106\n",
      "Epoch 889/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3109 - val_loss: 0.3237\n",
      "Epoch 890/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2941 - val_loss: 0.3184\n",
      "Epoch 891/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2837 - val_loss: 0.3113\n",
      "Epoch 892/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3045 - val_loss: 0.3016\n",
      "Epoch 893/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2866 - val_loss: 0.3038\n",
      "Epoch 894/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2655 - val_loss: 0.3040\n",
      "Epoch 895/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2863 - val_loss: 0.3075\n",
      "Epoch 896/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2895 - val_loss: 0.2948\n",
      "Epoch 897/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2841 - val_loss: 0.2985\n",
      "Epoch 898/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2823 - val_loss: 0.3035\n",
      "Epoch 899/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2793 - val_loss: 0.3122\n",
      "Epoch 900/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2750 - val_loss: 0.3036\n",
      "Epoch 901/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2914 - val_loss: 0.3079\n",
      "Epoch 902/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2754 - val_loss: 0.3271\n",
      "Epoch 903/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2844 - val_loss: 0.3425\n",
      "Epoch 904/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3275 - val_loss: 0.3174\n",
      "Epoch 905/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2968 - val_loss: 0.3064\n",
      "Epoch 906/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2925 - val_loss: 0.3002\n",
      "Epoch 907/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2767 - val_loss: 0.3010\n",
      "Epoch 908/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2720 - val_loss: 0.3286\n",
      "Epoch 909/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2991 - val_loss: 0.3077\n",
      "Epoch 910/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2759 - val_loss: 0.3171\n",
      "Epoch 911/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2969 - val_loss: 0.3030\n",
      "Epoch 912/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2947 - val_loss: 0.3207\n",
      "Epoch 913/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2855 - val_loss: 0.3103\n",
      "Epoch 914/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2988 - val_loss: 0.3029\n",
      "Epoch 915/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2746 - val_loss: 0.3021\n",
      "Epoch 916/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3067 - val_loss: 0.3127\n",
      "Epoch 917/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2761 - val_loss: 0.3000\n",
      "Epoch 918/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2622 - val_loss: 0.2966\n",
      "Epoch 919/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2797 - val_loss: 0.2978\n",
      "Epoch 920/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2856 - val_loss: 0.3246\n",
      "Epoch 921/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3041\n",
      "Epoch 922/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2810 - val_loss: 0.3117\n",
      "Epoch 923/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2845 - val_loss: 0.3034\n",
      "Epoch 924/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3098 - val_loss: 0.3116\n",
      "Epoch 925/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2922 - val_loss: 0.3003\n",
      "Epoch 926/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2825 - val_loss: 0.3066\n",
      "Epoch 927/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2633 - val_loss: 0.2986\n",
      "Epoch 928/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2852 - val_loss: 0.3106\n",
      "Epoch 929/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3069 - val_loss: 0.3146\n",
      "Epoch 930/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3069 - val_loss: 0.3002\n",
      "Epoch 931/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2773 - val_loss: 0.2991\n",
      "Epoch 932/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3155 - val_loss: 0.2989\n",
      "Epoch 933/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2952 - val_loss: 0.3101\n",
      "Epoch 934/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2782 - val_loss: 0.3324\n",
      "Epoch 935/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3112 - val_loss: 0.3145\n",
      "Epoch 936/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3084 - val_loss: 0.3051\n",
      "Epoch 937/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3159 - val_loss: 0.3011\n",
      "Epoch 938/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2889 - val_loss: 0.3117\n",
      "Epoch 939/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2979 - val_loss: 0.3054\n",
      "Epoch 940/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2856 - val_loss: 0.2996\n",
      "Epoch 941/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2881 - val_loss: 0.3041\n",
      "Epoch 942/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3131 - val_loss: 0.3067\n",
      "Epoch 943/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2720 - val_loss: 0.3026\n",
      "Epoch 944/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2847 - val_loss: 0.2977\n",
      "Epoch 945/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2920 - val_loss: 0.3006\n",
      "Epoch 946/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2793 - val_loss: 0.3007\n",
      "Epoch 947/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3061 - val_loss: 0.3133\n",
      "Epoch 948/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3324 - val_loss: 0.3060\n",
      "Epoch 949/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2730 - val_loss: 0.3074\n",
      "Epoch 950/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2969 - val_loss: 0.3011\n",
      "Epoch 951/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2961 - val_loss: 0.3122\n",
      "Epoch 952/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2610 - val_loss: 0.3035\n",
      "Epoch 953/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2801 - val_loss: 0.3033\n",
      "Epoch 954/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2826 - val_loss: 0.3150\n",
      "Epoch 955/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3193 - val_loss: 0.3034\n",
      "Epoch 956/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2947 - val_loss: 0.3046\n",
      "Epoch 957/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2852 - val_loss: 0.3112\n",
      "Epoch 958/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2824 - val_loss: 0.3024\n",
      "Epoch 959/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3149 - val_loss: 0.3108\n",
      "Epoch 960/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3117 - val_loss: 0.3155\n",
      "Epoch 961/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2810 - val_loss: 0.3081\n",
      "Epoch 962/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2931 - val_loss: 0.3095\n",
      "Epoch 963/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2789 - val_loss: 0.2994\n",
      "Epoch 964/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2850 - val_loss: 0.3011\n",
      "Epoch 965/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2796 - val_loss: 0.2971\n",
      "Epoch 966/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3038 - val_loss: 0.3051\n",
      "Epoch 967/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2784 - val_loss: 0.2964\n",
      "Epoch 968/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2974 - val_loss: 0.2938\n",
      "Epoch 969/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2920 - val_loss: 0.2975\n",
      "Epoch 970/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3065 - val_loss: 0.3064\n",
      "Epoch 971/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2783 - val_loss: 0.2959\n",
      "Epoch 972/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2953 - val_loss: 0.3016\n",
      "Epoch 973/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2774 - val_loss: 0.3095\n",
      "Epoch 974/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3142 - val_loss: 0.3078\n",
      "Epoch 975/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2700 - val_loss: 0.3221\n",
      "Epoch 976/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2737 - val_loss: 0.2989\n",
      "Epoch 977/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3013\n",
      "Epoch 978/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2906 - val_loss: 0.3000\n",
      "Epoch 979/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2923 - val_loss: 0.3126\n",
      "Epoch 980/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2812 - val_loss: 0.3010\n",
      "Epoch 981/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2982 - val_loss: 0.3032\n",
      "Epoch 982/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2849 - val_loss: 0.3041\n",
      "Epoch 983/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2985 - val_loss: 0.3001\n",
      "Epoch 984/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2972 - val_loss: 0.3010\n",
      "Epoch 985/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2793 - val_loss: 0.3051\n",
      "Epoch 986/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2665 - val_loss: 0.3015\n",
      "Epoch 987/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2822 - val_loss: 0.2944\n",
      "Epoch 988/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2861 - val_loss: 0.2969\n",
      "Epoch 989/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3067 - val_loss: 0.3085\n",
      "Epoch 990/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3258 - val_loss: 0.3000\n",
      "Epoch 991/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3130 - val_loss: 0.3066\n",
      "Epoch 992/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2900 - val_loss: 0.2950\n",
      "Epoch 993/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2918 - val_loss: 0.3035\n",
      "Epoch 994/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2987 - val_loss: 0.3102\n",
      "Epoch 995/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2851 - val_loss: 0.3020\n",
      "Epoch 996/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2841 - val_loss: 0.2973\n",
      "Epoch 997/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2766 - val_loss: 0.2992\n",
      "Epoch 998/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2700 - val_loss: 0.2955\n",
      "Epoch 999/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2683 - val_loss: 0.3068\n",
      "Epoch 1000/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2878 - val_loss: 0.2944\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Capa_de_Entrada (Dense)      (None, 15)                105       \n",
      "_________________________________________________________________\n",
      "Capa_de_Oculta0 (Dense)      (None, 5)                 80        \n",
      "_________________________________________________________________\n",
      "Capa_de_Oculta (Dense)       (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "Capa_de_Salida (Dense)       (None, 2)                 12        \n",
      "_________________________________________________________________\n",
      "Capa_de_Ocultaii (Dense)     (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 230\n",
      "Trainable params: 230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(data_train, labels_train, epochs=1000, batch_size=32, verbose=1, validation_split=0.2)\n",
    "model.summary()\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "coFKtRkXjxc-",
    "outputId": "ff0571a9-8ab5-4437-c1d7-6c1c808ebf74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2971\n",
      "0.2970607876777649\n",
      "['loss']\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(data.drop('Aprobado',axis=1),data['Aprobado']))\n",
    "print(model.metrics_names)\n",
    "predictions = model.predict(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGN0yQbvo1yG",
    "outputId": "d5754cd7-f0a9-4477-87ae-425e726dbb4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 235]\n",
      " [  0 145]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#y_pred=LogReg.predict(X_test)\n",
    "confusion_matrix = confusion_matrix(labels_test, predictions)\n",
    "print(confusion_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NRManREdFvpa",
    "outputId": "c27635ae-a53e-4856-e94e-b5cf6b8397d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de predicciones = (380,) \n",
      "\n",
      "[[  0 235]\n",
      " [  0 145]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report  \n",
    "\n",
    "predict_label = predictions.reshape(-1).round()\n",
    "\n",
    "print('Cantidad de predicciones = {} \\n'.format(predict_label.shape))\n",
    "\n",
    "cf_matrix = confusion_matrix(labels_test, predict_label)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dap4UIjqvsPK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "EstaticaRED.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

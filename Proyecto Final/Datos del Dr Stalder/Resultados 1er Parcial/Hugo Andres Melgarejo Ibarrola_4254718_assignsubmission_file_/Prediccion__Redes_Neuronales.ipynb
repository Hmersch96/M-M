{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX07Ttw7heV2"
   },
   "source": [
    "# Predicción sobre AL2-FIUNA\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Estudiantes:\n",
    "\n",
    "*   Marcos Ibañez\n",
    "*   Hugo Melgarejo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cc3mi16Bh6zR"
   },
   "source": [
    "# Importamos las librerias necesarias\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gPzimEl7h2E8"
   },
   "outputs": [],
   "source": [
    "#Importamos las librerias de pandas,numpy,matplotlib y sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#Sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.weightstats import ttest_ind\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "#Keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbTnNT-hhRdO"
   },
   "source": [
    "# Importamos nuestra base de datos desde Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "g8A16wPAhL4p"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/diegostaPy/cursoIA/main/datosRendimiento/datosfiltrados.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "VlMXm2GhiKnJ",
    "outputId": "3fc97e89-a272-4df6-be54-65252069080a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ix</th>\n",
       "      <th>Id</th>\n",
       "      <th>danho</th>\n",
       "      <th>ciclo</th>\n",
       "      <th>Cod.Asign</th>\n",
       "      <th>Asignatura</th>\n",
       "      <th>Cod.Car.Sec</th>\n",
       "      <th>Cod.Curso</th>\n",
       "      <th>Convocatoria</th>\n",
       "      <th>Anho</th>\n",
       "      <th>Semestre</th>\n",
       "      <th>Aprobado</th>\n",
       "      <th>Anho.Firma</th>\n",
       "      <th>Primer.Par</th>\n",
       "      <th>Segundo.Par</th>\n",
       "      <th>AOT</th>\n",
       "      <th>Primer.Rec</th>\n",
       "      <th>Segundo.Rec</th>\n",
       "      <th>Nota.Final</th>\n",
       "      <th>id_anony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135020</td>\n",
       "      <td>503</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>13008</td>\n",
       "      <td>CALCULO 2</td>\n",
       "      <td>ELE-PLS13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es_1444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135021</td>\n",
       "      <td>504</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>13008</td>\n",
       "      <td>CALCULO 2</td>\n",
       "      <td>CGF-PLS13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es_4238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135022</td>\n",
       "      <td>505</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>13008</td>\n",
       "      <td>CALCULO 2</td>\n",
       "      <td>ELE-PLS13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1F-1,2F-2</td>\n",
       "      <td>es_4245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135023</td>\n",
       "      <td>506</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>13008</td>\n",
       "      <td>CALCULO 2</td>\n",
       "      <td>CIV-PLS13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es_4967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135024</td>\n",
       "      <td>507</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>13008</td>\n",
       "      <td>CALCULO 2</td>\n",
       "      <td>CGF-PLS13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>2017</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3F-C-3</td>\n",
       "      <td>es_414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ix   Id  danho  ciclo  Cod.Asign Asignatura Cod.Car.Sec  Cod.Curso  \\\n",
       "0  135020  503   2017      1      13008  CALCULO 2  ELE-PLS13           2   \n",
       "1  135021  504   2017      1      13008  CALCULO 2  CGF-PLS13           2   \n",
       "2  135022  505   2017      1      13008  CALCULO 2  ELE-PLS13           2   \n",
       "3  135023  506   2017      1      13008  CALCULO 2  CIV-PLS13           2   \n",
       "4  135024  507   2017      1      13008  CALCULO 2  CGF-PLS13           2   \n",
       "\n",
       "   Convocatoria  Anho  Semestre Aprobado  Anho.Firma  Primer.Par  Segundo.Par  \\\n",
       "0             1  2017         1        N           0           7            0   \n",
       "1             1  2017         1        N           0           5            0   \n",
       "2             1  2017         1        S        2016           0            0   \n",
       "3             1  2017         1        N           0           0            0   \n",
       "4             1  2017         1        S        2017          21           10   \n",
       "\n",
       "   AOT  Primer.Rec  Segundo.Rec Nota.Final id_anony  \n",
       "0    0           0            0        NaN  es_1444  \n",
       "1    0           0            0        NaN  es_4238  \n",
       "2    0           0            0  1F-1,2F-2  es_4245  \n",
       "3    0           0            0        NaN  es_4967  \n",
       "4    0           0            0     3F-C-3   es_414  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylbwliUGizLZ"
   },
   "source": [
    "# Realizamos el pre-procesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuinSFe9kBgc"
   },
   "source": [
    "Reemplazamos la entrada aprobado que tiene valores S y N a 1 y 0, para realizar la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "kF3-0ekkiN2J",
    "outputId": "032adfde-86d7-4a2d-b69c-2269888e32d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ix</th>\n",
       "      <th>Id</th>\n",
       "      <th>danho</th>\n",
       "      <th>ciclo</th>\n",
       "      <th>Cod.Asign</th>\n",
       "      <th>Asignatura</th>\n",
       "      <th>Cod.Car.Sec</th>\n",
       "      <th>Cod.Curso</th>\n",
       "      <th>Convocatoria</th>\n",
       "      <th>Anho</th>\n",
       "      <th>Semestre</th>\n",
       "      <th>Aprobado</th>\n",
       "      <th>Anho.Firma</th>\n",
       "      <th>Primer.Par</th>\n",
       "      <th>Segundo.Par</th>\n",
       "      <th>AOT</th>\n",
       "      <th>Primer.Rec</th>\n",
       "      <th>Segundo.Rec</th>\n",
       "      <th>Nota.Final</th>\n",
       "      <th>id_anony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135020</td>\n",
       "      <td>503</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>13008</td>\n",
       "      <td>CALCULO 2</td>\n",
       "      <td>ELE-PLS13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es_1444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135021</td>\n",
       "      <td>504</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>13008</td>\n",
       "      <td>CALCULO 2</td>\n",
       "      <td>CGF-PLS13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es_4238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135022</td>\n",
       "      <td>505</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>13008</td>\n",
       "      <td>CALCULO 2</td>\n",
       "      <td>ELE-PLS13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1F-1,2F-2</td>\n",
       "      <td>es_4245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135023</td>\n",
       "      <td>506</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>13008</td>\n",
       "      <td>CALCULO 2</td>\n",
       "      <td>CIV-PLS13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es_4967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135024</td>\n",
       "      <td>507</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>13008</td>\n",
       "      <td>CALCULO 2</td>\n",
       "      <td>CGF-PLS13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3F-C-3</td>\n",
       "      <td>es_414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ix   Id  danho  ciclo  Cod.Asign Asignatura Cod.Car.Sec  Cod.Curso  \\\n",
       "0  135020  503   2017      1      13008  CALCULO 2  ELE-PLS13           2   \n",
       "1  135021  504   2017      1      13008  CALCULO 2  CGF-PLS13           2   \n",
       "2  135022  505   2017      1      13008  CALCULO 2  ELE-PLS13           2   \n",
       "3  135023  506   2017      1      13008  CALCULO 2  CIV-PLS13           2   \n",
       "4  135024  507   2017      1      13008  CALCULO 2  CGF-PLS13           2   \n",
       "\n",
       "   Convocatoria  Anho  Semestre  Aprobado  Anho.Firma  Primer.Par  \\\n",
       "0             1  2017         1         0           0           7   \n",
       "1             1  2017         1         0           0           5   \n",
       "2             1  2017         1         1        2016           0   \n",
       "3             1  2017         1         0           0           0   \n",
       "4             1  2017         1         1        2017          21   \n",
       "\n",
       "   Segundo.Par  AOT  Primer.Rec  Segundo.Rec Nota.Final id_anony  \n",
       "0            0    0           0            0        NaN  es_1444  \n",
       "1            0    0           0            0        NaN  es_4238  \n",
       "2            0    0           0            0  1F-1,2F-2  es_4245  \n",
       "3            0    0           0            0        NaN  es_4967  \n",
       "4           10    0           0            0     3F-C-3   es_414  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Aprobado'] = df['Aprobado'].replace(['S','N'],[1,0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbyvl4YckPAp"
   },
   "source": [
    "Separamos los campos referentes a la materia de interes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "-bVixNzYimHw",
    "outputId": "4cc34d7b-1f50-4dd5-ed78-600d50d65d83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ix</th>\n",
       "      <th>Id</th>\n",
       "      <th>danho</th>\n",
       "      <th>ciclo</th>\n",
       "      <th>Cod.Asign</th>\n",
       "      <th>Asignatura</th>\n",
       "      <th>Cod.Car.Sec</th>\n",
       "      <th>Cod.Curso</th>\n",
       "      <th>Convocatoria</th>\n",
       "      <th>Anho</th>\n",
       "      <th>Semestre</th>\n",
       "      <th>Aprobado</th>\n",
       "      <th>Anho.Firma</th>\n",
       "      <th>Primer.Par</th>\n",
       "      <th>Segundo.Par</th>\n",
       "      <th>AOT</th>\n",
       "      <th>Primer.Rec</th>\n",
       "      <th>Segundo.Rec</th>\n",
       "      <th>Nota.Final</th>\n",
       "      <th>id_anony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>135471</td>\n",
       "      <td>954</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>13009</td>\n",
       "      <td>ALGEBRA LINEAL 2</td>\n",
       "      <td>CIV-PLS13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es_4244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>135472</td>\n",
       "      <td>955</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>13009</td>\n",
       "      <td>ALGEBRA LINEAL 2</td>\n",
       "      <td>MCT-PLS13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es_1696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>135473</td>\n",
       "      <td>956</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>13009</td>\n",
       "      <td>ALGEBRA LINEAL 2</td>\n",
       "      <td>CGF-PLS13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es_4238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>135474</td>\n",
       "      <td>957</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>13009</td>\n",
       "      <td>ALGEBRA LINEAL 2</td>\n",
       "      <td>CIV-PLS13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es_4967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>135475</td>\n",
       "      <td>958</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>13009</td>\n",
       "      <td>ALGEBRA LINEAL 2</td>\n",
       "      <td>CIV-PLS13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2F-C-1,3F-C-1</td>\n",
       "      <td>es_4554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ix   Id  danho  ciclo  Cod.Asign        Asignatura Cod.Car.Sec  \\\n",
       "451  135471  954   2017      1      13009  ALGEBRA LINEAL 2  CIV-PLS13    \n",
       "452  135472  955   2017      1      13009  ALGEBRA LINEAL 2  MCT-PLS13    \n",
       "453  135473  956   2017      1      13009  ALGEBRA LINEAL 2  CGF-PLS13    \n",
       "454  135474  957   2017      1      13009  ALGEBRA LINEAL 2  CIV-PLS13    \n",
       "455  135475  958   2017      1      13009  ALGEBRA LINEAL 2  CIV-PLS13    \n",
       "\n",
       "     Cod.Curso  Convocatoria  Anho  Semestre  Aprobado  Anho.Firma  \\\n",
       "451          2             1  2017         1         0           0   \n",
       "452          2             1  2017         1         0           0   \n",
       "453          2             1  2017         1         0           0   \n",
       "454          2             1  2017         1         0           0   \n",
       "455          2             1  2017         1         0        2017   \n",
       "\n",
       "     Primer.Par  Segundo.Par  AOT  Primer.Rec  Segundo.Rec     Nota.Final  \\\n",
       "451           0            0    0           0            0            NaN   \n",
       "452           4           19    0           0            0            NaN   \n",
       "453           3            0    0           0            0            NaN   \n",
       "454           3            1    0           0            0            NaN   \n",
       "455           4           19    0           0            0  2F-C-1,3F-C-1   \n",
       "\n",
       "    id_anony  \n",
       "451  es_4244  \n",
       "452  es_1696  \n",
       "453  es_4238  \n",
       "454  es_4967  \n",
       "455  es_4554  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['Asignatura'] == 'ALGEBRA LINEAL 2']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "uVLzDUa0jK-R",
    "outputId": "03d10a4c-3543-4d76-b8c8-03473722e5ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primer.Par</th>\n",
       "      <th>Segundo.Par</th>\n",
       "      <th>Aprobado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15862</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15863</th>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15864</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15865</th>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15866</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2584 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Primer.Par  Segundo.Par  Aprobado\n",
       "451             0            0         0\n",
       "452             4           19         0\n",
       "453             3            0         0\n",
       "454             3            1         0\n",
       "455             4           19         0\n",
       "...           ...          ...       ...\n",
       "15862           4            0         0\n",
       "15863          18           29         1\n",
       "15864           7            0         0\n",
       "15865           7           18         0\n",
       "15866           6            0         0\n",
       "\n",
       "[2584 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Primer.Par','Segundo.Par','Aprobado']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef2seiHokfiV"
   },
   "source": [
    "A partir de ahora separamos los datos de interes como datos y etiquetas.\n",
    "\n",
    "Datos\n",
    "*   Primer Parcial\n",
    "*   Segundo Parcial\n",
    "\n",
    "\n",
    "Etiquetas:\n",
    "\n",
    "*   Aprobado\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "n3UTiiH-j6Ub"
   },
   "outputs": [],
   "source": [
    "X = df[['Primer.Par','Segundo.Par']].values\n",
    "Y = df[['Aprobado']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7fF4GBfnFLu"
   },
   "source": [
    "Ralizamos un gráfico para observar la situación y notamos que es posible realizar una frontera para clasificar a aprobados y reprobados, aunque la misma no será exacta siempre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "ks6sv0iWlEzs",
    "outputId": "b6aa082f-de39-4a6d-af14-ca058658236b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0],X[:,1],s=40,c=Y,cmap=plt.cm.Spectral)\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NTfn14erdTC"
   },
   "source": [
    "Separamos los datos en entrenamiento y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "U-noTOLmrpDc"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state = 1234,shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYlPOj9k04WX"
   },
   "source": [
    "Escalamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BtCfmLQ207_l"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "escalar = StandardScaler()\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tj2VpfOoAQ1"
   },
   "source": [
    "# Creamos la red neuronal con Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oM3UT4h5oswU"
   },
   "source": [
    "Ahora creamos la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3Wf0IntgoHu2"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, activation='linear',input_shape = (2,),name = \"Capa_de_Entrada\"))\n",
    "model.add(Dense(20,activation='relu', name=\"Capa_Oculta\"))\n",
    "model.add(Dense(1,activation = 'sigmoid',name = \"Capa_de_Salida\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1szmeF8p3m1"
   },
   "source": [
    "Configuramos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ayYEXl7Gp1gA",
    "outputId": "b925f6ee-7c5d-4dab-9eb6-be0c2e1ceadf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Capa_de_Entrada (Dense)      (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "Capa_Oculta (Dense)          (None, 20)                60        \n",
      "_________________________________________________________________\n",
      "Capa_de_Salida (Dense)       (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 87\n",
      "Trainable params: 87\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy',optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VYUSW9k8qErx",
    "outputId": "959baaac-8fdf-41d9-c8b6-ec74c820ed20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5617 - val_loss: 0.4889\n",
      "Epoch 2/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4971 - val_loss: 0.4357\n",
      "Epoch 3/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4676 - val_loss: 0.4089\n",
      "Epoch 4/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4500 - val_loss: 0.3923\n",
      "Epoch 5/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.3830\n",
      "Epoch 6/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4307 - val_loss: 0.3762\n",
      "Epoch 7/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4250 - val_loss: 0.3744\n",
      "Epoch 8/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.3721\n",
      "Epoch 9/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.3704\n",
      "Epoch 10/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4131 - val_loss: 0.3679\n",
      "Epoch 11/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4104 - val_loss: 0.3680\n",
      "Epoch 12/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4081 - val_loss: 0.3674\n",
      "Epoch 13/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.3670\n",
      "Epoch 14/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4047 - val_loss: 0.3655\n",
      "Epoch 15/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4034 - val_loss: 0.3676\n",
      "Epoch 16/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4025 - val_loss: 0.3644\n",
      "Epoch 17/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.3661\n",
      "Epoch 18/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4010 - val_loss: 0.3645\n",
      "Epoch 19/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4010 - val_loss: 0.3656\n",
      "Epoch 20/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4001 - val_loss: 0.3644\n",
      "Epoch 21/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3995 - val_loss: 0.3660\n",
      "Epoch 22/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3989 - val_loss: 0.3642\n",
      "Epoch 23/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3985 - val_loss: 0.3633\n",
      "Epoch 24/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3986 - val_loss: 0.3627\n",
      "Epoch 25/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3977 - val_loss: 0.3615\n",
      "Epoch 26/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3980 - val_loss: 0.3635\n",
      "Epoch 27/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3973 - val_loss: 0.3616\n",
      "Epoch 28/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3970 - val_loss: 0.3627\n",
      "Epoch 29/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3968 - val_loss: 0.3631\n",
      "Epoch 30/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3969 - val_loss: 0.3613\n",
      "Epoch 31/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3964 - val_loss: 0.3628\n",
      "Epoch 32/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3966 - val_loss: 0.3618\n",
      "Epoch 33/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.3614\n",
      "Epoch 34/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3957 - val_loss: 0.3613\n",
      "Epoch 35/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3962 - val_loss: 0.3611\n",
      "Epoch 36/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3949 - val_loss: 0.3588\n",
      "Epoch 37/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3950 - val_loss: 0.3606\n",
      "Epoch 38/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3949 - val_loss: 0.3586\n",
      "Epoch 39/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3945 - val_loss: 0.3597\n",
      "Epoch 40/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3943 - val_loss: 0.3596\n",
      "Epoch 41/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3940 - val_loss: 0.3595\n",
      "Epoch 42/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3946 - val_loss: 0.3596\n",
      "Epoch 43/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3942 - val_loss: 0.3576\n",
      "Epoch 44/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3936 - val_loss: 0.3593\n",
      "Epoch 45/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3933 - val_loss: 0.3592\n",
      "Epoch 46/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3931 - val_loss: 0.3572\n",
      "Epoch 47/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3933 - val_loss: 0.3585\n",
      "Epoch 48/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 0.3575\n",
      "Epoch 49/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3928 - val_loss: 0.3586\n",
      "Epoch 50/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3931 - val_loss: 0.3582\n",
      "Epoch 51/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3928 - val_loss: 0.3569\n",
      "Epoch 52/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3925 - val_loss: 0.3575\n",
      "Epoch 53/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3924 - val_loss: 0.3567\n",
      "Epoch 54/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3925 - val_loss: 0.3572\n",
      "Epoch 55/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3924 - val_loss: 0.3567\n",
      "Epoch 56/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3922 - val_loss: 0.3564\n",
      "Epoch 57/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3925 - val_loss: 0.3575\n",
      "Epoch 58/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3920 - val_loss: 0.3556\n",
      "Epoch 59/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3913 - val_loss: 0.3565\n",
      "Epoch 60/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3919 - val_loss: 0.3574\n",
      "Epoch 61/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3915 - val_loss: 0.3550\n",
      "Epoch 62/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3916 - val_loss: 0.3578\n",
      "Epoch 63/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3913 - val_loss: 0.3545\n",
      "Epoch 64/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3911 - val_loss: 0.3559\n",
      "Epoch 65/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3907 - val_loss: 0.3562\n",
      "Epoch 66/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3908 - val_loss: 0.3563\n",
      "Epoch 67/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3906 - val_loss: 0.3559\n",
      "Epoch 68/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3907 - val_loss: 0.3573\n",
      "Epoch 69/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3907 - val_loss: 0.3539\n",
      "Epoch 70/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3905 - val_loss: 0.3559\n",
      "Epoch 71/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3904 - val_loss: 0.3546\n",
      "Epoch 72/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3901 - val_loss: 0.3555\n",
      "Epoch 73/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3899 - val_loss: 0.3558\n",
      "Epoch 74/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3900 - val_loss: 0.3563\n",
      "Epoch 75/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3899 - val_loss: 0.3562\n",
      "Epoch 76/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3556\n",
      "Epoch 77/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.3560\n",
      "Epoch 78/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3555\n",
      "Epoch 79/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3560\n",
      "Epoch 80/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.3561\n",
      "Epoch 81/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.3546\n",
      "Epoch 82/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3893 - val_loss: 0.3542\n",
      "Epoch 83/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.3536\n",
      "Epoch 84/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.3544\n",
      "Epoch 85/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.3542\n",
      "Epoch 86/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3893 - val_loss: 0.3539\n",
      "Epoch 87/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3889 - val_loss: 0.3556\n",
      "Epoch 88/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3893 - val_loss: 0.3546\n",
      "Epoch 89/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3897 - val_loss: 0.3529\n",
      "Epoch 90/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3893 - val_loss: 0.3542\n",
      "Epoch 91/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3528\n",
      "Epoch 92/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3558\n",
      "Epoch 93/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3886 - val_loss: 0.3533\n",
      "Epoch 94/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.3527\n",
      "Epoch 95/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.3555\n",
      "Epoch 96/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3886 - val_loss: 0.3546\n",
      "Epoch 97/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3534\n",
      "Epoch 98/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.3541\n",
      "Epoch 99/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3886 - val_loss: 0.3549\n",
      "Epoch 100/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3888 - val_loss: 0.3548\n",
      "Epoch 101/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.3535\n",
      "Epoch 102/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.3547\n",
      "Epoch 103/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.3534\n",
      "Epoch 104/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.3532\n",
      "Epoch 105/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.3547\n",
      "Epoch 106/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3882 - val_loss: 0.3541\n",
      "Epoch 107/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.3534\n",
      "Epoch 108/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.3544\n",
      "Epoch 109/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.3546\n",
      "Epoch 110/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.3540\n",
      "Epoch 111/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.3542\n",
      "Epoch 112/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3882 - val_loss: 0.3547\n",
      "Epoch 113/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3884 - val_loss: 0.3529\n",
      "Epoch 114/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3882 - val_loss: 0.3530\n",
      "Epoch 115/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.3524\n",
      "Epoch 116/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3530\n",
      "Epoch 117/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.3545\n",
      "Epoch 118/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.3536\n",
      "Epoch 119/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.3531\n",
      "Epoch 120/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3878 - val_loss: 0.3526\n",
      "Epoch 121/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.3543\n",
      "Epoch 122/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3879 - val_loss: 0.3528\n",
      "Epoch 123/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.3544\n",
      "Epoch 124/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.3518\n",
      "Epoch 125/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.3532\n",
      "Epoch 126/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 0.3541\n",
      "Epoch 127/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.3537\n",
      "Epoch 128/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3875 - val_loss: 0.3539\n",
      "Epoch 129/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.3525\n",
      "Epoch 130/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.3531\n",
      "Epoch 131/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.3534\n",
      "Epoch 132/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3881 - val_loss: 0.3534\n",
      "Epoch 133/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.3530\n",
      "Epoch 134/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3874 - val_loss: 0.3530\n",
      "Epoch 135/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 0.3531\n",
      "Epoch 136/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3877 - val_loss: 0.3527\n",
      "Epoch 137/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 0.3524\n",
      "Epoch 138/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 0.3522\n",
      "Epoch 139/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.3516\n",
      "Epoch 140/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3879 - val_loss: 0.3537\n",
      "Epoch 141/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3874 - val_loss: 0.3525\n",
      "Epoch 142/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3874 - val_loss: 0.3534\n",
      "Epoch 143/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3873 - val_loss: 0.3532\n",
      "Epoch 144/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3873 - val_loss: 0.3522\n",
      "Epoch 145/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 0.3543\n",
      "Epoch 146/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3873 - val_loss: 0.3525\n",
      "Epoch 147/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3874 - val_loss: 0.3528\n",
      "Epoch 148/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.3530\n",
      "Epoch 149/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.3526\n",
      "Epoch 150/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3877 - val_loss: 0.3515\n",
      "Epoch 151/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3874 - val_loss: 0.3535\n",
      "Epoch 152/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3873 - val_loss: 0.3519\n",
      "Epoch 153/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.3534\n",
      "Epoch 154/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3871 - val_loss: 0.3513\n",
      "Epoch 155/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.3524\n",
      "Epoch 156/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.3514\n",
      "Epoch 157/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3873 - val_loss: 0.3535\n",
      "Epoch 158/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3871 - val_loss: 0.3521\n",
      "Epoch 159/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.3533\n",
      "Epoch 160/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.3519\n",
      "Epoch 161/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3874 - val_loss: 0.3520\n",
      "Epoch 162/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.3523\n",
      "Epoch 163/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3871 - val_loss: 0.3517\n",
      "Epoch 164/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.3525\n",
      "Epoch 165/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3869 - val_loss: 0.3520\n",
      "Epoch 166/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 0.3524\n",
      "Epoch 167/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.387 - 0s 2ms/step - loss: 0.3871 - val_loss: 0.3530\n",
      "Epoch 168/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3871 - val_loss: 0.3523\n",
      "Epoch 169/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3871 - val_loss: 0.3516\n",
      "Epoch 170/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.3526\n",
      "Epoch 171/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3873 - val_loss: 0.3521\n",
      "Epoch 172/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 0.3507\n",
      "Epoch 173/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.3515\n",
      "Epoch 174/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3868 - val_loss: 0.3528\n",
      "Epoch 175/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3870 - val_loss: 0.3519\n",
      "Epoch 176/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3871 - val_loss: 0.3520\n",
      "Epoch 177/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3871 - val_loss: 0.3520\n",
      "Epoch 178/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3869 - val_loss: 0.3524\n",
      "Epoch 179/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3869 - val_loss: 0.3515\n",
      "Epoch 180/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3873 - val_loss: 0.3536\n",
      "Epoch 181/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.3537\n",
      "Epoch 182/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3873 - val_loss: 0.3524\n",
      "Epoch 183/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3867 - val_loss: 0.3527\n",
      "Epoch 184/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.3531\n",
      "Epoch 185/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.3517\n",
      "Epoch 186/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3870 - val_loss: 0.3535\n",
      "Epoch 187/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.3536\n",
      "Epoch 188/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.3509\n",
      "Epoch 189/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.3514\n",
      "Epoch 190/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3870 - val_loss: 0.3519\n",
      "Epoch 191/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3867 - val_loss: 0.3516\n",
      "Epoch 192/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.3526\n",
      "Epoch 193/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3870 - val_loss: 0.3511\n",
      "Epoch 194/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.3525\n",
      "Epoch 195/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.3514\n",
      "Epoch 196/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.3528\n",
      "Epoch 197/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3520\n",
      "Epoch 198/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3867 - val_loss: 0.3519\n",
      "Epoch 199/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.381 - 0s 2ms/step - loss: 0.3867 - val_loss: 0.3524\n",
      "Epoch 200/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3873 - val_loss: 0.3525\n",
      "Epoch 201/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3867 - val_loss: 0.3507\n",
      "Epoch 202/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3868 - val_loss: 0.3517\n",
      "Epoch 203/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3869 - val_loss: 0.3522\n",
      "Epoch 204/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.3517\n",
      "Epoch 205/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3867 - val_loss: 0.3519\n",
      "Epoch 206/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3865 - val_loss: 0.3525\n",
      "Epoch 207/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3867 - val_loss: 0.3529\n",
      "Epoch 208/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3868 - val_loss: 0.3532\n",
      "Epoch 209/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.3516\n",
      "Epoch 210/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3870 - val_loss: 0.3517\n",
      "Epoch 211/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.381 - 0s 2ms/step - loss: 0.3864 - val_loss: 0.3515\n",
      "Epoch 212/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3865 - val_loss: 0.3521\n",
      "Epoch 213/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.3505\n",
      "Epoch 214/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3868 - val_loss: 0.3523\n",
      "Epoch 215/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.3511\n",
      "Epoch 216/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3870 - val_loss: 0.3517\n",
      "Epoch 217/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3869 - val_loss: 0.3504\n",
      "Epoch 218/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3864 - val_loss: 0.3517\n",
      "Epoch 219/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3516\n",
      "Epoch 220/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.3510\n",
      "Epoch 221/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.3514\n",
      "Epoch 222/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3868 - val_loss: 0.3514\n",
      "Epoch 223/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3862 - val_loss: 0.3519\n",
      "Epoch 224/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3516\n",
      "Epoch 225/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.3519\n",
      "Epoch 226/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3519\n",
      "Epoch 227/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.384 - 0s 2ms/step - loss: 0.3867 - val_loss: 0.3516\n",
      "Epoch 228/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3531\n",
      "Epoch 229/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3865 - val_loss: 0.3502\n",
      "Epoch 230/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3506\n",
      "Epoch 231/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3516\n",
      "Epoch 232/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.3518\n",
      "Epoch 233/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3860 - val_loss: 0.3521\n",
      "Epoch 234/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3865 - val_loss: 0.3514\n",
      "Epoch 235/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3862 - val_loss: 0.3518\n",
      "Epoch 236/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3865 - val_loss: 0.3519\n",
      "Epoch 237/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3513\n",
      "Epoch 238/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3504\n",
      "Epoch 239/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3865 - val_loss: 0.3514\n",
      "Epoch 240/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3862 - val_loss: 0.3510\n",
      "Epoch 241/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.3510\n",
      "Epoch 242/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3862 - val_loss: 0.3511\n",
      "Epoch 243/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.3524\n",
      "Epoch 244/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.3517\n",
      "Epoch 245/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.3523\n",
      "Epoch 246/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.3525\n",
      "Epoch 247/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3864 - val_loss: 0.3533\n",
      "Epoch 248/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3862 - val_loss: 0.3519\n",
      "Epoch 249/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3859 - val_loss: 0.3528\n",
      "Epoch 250/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.3520\n",
      "Epoch 251/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.3521\n",
      "Epoch 252/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.3513\n",
      "Epoch 253/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3517\n",
      "Epoch 254/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3862 - val_loss: 0.3519\n",
      "Epoch 255/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.3508\n",
      "Epoch 256/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.3513\n",
      "Epoch 257/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.3512\n",
      "Epoch 258/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.3524\n",
      "Epoch 259/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.3516\n",
      "Epoch 260/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3511\n",
      "Epoch 261/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3531\n",
      "Epoch 262/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.3502\n",
      "Epoch 263/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3862 - val_loss: 0.3514\n",
      "Epoch 264/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.3502\n",
      "Epoch 265/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.3522\n",
      "Epoch 266/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3857 - val_loss: 0.3498\n",
      "Epoch 267/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.3520\n",
      "Epoch 268/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.3521\n",
      "Epoch 269/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.3522\n",
      "Epoch 270/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.3525\n",
      "Epoch 271/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.3522\n",
      "Epoch 272/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.3519\n",
      "Epoch 273/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3508\n",
      "Epoch 274/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.3522\n",
      "Epoch 275/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3857 - val_loss: 0.3520\n",
      "Epoch 276/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3857 - val_loss: 0.3520\n",
      "Epoch 277/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.3511\n",
      "Epoch 278/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3857 - val_loss: 0.3514\n",
      "Epoch 279/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.3519\n",
      "Epoch 280/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.3508\n",
      "Epoch 281/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.3521\n",
      "Epoch 282/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3857 - val_loss: 0.3503\n",
      "Epoch 283/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.3504\n",
      "Epoch 284/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.3505\n",
      "Epoch 285/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3856 - val_loss: 0.3518\n",
      "Epoch 286/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.3525\n",
      "Epoch 287/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3856 - val_loss: 0.3509\n",
      "Epoch 288/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3854 - val_loss: 0.3520\n",
      "Epoch 289/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.3508\n",
      "Epoch 290/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.3524\n",
      "Epoch 291/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.384 - 0s 2ms/step - loss: 0.3857 - val_loss: 0.3514\n",
      "Epoch 292/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.3513\n",
      "Epoch 293/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.3524\n",
      "Epoch 294/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3856 - val_loss: 0.3513\n",
      "Epoch 295/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.3511\n",
      "Epoch 296/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.3498\n",
      "Epoch 297/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.3536\n",
      "Epoch 298/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3852 - val_loss: 0.3502\n",
      "Epoch 299/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3854 - val_loss: 0.3511\n",
      "Epoch 300/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.3525\n",
      "Epoch 301/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.3517\n",
      "Epoch 302/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.3506\n",
      "Epoch 303/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.3507\n",
      "Epoch 304/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3854 - val_loss: 0.3514\n",
      "Epoch 305/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3852 - val_loss: 0.3522\n",
      "Epoch 306/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3497\n",
      "Epoch 307/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.3514\n",
      "Epoch 308/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.3517\n",
      "Epoch 309/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3510\n",
      "Epoch 310/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3852 - val_loss: 0.3508\n",
      "Epoch 311/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.3505\n",
      "Epoch 312/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.3498\n",
      "Epoch 313/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.3505\n",
      "Epoch 314/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.3488\n",
      "Epoch 315/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.3493\n",
      "Epoch 316/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3512\n",
      "Epoch 317/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3852 - val_loss: 0.3516\n",
      "Epoch 318/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.386 - 0s 2ms/step - loss: 0.3857 - val_loss: 0.3517\n",
      "Epoch 319/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3503\n",
      "Epoch 320/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3856 - val_loss: 0.3496\n",
      "Epoch 322/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.3509\n",
      "Epoch 323/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.3502\n",
      "Epoch 324/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.3505\n",
      "Epoch 325/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3503\n",
      "Epoch 326/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.3502\n",
      "Epoch 327/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.3500\n",
      "Epoch 328/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3511\n",
      "Epoch 329/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.3498\n",
      "Epoch 330/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.3503\n",
      "Epoch 331/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3491\n",
      "Epoch 332/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3505\n",
      "Epoch 333/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.3497\n",
      "Epoch 334/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3512\n",
      "Epoch 335/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3505\n",
      "Epoch 336/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.3511\n",
      "Epoch 337/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3846 - val_loss: 0.3499\n",
      "Epoch 338/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.3510\n",
      "Epoch 339/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3846 - val_loss: 0.3506\n",
      "Epoch 340/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3846 - val_loss: 0.3502\n",
      "Epoch 341/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3518\n",
      "Epoch 342/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3508\n",
      "Epoch 343/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.3513\n",
      "Epoch 344/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.3500\n",
      "Epoch 345/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.3505\n",
      "Epoch 346/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.3500\n",
      "Epoch 347/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3848 - val_loss: 0.3512\n",
      "Epoch 348/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3522\n",
      "Epoch 349/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3512\n",
      "Epoch 350/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3503\n",
      "Epoch 351/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3490\n",
      "Epoch 352/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.3505\n",
      "Epoch 353/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3503\n",
      "Epoch 354/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.3518\n",
      "Epoch 355/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.3509\n",
      "Epoch 356/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3506\n",
      "Epoch 357/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3852 - val_loss: 0.3515\n",
      "Epoch 358/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3507\n",
      "Epoch 359/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.3496\n",
      "Epoch 360/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3846 - val_loss: 0.3505\n",
      "Epoch 361/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.3492\n",
      "Epoch 362/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.3508\n",
      "Epoch 363/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.3502\n",
      "Epoch 364/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.3505\n",
      "Epoch 365/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3852 - val_loss: 0.3492\n",
      "Epoch 366/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.3518\n",
      "Epoch 367/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3509\n",
      "Epoch 368/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3505\n",
      "Epoch 369/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3501\n",
      "Epoch 370/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3493\n",
      "Epoch 371/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.3504\n",
      "Epoch 372/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3513\n",
      "Epoch 373/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3510\n",
      "Epoch 374/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3508\n",
      "Epoch 375/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3846 - val_loss: 0.3507\n",
      "Epoch 376/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3488\n",
      "Epoch 377/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3846 - val_loss: 0.3496\n",
      "Epoch 378/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.3501\n",
      "Epoch 379/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.3503\n",
      "Epoch 380/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.3489\n",
      "Epoch 381/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3502\n",
      "Epoch 382/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.3511\n",
      "Epoch 383/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3495\n",
      "Epoch 384/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3848 - val_loss: 0.3504\n",
      "Epoch 385/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3515\n",
      "Epoch 386/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3502\n",
      "Epoch 387/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3502\n",
      "Epoch 388/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3495\n",
      "Epoch 389/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3505\n",
      "Epoch 390/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3509\n",
      "Epoch 391/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3501\n",
      "Epoch 392/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.3496\n",
      "Epoch 393/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3489\n",
      "Epoch 394/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.3501\n",
      "Epoch 395/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3848 - val_loss: 0.3478\n",
      "Epoch 396/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3501\n",
      "Epoch 397/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3503\n",
      "Epoch 398/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.597 - 0s 2ms/step - loss: 0.3846 - val_loss: 0.3496\n",
      "Epoch 399/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3506\n",
      "Epoch 400/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.3504\n",
      "Epoch 401/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3505\n",
      "Epoch 402/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3494\n",
      "Epoch 403/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3508\n",
      "Epoch 404/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3510\n",
      "Epoch 405/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3522\n",
      "Epoch 406/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3507\n",
      "Epoch 407/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3519\n",
      "Epoch 408/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3503\n",
      "Epoch 409/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3498\n",
      "Epoch 410/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3493\n",
      "Epoch 411/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3848 - val_loss: 0.3498\n",
      "Epoch 412/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3854 - val_loss: 0.3498\n",
      "Epoch 413/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3496\n",
      "Epoch 414/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3506\n",
      "Epoch 415/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3501\n",
      "Epoch 416/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.3517\n",
      "Epoch 417/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.3503\n",
      "Epoch 418/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3515\n",
      "Epoch 419/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.3516\n",
      "Epoch 420/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.3525\n",
      "Epoch 421/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3495\n",
      "Epoch 422/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3509\n",
      "Epoch 423/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.3524\n",
      "Epoch 424/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.3527\n",
      "Epoch 425/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.3498\n",
      "Epoch 426/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.3520\n",
      "Epoch 427/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.3489\n",
      "Epoch 428/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.387 - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3495\n",
      "Epoch 429/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3499\n",
      "Epoch 430/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3494\n",
      "Epoch 431/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3509\n",
      "Epoch 432/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.3515\n",
      "Epoch 433/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3501\n",
      "Epoch 434/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3509\n",
      "Epoch 435/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.3495\n",
      "Epoch 436/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3846 - val_loss: 0.3494\n",
      "Epoch 437/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3502\n",
      "Epoch 438/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3497\n",
      "Epoch 439/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3497\n",
      "Epoch 440/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.384 - 0s 2ms/step - loss: 0.3847 - val_loss: 0.3499\n",
      "Epoch 441/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.3495\n",
      "Epoch 442/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3492\n",
      "Epoch 443/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3486\n",
      "Epoch 444/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3521\n",
      "Epoch 445/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3512\n",
      "Epoch 446/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3503\n",
      "Epoch 447/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.3495\n",
      "Epoch 448/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3502\n",
      "Epoch 449/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3848 - val_loss: 0.3522\n",
      "Epoch 450/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.3491\n",
      "Epoch 451/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3503\n",
      "Epoch 452/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3500\n",
      "Epoch 453/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.3505\n",
      "Epoch 454/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.3487\n",
      "Epoch 455/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3491\n",
      "Epoch 456/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3512\n",
      "Epoch 457/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3501\n",
      "Epoch 458/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3524\n",
      "Epoch 459/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.3521\n",
      "Epoch 460/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3505\n",
      "Epoch 461/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3516\n",
      "Epoch 462/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3511\n",
      "Epoch 463/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3477\n",
      "Epoch 464/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.3502\n",
      "Epoch 465/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.3525\n",
      "Epoch 466/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.3500\n",
      "Epoch 467/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3516\n",
      "Epoch 468/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.3486\n",
      "Epoch 469/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.3505\n",
      "Epoch 470/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.3509\n",
      "Epoch 471/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3508\n",
      "Epoch 472/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3505\n",
      "Epoch 473/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3489\n",
      "Epoch 474/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3507\n",
      "Epoch 475/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.3492\n",
      "Epoch 476/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3494\n",
      "Epoch 477/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3493\n",
      "Epoch 478/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.3504\n",
      "Epoch 479/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3511\n",
      "Epoch 480/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3501\n",
      "Epoch 482/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3489\n",
      "Epoch 483/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3498\n",
      "Epoch 484/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3491\n",
      "Epoch 485/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.3519\n",
      "Epoch 486/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3504\n",
      "Epoch 487/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.3492\n",
      "Epoch 488/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3497\n",
      "Epoch 489/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3501\n",
      "Epoch 490/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3498\n",
      "Epoch 491/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3504\n",
      "Epoch 492/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3506\n",
      "Epoch 493/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.3487\n",
      "Epoch 494/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3487\n",
      "Epoch 495/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.3518\n",
      "Epoch 496/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.3509\n",
      "Epoch 497/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.3511\n",
      "Epoch 498/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.3485\n",
      "Epoch 499/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.3500\n",
      "Epoch 500/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3493\n",
      "Epoch 501/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3498\n",
      "Epoch 502/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3493\n",
      "Epoch 503/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3498\n",
      "Epoch 504/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3504\n",
      "Epoch 505/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3493\n",
      "Epoch 506/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3522\n",
      "Epoch 507/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3491\n",
      "Epoch 508/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.3492\n",
      "Epoch 509/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.3479\n",
      "Epoch 510/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3508\n",
      "Epoch 511/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3515\n",
      "Epoch 512/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3478\n",
      "Epoch 513/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3508\n",
      "Epoch 514/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3496\n",
      "Epoch 515/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3498\n",
      "Epoch 516/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3490\n",
      "Epoch 517/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.3498\n",
      "Epoch 518/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3506\n",
      "Epoch 519/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3505\n",
      "Epoch 520/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3488\n",
      "Epoch 521/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3485\n",
      "Epoch 522/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3488\n",
      "Epoch 523/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3493\n",
      "Epoch 524/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3493\n",
      "Epoch 525/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3490\n",
      "Epoch 526/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3501\n",
      "Epoch 527/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3499\n",
      "Epoch 528/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3511\n",
      "Epoch 529/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3501\n",
      "Epoch 530/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3511\n",
      "Epoch 531/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3510\n",
      "Epoch 532/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3499\n",
      "Epoch 533/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3496\n",
      "Epoch 534/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3495\n",
      "Epoch 535/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.3482\n",
      "Epoch 536/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3505\n",
      "Epoch 537/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3483\n",
      "Epoch 538/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3496\n",
      "Epoch 539/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3503\n",
      "Epoch 540/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3513\n",
      "Epoch 541/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3486\n",
      "Epoch 542/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3511\n",
      "Epoch 543/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3498\n",
      "Epoch 544/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3510\n",
      "Epoch 545/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3506\n",
      "Epoch 546/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.3492\n",
      "Epoch 547/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3506\n",
      "Epoch 548/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3488\n",
      "Epoch 549/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3500\n",
      "Epoch 550/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3497\n",
      "Epoch 551/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3497\n",
      "Epoch 552/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3500\n",
      "Epoch 553/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3515\n",
      "Epoch 554/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3493\n",
      "Epoch 555/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3508\n",
      "Epoch 556/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.3502\n",
      "Epoch 557/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3482\n",
      "Epoch 558/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3500\n",
      "Epoch 559/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3497\n",
      "Epoch 560/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3485\n",
      "Epoch 561/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3496\n",
      "Epoch 562/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3476\n",
      "Epoch 563/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3509\n",
      "Epoch 564/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3495\n",
      "Epoch 565/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3501\n",
      "Epoch 566/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3481\n",
      "Epoch 567/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3496\n",
      "Epoch 568/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3476\n",
      "Epoch 569/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3492\n",
      "Epoch 570/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3498\n",
      "Epoch 571/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3501\n",
      "Epoch 572/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3503\n",
      "Epoch 573/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3507\n",
      "Epoch 574/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3507\n",
      "Epoch 575/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3492\n",
      "Epoch 576/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3506\n",
      "Epoch 577/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3499\n",
      "Epoch 578/1500\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.3838 - val_loss: 0.3502\n",
      "Epoch 579/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3495\n",
      "Epoch 580/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3499\n",
      "Epoch 581/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3490\n",
      "Epoch 582/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3510\n",
      "Epoch 583/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3489\n",
      "Epoch 584/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3506\n",
      "Epoch 585/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3482\n",
      "Epoch 586/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3486\n",
      "Epoch 587/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3504\n",
      "Epoch 588/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3492\n",
      "Epoch 589/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3483\n",
      "Epoch 590/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3483\n",
      "Epoch 591/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3492\n",
      "Epoch 592/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3490\n",
      "Epoch 593/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3492\n",
      "Epoch 594/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3492\n",
      "Epoch 595/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3482\n",
      "Epoch 596/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3486\n",
      "Epoch 597/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3493\n",
      "Epoch 598/1500\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.3836 - val_loss: 0.3477\n",
      "Epoch 599/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3487\n",
      "Epoch 600/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3499\n",
      "Epoch 601/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3494\n",
      "Epoch 602/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3484\n",
      "Epoch 603/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3482\n",
      "Epoch 604/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3493\n",
      "Epoch 605/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3493\n",
      "Epoch 606/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3496\n",
      "Epoch 607/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3494\n",
      "Epoch 608/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3512\n",
      "Epoch 609/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3510\n",
      "Epoch 610/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3503\n",
      "Epoch 611/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3508\n",
      "Epoch 612/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3502\n",
      "Epoch 613/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3502\n",
      "Epoch 614/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3492\n",
      "Epoch 615/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3494\n",
      "Epoch 616/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3515\n",
      "Epoch 617/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.3517\n",
      "Epoch 618/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3487\n",
      "Epoch 619/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3482\n",
      "Epoch 620/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3488\n",
      "Epoch 621/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3497\n",
      "Epoch 622/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3502\n",
      "Epoch 623/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3479\n",
      "Epoch 624/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3488\n",
      "Epoch 625/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3503\n",
      "Epoch 626/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3485\n",
      "Epoch 627/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3494\n",
      "Epoch 628/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3491\n",
      "Epoch 629/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3493\n",
      "Epoch 630/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3487\n",
      "Epoch 631/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3487\n",
      "Epoch 632/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3476\n",
      "Epoch 633/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3488\n",
      "Epoch 634/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3486\n",
      "Epoch 635/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3498\n",
      "Epoch 636/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3489\n",
      "Epoch 637/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3492\n",
      "Epoch 638/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3486\n",
      "Epoch 639/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3500\n",
      "Epoch 640/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3490\n",
      "Epoch 641/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3476\n",
      "Epoch 642/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3478\n",
      "Epoch 643/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3487\n",
      "Epoch 644/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3495\n",
      "Epoch 645/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3477\n",
      "Epoch 646/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3486\n",
      "Epoch 647/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3481\n",
      "Epoch 648/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3486\n",
      "Epoch 649/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3496\n",
      "Epoch 650/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3495\n",
      "Epoch 651/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3495\n",
      "Epoch 652/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3486\n",
      "Epoch 653/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3472\n",
      "Epoch 654/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3506\n",
      "Epoch 655/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3491\n",
      "Epoch 656/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3499\n",
      "Epoch 657/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3484\n",
      "Epoch 658/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3493\n",
      "Epoch 659/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3486\n",
      "Epoch 660/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3490\n",
      "Epoch 661/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3491\n",
      "Epoch 662/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3491\n",
      "Epoch 663/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3493\n",
      "Epoch 664/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3489\n",
      "Epoch 665/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3526\n",
      "Epoch 666/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3479\n",
      "Epoch 667/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3489\n",
      "Epoch 668/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3489\n",
      "Epoch 669/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3495\n",
      "Epoch 670/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3482\n",
      "Epoch 671/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3479\n",
      "Epoch 672/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3496\n",
      "Epoch 673/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3478\n",
      "Epoch 674/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3494\n",
      "Epoch 675/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3483\n",
      "Epoch 676/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3507\n",
      "Epoch 677/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3477\n",
      "Epoch 678/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3482\n",
      "Epoch 679/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3490\n",
      "Epoch 680/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3491\n",
      "Epoch 681/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3479\n",
      "Epoch 682/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.3504\n",
      "Epoch 683/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3492\n",
      "Epoch 684/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3493\n",
      "Epoch 685/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3514\n",
      "Epoch 686/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3475\n",
      "Epoch 687/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.3484\n",
      "Epoch 688/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3493\n",
      "Epoch 689/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3487\n",
      "Epoch 690/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3488\n",
      "Epoch 691/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3518\n",
      "Epoch 692/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.3494\n",
      "Epoch 693/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3500\n",
      "Epoch 694/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3513\n",
      "Epoch 695/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3491\n",
      "Epoch 696/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3486\n",
      "Epoch 697/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3489\n",
      "Epoch 698/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3498\n",
      "Epoch 699/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3482\n",
      "Epoch 700/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3494\n",
      "Epoch 701/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3503\n",
      "Epoch 702/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3482\n",
      "Epoch 703/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3504\n",
      "Epoch 704/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3467\n",
      "Epoch 705/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3512\n",
      "Epoch 706/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3506\n",
      "Epoch 707/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3491\n",
      "Epoch 708/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3479\n",
      "Epoch 709/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3510\n",
      "Epoch 710/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3503\n",
      "Epoch 711/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3491\n",
      "Epoch 712/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3494\n",
      "Epoch 713/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3494\n",
      "Epoch 714/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3495\n",
      "Epoch 715/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3483\n",
      "Epoch 716/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3490\n",
      "Epoch 717/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3501\n",
      "Epoch 718/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3504\n",
      "Epoch 719/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.3483\n",
      "Epoch 720/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3830 - val_loss: 0.3500\n",
      "Epoch 721/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3474\n",
      "Epoch 722/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3489\n",
      "Epoch 723/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3500\n",
      "Epoch 724/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3473\n",
      "Epoch 725/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3481\n",
      "Epoch 726/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3480\n",
      "Epoch 727/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3495\n",
      "Epoch 728/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.3478\n",
      "Epoch 729/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.3480\n",
      "Epoch 730/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3494\n",
      "Epoch 731/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3501\n",
      "Epoch 732/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3511\n",
      "Epoch 733/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3496\n",
      "Epoch 734/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3486\n",
      "Epoch 735/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.3481\n",
      "Epoch 736/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3487\n",
      "Epoch 737/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3493\n",
      "Epoch 738/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3508\n",
      "Epoch 739/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3483\n",
      "Epoch 740/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3488\n",
      "Epoch 741/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3488\n",
      "Epoch 742/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3486\n",
      "Epoch 743/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3500\n",
      "Epoch 744/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3497\n",
      "Epoch 745/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3473\n",
      "Epoch 746/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3472\n",
      "Epoch 747/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3483\n",
      "Epoch 748/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3473\n",
      "Epoch 749/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.3509\n",
      "Epoch 750/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.3474\n",
      "Epoch 751/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3481\n",
      "Epoch 752/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3478\n",
      "Epoch 753/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3486\n",
      "Epoch 754/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3482\n",
      "Epoch 755/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3482\n",
      "Epoch 756/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3486\n",
      "Epoch 757/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3511\n",
      "Epoch 758/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3473\n",
      "Epoch 759/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.3485\n",
      "Epoch 760/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3486\n",
      "Epoch 761/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3471\n",
      "Epoch 762/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3830 - val_loss: 0.3485\n",
      "Epoch 763/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.3495\n",
      "Epoch 764/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3489\n",
      "Epoch 765/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3495\n",
      "Epoch 766/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3504\n",
      "Epoch 767/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3478\n",
      "Epoch 768/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3495\n",
      "Epoch 769/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3482\n",
      "Epoch 770/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3478\n",
      "Epoch 771/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3480\n",
      "Epoch 772/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3477\n",
      "Epoch 773/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3479\n",
      "Epoch 774/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3490\n",
      "Epoch 775/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3502\n",
      "Epoch 776/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3473\n",
      "Epoch 777/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3484\n",
      "Epoch 778/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3476\n",
      "Epoch 779/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.386 - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3483\n",
      "Epoch 780/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3484\n",
      "Epoch 781/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3505\n",
      "Epoch 782/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3495\n",
      "Epoch 783/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3490\n",
      "Epoch 784/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3487\n",
      "Epoch 785/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3483\n",
      "Epoch 786/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3495\n",
      "Epoch 787/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3478\n",
      "Epoch 788/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3488\n",
      "Epoch 789/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3494\n",
      "Epoch 790/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3494\n",
      "Epoch 791/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3480\n",
      "Epoch 792/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3482\n",
      "Epoch 793/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3493\n",
      "Epoch 794/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3486\n",
      "Epoch 795/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3491\n",
      "Epoch 796/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3492\n",
      "Epoch 797/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3488\n",
      "Epoch 798/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3493\n",
      "Epoch 799/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3482\n",
      "Epoch 800/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3495\n",
      "Epoch 801/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3473\n",
      "Epoch 802/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3484\n",
      "Epoch 803/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3477\n",
      "Epoch 804/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3483\n",
      "Epoch 805/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3488\n",
      "Epoch 806/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3487\n",
      "Epoch 807/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3482\n",
      "Epoch 808/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3482\n",
      "Epoch 809/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3481\n",
      "Epoch 810/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.391 - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3481\n",
      "Epoch 811/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3493\n",
      "Epoch 812/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3484\n",
      "Epoch 813/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3483\n",
      "Epoch 814/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3488\n",
      "Epoch 815/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3498\n",
      "Epoch 816/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3491\n",
      "Epoch 817/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3494\n",
      "Epoch 818/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3476\n",
      "Epoch 819/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3486\n",
      "Epoch 820/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3494\n",
      "Epoch 821/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3485\n",
      "Epoch 822/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3491\n",
      "Epoch 823/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3484\n",
      "Epoch 824/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3469\n",
      "Epoch 825/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3485\n",
      "Epoch 826/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3483\n",
      "Epoch 827/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3492\n",
      "Epoch 828/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3498\n",
      "Epoch 829/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3481\n",
      "Epoch 830/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3497\n",
      "Epoch 831/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3482\n",
      "Epoch 832/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3478\n",
      "Epoch 833/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3495\n",
      "Epoch 834/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3483\n",
      "Epoch 835/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3472\n",
      "Epoch 836/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3486\n",
      "Epoch 837/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3471\n",
      "Epoch 838/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3486\n",
      "Epoch 839/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3493\n",
      "Epoch 840/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3488\n",
      "Epoch 841/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3517\n",
      "Epoch 842/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3492\n",
      "Epoch 843/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3489\n",
      "Epoch 844/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3485\n",
      "Epoch 845/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3478\n",
      "Epoch 846/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3501\n",
      "Epoch 847/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3496\n",
      "Epoch 848/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3483\n",
      "Epoch 849/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3490\n",
      "Epoch 850/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3475\n",
      "Epoch 851/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3479\n",
      "Epoch 852/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3479\n",
      "Epoch 853/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3495\n",
      "Epoch 854/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3479\n",
      "Epoch 855/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3495\n",
      "Epoch 856/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3500\n",
      "Epoch 857/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3485\n",
      "Epoch 858/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3466\n",
      "Epoch 859/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.3489\n",
      "Epoch 860/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3498\n",
      "Epoch 861/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3830 - val_loss: 0.3483\n",
      "Epoch 862/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.3467\n",
      "Epoch 863/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3830 - val_loss: 0.3469\n",
      "Epoch 864/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3490\n",
      "Epoch 865/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3480\n",
      "Epoch 866/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3479\n",
      "Epoch 867/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3479\n",
      "Epoch 868/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3473\n",
      "Epoch 869/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3494\n",
      "Epoch 870/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3486\n",
      "Epoch 871/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3487\n",
      "Epoch 872/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3472\n",
      "Epoch 873/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3495\n",
      "Epoch 874/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.3483\n",
      "Epoch 875/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3494\n",
      "Epoch 876/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3493\n",
      "Epoch 877/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3830 - val_loss: 0.3472\n",
      "Epoch 878/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3469\n",
      "Epoch 879/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3483\n",
      "Epoch 880/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3495\n",
      "Epoch 881/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3491\n",
      "Epoch 882/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3475\n",
      "Epoch 883/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3471\n",
      "Epoch 884/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3481\n",
      "Epoch 885/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3478\n",
      "Epoch 886/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3488\n",
      "Epoch 887/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3482\n",
      "Epoch 888/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3492\n",
      "Epoch 889/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3504\n",
      "Epoch 890/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3488\n",
      "Epoch 891/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3482\n",
      "Epoch 892/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3471\n",
      "Epoch 893/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3487\n",
      "Epoch 894/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3492\n",
      "Epoch 895/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3491\n",
      "Epoch 896/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3487\n",
      "Epoch 897/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3474\n",
      "Epoch 898/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3484\n",
      "Epoch 899/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3474\n",
      "Epoch 900/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3496\n",
      "Epoch 901/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3468\n",
      "Epoch 902/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3468\n",
      "Epoch 903/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3490\n",
      "Epoch 904/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3472\n",
      "Epoch 905/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3489\n",
      "Epoch 906/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3489\n",
      "Epoch 907/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3473\n",
      "Epoch 908/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3485\n",
      "Epoch 909/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3476\n",
      "Epoch 910/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3489\n",
      "Epoch 911/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3458\n",
      "Epoch 912/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3473\n",
      "Epoch 913/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3474\n",
      "Epoch 914/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3495\n",
      "Epoch 915/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3464\n",
      "Epoch 916/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3496\n",
      "Epoch 917/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3469\n",
      "Epoch 918/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3483\n",
      "Epoch 919/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3474\n",
      "Epoch 920/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3491\n",
      "Epoch 921/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3474\n",
      "Epoch 922/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3472\n",
      "Epoch 923/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3475\n",
      "Epoch 924/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3485\n",
      "Epoch 925/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3484\n",
      "Epoch 926/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3456\n",
      "Epoch 927/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3469\n",
      "Epoch 928/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3487\n",
      "Epoch 929/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3467\n",
      "Epoch 930/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3477\n",
      "Epoch 931/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3484\n",
      "Epoch 932/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3490\n",
      "Epoch 933/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3484\n",
      "Epoch 934/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3487\n",
      "Epoch 935/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3490\n",
      "Epoch 936/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3483\n",
      "Epoch 937/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3492\n",
      "Epoch 938/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3490\n",
      "Epoch 939/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3476\n",
      "Epoch 940/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3498\n",
      "Epoch 941/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3483\n",
      "Epoch 942/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3478\n",
      "Epoch 943/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3470\n",
      "Epoch 944/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3481\n",
      "Epoch 945/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3490\n",
      "Epoch 946/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3477\n",
      "Epoch 947/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3494\n",
      "Epoch 948/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3481\n",
      "Epoch 949/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3477\n",
      "Epoch 950/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3479\n",
      "Epoch 951/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3484\n",
      "Epoch 952/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3471\n",
      "Epoch 953/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3477\n",
      "Epoch 954/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3481\n",
      "Epoch 955/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3487\n",
      "Epoch 956/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3485\n",
      "Epoch 957/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3464\n",
      "Epoch 958/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3476\n",
      "Epoch 959/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3473\n",
      "Epoch 960/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3475\n",
      "Epoch 961/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3472\n",
      "Epoch 962/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3480\n",
      "Epoch 963/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3482\n",
      "Epoch 964/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3470\n",
      "Epoch 965/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3475\n",
      "Epoch 966/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3479\n",
      "Epoch 967/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3479\n",
      "Epoch 968/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3486\n",
      "Epoch 969/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3472\n",
      "Epoch 970/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3473\n",
      "Epoch 971/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3502\n",
      "Epoch 972/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3462\n",
      "Epoch 973/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3464\n",
      "Epoch 974/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3496\n",
      "Epoch 975/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3491\n",
      "Epoch 976/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3468\n",
      "Epoch 977/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3485\n",
      "Epoch 978/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3492\n",
      "Epoch 979/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3488\n",
      "Epoch 980/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3467\n",
      "Epoch 981/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3497\n",
      "Epoch 982/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3499\n",
      "Epoch 983/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3486\n",
      "Epoch 984/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3483\n",
      "Epoch 985/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3469\n",
      "Epoch 986/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3486\n",
      "Epoch 987/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3507\n",
      "Epoch 988/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3485\n",
      "Epoch 989/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3478\n",
      "Epoch 990/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3475\n",
      "Epoch 991/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3483\n",
      "Epoch 992/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3487\n",
      "Epoch 993/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3493\n",
      "Epoch 994/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3479\n",
      "Epoch 995/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3476\n",
      "Epoch 996/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3482\n",
      "Epoch 997/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3484\n",
      "Epoch 998/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.382 - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3473\n",
      "Epoch 999/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3475\n",
      "Epoch 1000/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3492\n",
      "Epoch 1001/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3499\n",
      "Epoch 1002/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3488\n",
      "Epoch 1003/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3464\n",
      "Epoch 1004/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3484\n",
      "Epoch 1005/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3494\n",
      "Epoch 1006/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3482\n",
      "Epoch 1007/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3485\n",
      "Epoch 1008/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3472\n",
      "Epoch 1009/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3477\n",
      "Epoch 1010/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.377 - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3489\n",
      "Epoch 1011/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3490\n",
      "Epoch 1012/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3490\n",
      "Epoch 1013/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3465\n",
      "Epoch 1014/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3476\n",
      "Epoch 1015/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3472\n",
      "Epoch 1016/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3470\n",
      "Epoch 1017/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3467\n",
      "Epoch 1018/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3483\n",
      "Epoch 1019/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3477\n",
      "Epoch 1020/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3486\n",
      "Epoch 1021/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3469\n",
      "Epoch 1022/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3485\n",
      "Epoch 1023/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3482\n",
      "Epoch 1024/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3488\n",
      "Epoch 1025/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3468\n",
      "Epoch 1026/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3494\n",
      "Epoch 1027/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3484\n",
      "Epoch 1028/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3485\n",
      "Epoch 1029/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3501\n",
      "Epoch 1030/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3491\n",
      "Epoch 1031/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3496\n",
      "Epoch 1032/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3484\n",
      "Epoch 1033/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3484\n",
      "Epoch 1034/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3474\n",
      "Epoch 1035/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3480\n",
      "Epoch 1036/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3486\n",
      "Epoch 1037/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3498\n",
      "Epoch 1038/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3494\n",
      "Epoch 1039/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3467\n",
      "Epoch 1040/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3481\n",
      "Epoch 1041/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3507\n",
      "Epoch 1042/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3490\n",
      "Epoch 1043/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3464\n",
      "Epoch 1044/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.3485\n",
      "Epoch 1045/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3477\n",
      "Epoch 1046/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3475\n",
      "Epoch 1047/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3482\n",
      "Epoch 1048/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3479\n",
      "Epoch 1049/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3484\n",
      "Epoch 1050/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3473\n",
      "Epoch 1051/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3479\n",
      "Epoch 1052/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3497\n",
      "Epoch 1053/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3501\n",
      "Epoch 1054/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3497\n",
      "Epoch 1055/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3469\n",
      "Epoch 1056/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3473\n",
      "Epoch 1057/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3488\n",
      "Epoch 1058/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3484\n",
      "Epoch 1059/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3486\n",
      "Epoch 1060/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3494\n",
      "Epoch 1061/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3494\n",
      "Epoch 1062/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3482\n",
      "Epoch 1063/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3468\n",
      "Epoch 1064/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3458\n",
      "Epoch 1065/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3468\n",
      "Epoch 1066/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3479\n",
      "Epoch 1067/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3477\n",
      "Epoch 1068/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3474\n",
      "Epoch 1069/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3485\n",
      "Epoch 1070/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3468\n",
      "Epoch 1071/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3472\n",
      "Epoch 1072/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3465\n",
      "Epoch 1073/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3483\n",
      "Epoch 1074/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3483\n",
      "Epoch 1075/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3470\n",
      "Epoch 1076/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3473\n",
      "Epoch 1077/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3485\n",
      "Epoch 1078/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3479\n",
      "Epoch 1079/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3457\n",
      "Epoch 1080/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3490\n",
      "Epoch 1081/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3474\n",
      "Epoch 1082/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3483\n",
      "Epoch 1083/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3476\n",
      "Epoch 1084/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3480\n",
      "Epoch 1085/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3485\n",
      "Epoch 1086/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3489\n",
      "Epoch 1087/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3494\n",
      "Epoch 1088/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3483\n",
      "Epoch 1089/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3482\n",
      "Epoch 1090/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3469\n",
      "Epoch 1091/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3474\n",
      "Epoch 1092/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3485\n",
      "Epoch 1093/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3465\n",
      "Epoch 1094/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3474\n",
      "Epoch 1095/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3457\n",
      "Epoch 1096/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3494\n",
      "Epoch 1097/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3487\n",
      "Epoch 1098/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3485\n",
      "Epoch 1099/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3479\n",
      "Epoch 1100/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3493\n",
      "Epoch 1101/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3485\n",
      "Epoch 1102/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3473\n",
      "Epoch 1103/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3491\n",
      "Epoch 1104/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3463\n",
      "Epoch 1105/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3478\n",
      "Epoch 1106/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3487\n",
      "Epoch 1107/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3485\n",
      "Epoch 1108/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3473\n",
      "Epoch 1109/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3474\n",
      "Epoch 1110/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3470\n",
      "Epoch 1111/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3472\n",
      "Epoch 1112/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3484\n",
      "Epoch 1113/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3492\n",
      "Epoch 1114/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3488\n",
      "Epoch 1115/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3477\n",
      "Epoch 1116/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3486\n",
      "Epoch 1117/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3464\n",
      "Epoch 1118/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3487\n",
      "Epoch 1119/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3472\n",
      "Epoch 1120/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3495\n",
      "Epoch 1121/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3492\n",
      "Epoch 1122/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3491\n",
      "Epoch 1123/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3491\n",
      "Epoch 1124/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3486\n",
      "Epoch 1125/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3484\n",
      "Epoch 1126/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3482\n",
      "Epoch 1127/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3473\n",
      "Epoch 1128/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3479\n",
      "Epoch 1129/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3502\n",
      "Epoch 1130/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3460\n",
      "Epoch 1131/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3481\n",
      "Epoch 1132/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3489\n",
      "Epoch 1133/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3487\n",
      "Epoch 1134/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3468\n",
      "Epoch 1135/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3476\n",
      "Epoch 1136/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3464\n",
      "Epoch 1137/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3492\n",
      "Epoch 1138/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3488\n",
      "Epoch 1139/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3473\n",
      "Epoch 1140/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3500\n",
      "Epoch 1141/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3467\n",
      "Epoch 1142/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3481\n",
      "Epoch 1143/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3464\n",
      "Epoch 1144/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3482\n",
      "Epoch 1145/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3473\n",
      "Epoch 1146/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3488\n",
      "Epoch 1147/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3471\n",
      "Epoch 1148/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.388 - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3472\n",
      "Epoch 1149/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3479\n",
      "Epoch 1150/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3464\n",
      "Epoch 1151/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3480\n",
      "Epoch 1152/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3474\n",
      "Epoch 1153/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.3474\n",
      "Epoch 1154/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3471\n",
      "Epoch 1155/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3479\n",
      "Epoch 1156/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3507\n",
      "Epoch 1157/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3468\n",
      "Epoch 1158/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3490\n",
      "Epoch 1159/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3502\n",
      "Epoch 1160/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3488\n",
      "Epoch 1161/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3472\n",
      "Epoch 1162/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3489\n",
      "Epoch 1163/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3478\n",
      "Epoch 1164/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3491\n",
      "Epoch 1165/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3471\n",
      "Epoch 1166/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3501\n",
      "Epoch 1167/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3487\n",
      "Epoch 1168/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3483\n",
      "Epoch 1169/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3482\n",
      "Epoch 1170/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3478\n",
      "Epoch 1171/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3475\n",
      "Epoch 1172/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3497\n",
      "Epoch 1173/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3492\n",
      "Epoch 1174/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3472\n",
      "Epoch 1175/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3475\n",
      "Epoch 1176/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3482\n",
      "Epoch 1177/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3509\n",
      "Epoch 1178/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3470\n",
      "Epoch 1179/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3470\n",
      "Epoch 1180/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3500\n",
      "Epoch 1181/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3493\n",
      "Epoch 1182/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3487\n",
      "Epoch 1183/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3485\n",
      "Epoch 1184/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3479\n",
      "Epoch 1185/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3471\n",
      "Epoch 1186/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3486\n",
      "Epoch 1187/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3469\n",
      "Epoch 1188/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3487\n",
      "Epoch 1189/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3476\n",
      "Epoch 1190/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.3478\n",
      "Epoch 1191/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3487\n",
      "Epoch 1192/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.3480\n",
      "Epoch 1193/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3478\n",
      "Epoch 1194/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3486\n",
      "Epoch 1195/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3483\n",
      "Epoch 1196/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3470\n",
      "Epoch 1197/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3469\n",
      "Epoch 1198/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3495\n",
      "Epoch 1199/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.3469\n",
      "Epoch 1200/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3472\n",
      "Epoch 1201/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3830 - val_loss: 0.3480\n",
      "Epoch 1202/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3490\n",
      "Epoch 1203/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3488\n",
      "Epoch 1204/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3474\n",
      "Epoch 1205/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3479\n",
      "Epoch 1206/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3483\n",
      "Epoch 1207/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3486\n",
      "Epoch 1208/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3469\n",
      "Epoch 1209/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3469\n",
      "Epoch 1210/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.383 - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3476\n",
      "Epoch 1211/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3487\n",
      "Epoch 1212/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3484\n",
      "Epoch 1213/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3476\n",
      "Epoch 1214/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3461\n",
      "Epoch 1215/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3484\n",
      "Epoch 1216/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3481\n",
      "Epoch 1217/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3501\n",
      "Epoch 1218/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3491\n",
      "Epoch 1219/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3466\n",
      "Epoch 1220/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3468\n",
      "Epoch 1221/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3470\n",
      "Epoch 1222/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3478\n",
      "Epoch 1223/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3480\n",
      "Epoch 1224/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3487\n",
      "Epoch 1225/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3477\n",
      "Epoch 1226/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3466\n",
      "Epoch 1227/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3478\n",
      "Epoch 1228/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3490\n",
      "Epoch 1229/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3489\n",
      "Epoch 1230/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3477\n",
      "Epoch 1231/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3476\n",
      "Epoch 1232/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3482\n",
      "Epoch 1233/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3490\n",
      "Epoch 1234/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3487\n",
      "Epoch 1235/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3491\n",
      "Epoch 1236/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3494\n",
      "Epoch 1237/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3472\n",
      "Epoch 1238/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3499\n",
      "Epoch 1239/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3485\n",
      "Epoch 1240/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3486\n",
      "Epoch 1241/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3478\n",
      "Epoch 1242/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3488\n",
      "Epoch 1243/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3481\n",
      "Epoch 1244/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3481\n",
      "Epoch 1245/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3462\n",
      "Epoch 1246/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3483\n",
      "Epoch 1247/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3473\n",
      "Epoch 1248/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3467\n",
      "Epoch 1249/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3475\n",
      "Epoch 1250/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3481\n",
      "Epoch 1251/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3470\n",
      "Epoch 1252/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3474\n",
      "Epoch 1253/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3479\n",
      "Epoch 1254/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3489\n",
      "Epoch 1255/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3467\n",
      "Epoch 1256/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3480\n",
      "Epoch 1257/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3479\n",
      "Epoch 1258/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3480\n",
      "Epoch 1259/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3483\n",
      "Epoch 1260/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3487\n",
      "Epoch 1261/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3486\n",
      "Epoch 1262/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3482\n",
      "Epoch 1263/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3491\n",
      "Epoch 1264/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3472\n",
      "Epoch 1265/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3481\n",
      "Epoch 1266/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3472\n",
      "Epoch 1267/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3478\n",
      "Epoch 1268/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3492\n",
      "Epoch 1269/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3482\n",
      "Epoch 1270/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3475\n",
      "Epoch 1271/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3471\n",
      "Epoch 1272/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3493\n",
      "Epoch 1273/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3480\n",
      "Epoch 1274/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3478\n",
      "Epoch 1275/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3463\n",
      "Epoch 1276/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3495\n",
      "Epoch 1277/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3462\n",
      "Epoch 1278/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3486\n",
      "Epoch 1279/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3482\n",
      "Epoch 1280/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3476\n",
      "Epoch 1281/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3468\n",
      "Epoch 1282/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3488\n",
      "Epoch 1283/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3466\n",
      "Epoch 1284/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3479\n",
      "Epoch 1285/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3471\n",
      "Epoch 1286/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3485\n",
      "Epoch 1287/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3488\n",
      "Epoch 1288/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3453\n",
      "Epoch 1289/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3480\n",
      "Epoch 1290/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3481\n",
      "Epoch 1291/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3472\n",
      "Epoch 1292/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3496\n",
      "Epoch 1293/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3486\n",
      "Epoch 1294/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3476\n",
      "Epoch 1295/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3480\n",
      "Epoch 1296/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3461\n",
      "Epoch 1297/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3479\n",
      "Epoch 1298/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3484\n",
      "Epoch 1299/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3484\n",
      "Epoch 1300/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3470\n",
      "Epoch 1301/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3467\n",
      "Epoch 1302/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3465\n",
      "Epoch 1303/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3466\n",
      "Epoch 1304/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3480\n",
      "Epoch 1305/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3488\n",
      "Epoch 1306/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3482\n",
      "Epoch 1307/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3472\n",
      "Epoch 1308/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3472\n",
      "Epoch 1309/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3486\n",
      "Epoch 1310/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3496\n",
      "Epoch 1311/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3484\n",
      "Epoch 1312/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3475\n",
      "Epoch 1313/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3508\n",
      "Epoch 1314/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3488\n",
      "Epoch 1315/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3471\n",
      "Epoch 1316/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3485\n",
      "Epoch 1317/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3502\n",
      "Epoch 1318/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3467\n",
      "Epoch 1319/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3475\n",
      "Epoch 1320/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3477\n",
      "Epoch 1321/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3476\n",
      "Epoch 1322/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3482\n",
      "Epoch 1323/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3484\n",
      "Epoch 1324/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3488\n",
      "Epoch 1325/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3478\n",
      "Epoch 1326/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3477\n",
      "Epoch 1327/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3482\n",
      "Epoch 1328/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3463\n",
      "Epoch 1329/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.383 - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3493\n",
      "Epoch 1330/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3457\n",
      "Epoch 1331/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3487\n",
      "Epoch 1332/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3495\n",
      "Epoch 1333/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3474\n",
      "Epoch 1334/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3483\n",
      "Epoch 1335/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3474\n",
      "Epoch 1336/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3484\n",
      "Epoch 1337/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3489\n",
      "Epoch 1338/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3470\n",
      "Epoch 1339/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3479\n",
      "Epoch 1340/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3484\n",
      "Epoch 1341/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3482\n",
      "Epoch 1342/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3482\n",
      "Epoch 1343/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3482\n",
      "Epoch 1344/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3493\n",
      "Epoch 1345/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3477\n",
      "Epoch 1346/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.3471\n",
      "Epoch 1347/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3475\n",
      "Epoch 1348/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3471\n",
      "Epoch 1349/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3489\n",
      "Epoch 1350/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3478\n",
      "Epoch 1351/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3467\n",
      "Epoch 1352/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3467\n",
      "Epoch 1353/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3476\n",
      "Epoch 1354/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3480\n",
      "Epoch 1355/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3478\n",
      "Epoch 1356/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3474\n",
      "Epoch 1357/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3478\n",
      "Epoch 1358/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3474\n",
      "Epoch 1359/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.3493\n",
      "Epoch 1360/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3501\n",
      "Epoch 1361/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3482\n",
      "Epoch 1362/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3483\n",
      "Epoch 1363/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3472\n",
      "Epoch 1364/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.3476\n",
      "Epoch 1365/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3473\n",
      "Epoch 1366/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.3468\n",
      "Epoch 1367/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3454\n",
      "Epoch 1368/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.3487\n",
      "Epoch 1369/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3465\n",
      "Epoch 1370/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3459\n",
      "Epoch 1371/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3482\n",
      "Epoch 1372/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3463\n",
      "Epoch 1373/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.3500\n",
      "Epoch 1374/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3486\n",
      "Epoch 1375/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3467\n",
      "Epoch 1376/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3475\n",
      "Epoch 1377/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3494\n",
      "Epoch 1378/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3503\n",
      "Epoch 1379/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3475\n",
      "Epoch 1380/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3476\n",
      "Epoch 1381/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3490\n",
      "Epoch 1382/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3467\n",
      "Epoch 1383/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3472\n",
      "Epoch 1384/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3473\n",
      "Epoch 1385/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3475\n",
      "Epoch 1386/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3477\n",
      "Epoch 1387/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3468\n",
      "Epoch 1388/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3484\n",
      "Epoch 1389/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3483\n",
      "Epoch 1390/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3483\n",
      "Epoch 1391/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3474\n",
      "Epoch 1392/1500\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3492\n",
      "Epoch 1393/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3495\n",
      "Epoch 1394/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3479\n",
      "Epoch 1395/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3480\n",
      "Epoch 1396/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3492\n",
      "Epoch 1397/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3478\n",
      "Epoch 1398/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3476\n",
      "Epoch 1399/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3481\n",
      "Epoch 1400/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3510\n",
      "Epoch 1401/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.3477\n",
      "Epoch 1402/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3481\n",
      "Epoch 1403/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3471\n",
      "Epoch 1404/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3472\n",
      "Epoch 1405/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3483\n",
      "Epoch 1406/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3496\n",
      "Epoch 1407/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3467\n",
      "Epoch 1408/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3488\n",
      "Epoch 1409/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3493\n",
      "Epoch 1410/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3486\n",
      "Epoch 1411/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3481\n",
      "Epoch 1412/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3483\n",
      "Epoch 1413/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3472\n",
      "Epoch 1414/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3478\n",
      "Epoch 1415/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3487\n",
      "Epoch 1416/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.3480\n",
      "Epoch 1417/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3481\n",
      "Epoch 1418/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3462\n",
      "Epoch 1419/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3474\n",
      "Epoch 1420/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.3470\n",
      "Epoch 1421/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3470\n",
      "Epoch 1422/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3473\n",
      "Epoch 1423/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3466\n",
      "Epoch 1424/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3485\n",
      "Epoch 1425/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3485\n",
      "Epoch 1426/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3467\n",
      "Epoch 1427/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3488\n",
      "Epoch 1428/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3482\n",
      "Epoch 1429/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3474\n",
      "Epoch 1430/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3482\n",
      "Epoch 1431/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3470\n",
      "Epoch 1432/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3480\n",
      "Epoch 1433/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3512\n",
      "Epoch 1434/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3477\n",
      "Epoch 1435/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3462\n",
      "Epoch 1436/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3481\n",
      "Epoch 1437/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3481\n",
      "Epoch 1438/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3477\n",
      "Epoch 1439/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3489\n",
      "Epoch 1440/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3465\n",
      "Epoch 1441/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3472\n",
      "Epoch 1442/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3489\n",
      "Epoch 1443/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3481\n",
      "Epoch 1444/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3465\n",
      "Epoch 1445/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3488\n",
      "Epoch 1446/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3491\n",
      "Epoch 1447/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3480\n",
      "Epoch 1448/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.3474\n",
      "Epoch 1449/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3488\n",
      "Epoch 1450/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.3482\n",
      "Epoch 1451/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3473\n",
      "Epoch 1452/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3475\n",
      "Epoch 1453/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3494\n",
      "Epoch 1454/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3481\n",
      "Epoch 1455/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3482\n",
      "Epoch 1456/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.3475\n",
      "Epoch 1457/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.257 - 0s 2ms/step - loss: 0.3819 - val_loss: 0.3500\n",
      "Epoch 1458/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3482\n",
      "Epoch 1459/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.3464\n",
      "Epoch 1460/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3818 - val_loss: 0.3497\n",
      "Epoch 1461/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.3469\n",
      "Epoch 1462/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3491\n",
      "Epoch 1463/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3489\n",
      "Epoch 1464/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3498\n",
      "Epoch 1465/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.3488\n",
      "Epoch 1466/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.3483\n",
      "Epoch 1467/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.3484\n",
      "Epoch 1468/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3489\n",
      "Epoch 1469/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3474\n",
      "Epoch 1470/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3484\n",
      "Epoch 1471/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3482\n",
      "Epoch 1472/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.3469\n",
      "Epoch 1473/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3479\n",
      "Epoch 1474/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3492\n",
      "Epoch 1475/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3504\n",
      "Epoch 1476/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.3484\n",
      "Epoch 1477/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3476\n",
      "Epoch 1478/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3486\n",
      "Epoch 1479/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3501\n",
      "Epoch 1480/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3469\n",
      "Epoch 1481/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3483\n",
      "Epoch 1482/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3483\n",
      "Epoch 1483/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3465\n",
      "Epoch 1484/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.3459\n",
      "Epoch 1485/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3496\n",
      "Epoch 1486/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3488\n",
      "Epoch 1487/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3501\n",
      "Epoch 1488/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3473\n",
      "Epoch 1489/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3494\n",
      "Epoch 1490/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3469\n",
      "Epoch 1491/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.3490\n",
      "Epoch 1492/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3478\n",
      "Epoch 1493/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.3467\n",
      "Epoch 1494/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.3489\n",
      "Epoch 1495/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.3475\n",
      "Epoch 1496/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3477\n",
      "Epoch 1497/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.3478\n",
      "Epoch 1498/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3458\n",
      "Epoch 1499/1500\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.379 - 0s 2ms/step - loss: 0.3818 - val_loss: 0.3480\n",
      "Epoch 1500/1500\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3817 - val_loss: 0.3476\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Capa_de_Entrada (Dense)      (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "Capa_Oculta (Dense)          (None, 20)                60        \n",
      "_________________________________________________________________\n",
      "Capa_de_Salida (Dense)       (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 87\n",
      "Trainable params: 87\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=1500 , batch_size=32, verbose=1, validation_split=0.2)\n",
    "model.summary()\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NKCzuHaJ-vdY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTOB1JMv-zBo"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbMH6mymr5yi"
   },
   "source": [
    "Comenzamos a entrenar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ylLw9emyqgf"
   },
   "source": [
    "Evaluamos el error del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E35LdZ29sAvh",
    "outputId": "342b33e6-7a1d-40de-806f-93b2e88e1210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 1ms/step - loss: 14.9326\n",
      "14.93262767791748\n",
      "['loss']\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X, Y))\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P25DKnAZyxka"
   },
   "source": [
    "Imprimimos la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CQ5S6KdKvn-S",
    "outputId": "e3640664-194e-4421-b7f0-ad71f533923e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de predicciones = (517,) \n",
      "\n",
      "[[281  33]\n",
      " [ 42 161]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report  \n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "predict_label = predictions.reshape(-1).round()\n",
    "\n",
    "print('Cantidad de predicciones = {} \\n'.format(predict_label.shape))\n",
    "\n",
    "cf_matrix = confusion_matrix(Y_test, predict_label)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnGvbcFmy3rD"
   },
   "source": [
    "Graficamos la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "YPqEspU7xfYo",
    "outputId": "eb92aa98-8e54-49b6-9958-fdfc106257f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "OgI4jyv-yKYN",
    "outputId": "7a01fc83-197e-4f3b-c340-f22f5166f3b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUPJfS4xy69Y"
   },
   "source": [
    "# Creamos el reporte del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fUnSMXuyP5c",
    "outputId": "ad145e16-25bf-42f7-f2a5-806e60c9db82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       314\n",
      "           1       0.83      0.79      0.81       203\n",
      "\n",
      "    accuracy                           0.85       517\n",
      "   macro avg       0.85      0.84      0.85       517\n",
      "weighted avg       0.85      0.85      0.85       517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(Y_test, predict_label)  \n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jHXUjy8oya-l"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 2 but received input with shape [None, 1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-b091a8a4ab00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpredict_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3139\u001b[0m           expand_composites=True)\n\u001b[0;32m   3140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3141\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3142\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    D:\\Anaconda\\envs\\Inteligencia_Artificial\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 2 but received input with shape [None, 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "from sklearn.metrics import accuracy_score\n",
    "predictions = model.predict(Y_test)\n",
    "predict_label = predictions.reshape(-1).round()\n",
    "\n",
    "\n",
    "exactitud=accuracy_score(labels_test, predict_label)*100\n",
    "print('Exactitud del modelo: ',exactitud,' %')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rhOwdTH-0mr"
   },
   "source": [
    "Prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QtZbtIrozYWV",
    "outputId": "6d79fe2d-f27c-4ec8-ca86-bcd6e5f19f8e"
   },
   "outputs": [],
   "source": [
    "X_new = pd.DataFrame({'Primer.Par': [24], 'Segundo.Par': [36]})\n",
    "model.predict(X_new)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Prediccion _Redes_Neuronales.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

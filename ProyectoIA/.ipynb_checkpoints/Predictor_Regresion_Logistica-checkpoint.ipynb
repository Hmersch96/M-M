{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hollow-metadata",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d26e102fd168>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model, model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv(\"Resumido.csv\")\n",
    "\n",
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['Aprobo'] == True, 'Aprobo'] = '1'\n",
    "#df.loc[df['Aprobo'] == False, 'Aprobo'] = '0'\n",
    "\n",
    "df['Aprobo' ] =df['Aprobado'].replace(['N','S'],['0','1'])\n",
    "df['Derecho a Recuperatorio' ] =df['Derecho a Recuperatorio'].replace([False,True],['0','1'])\n",
    "df['Derecho a Final' ] =df['Derecho a Final'].replace([False,True],['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-advisory",
   "metadata": {},
   "source": [
    "<h1>Modelo #1</h1>\n",
    "Para el primer modelo a implementar, analizaremos si pasa la materia al conseguir firma. Los factores que se deben tener en cuenta para saber si pasa o no la materia solo con la firma son: La firma(Firma), que es la suma de los parciales y el taller; y finalmente su puntaje de taller (Taller), porque si no cumple con el puntaje minimo de taller (taller>=6) el alumno recursa directamente. Para este modelo predictivo, emplearemos la libreria sklearn y el modelo de regresion lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero cargamos en un vector X1 todos los datos que tenemos del dataset sobre el primer y segundo parcial, como tambien el taller de cada alumno\n",
    "X1=df[['Firma','Taller']]\n",
    "X1=np.array(X1)\n",
    "#Como solo buscamos saber si es que paso o no (no su nota final), en el vector Y1 se carga la columna \"Aprobo\"\n",
    "y1=df[['Aprobo']]\n",
    "y1=np.array(y1)\n",
    "y1=np.ravel(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui importamos las herramientas necesarias para utilizar una parte de los datos para el entrenamiento\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.4,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui se importan las librerias necesarias para crear y entrenar el modelo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui se declara al modelo a utilizar\n",
    "logreg1 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui se entrena al modelo con las vvariables de entrenamiento\n",
    "logreg1.fit(X1_train,y1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-trick",
   "metadata": {},
   "source": [
    "Una vez entrenado el modelo, se realizan predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred=logreg1.predict(X1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-train",
   "metadata": {},
   "source": [
    "Luego de realizar las predicciones, es necesario verificar el rendimiento de la prediccion. Para ello, es necesario utilizar la matriz de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este comando sirve para importar las funciones que permiten crear la matriz de confusion\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz1=confusion_matrix(y1_test,y1_pred)\n",
    "display('Matriz de Confusion:')\n",
    "print(matriz1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora calculamos la exactitud del modelo, para ello, se importa la siguiente libreria\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "exactitud1=accuracy_score(y1_test,y1_pred)*100\n",
    "print('Exactitud del modelo: ',exactitud1,' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-variable",
   "metadata": {},
   "source": [
    "Luego de haber terminado con este modelo, podemos implementar otros modelos con variables de entrada diferentes para asi seleccionar el modelo predictivo mas eficaz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-wheat",
   "metadata": {},
   "source": [
    "<h1>Modelo #2</h1>\n",
    "Para el segundo modelo a realizar, se tendra en cuenta el puntaje del primer parcial (1P), del segundo parcial (2P) y finalmente del taller (Taller) para determinar si es que el alumno pasa o no. Como en el primer modelo se explico detalladamente cada paso, para este modelo se omitiran algunas descripciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo #2\n",
    "X2=df[['1P','2P','Taller']]\n",
    "X2=np.array(X2)\n",
    "#Como solo buscamos saber si es que paso o no (no su nota final), en el vector Y1 se carga la columna \"Aprobo\"\n",
    "y2=df[['Aprobo']]\n",
    "y2=np.array(y2)\n",
    "y2=np.ravel(y2)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.6,random_state=101)\n",
    "\n",
    "logreg2 = LogisticRegression()\n",
    "logreg2.fit(X2_train,y2_train)\\\n",
    "\n",
    "y2_pred=logreg2.predict(X2_test)\n",
    "\n",
    "matriz2=confusion_matrix(y2_test,y2_pred)\n",
    "display('Matriz de Confusion:')\n",
    "print(matriz2)\n",
    "\n",
    "exactitud2=accuracy_score(y2_test,y2_pred)*100\n",
    "print('Exactitud del modelo: ',exactitud2,' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-domain",
   "metadata": {},
   "source": [
    "Como se puede apreciar, la exactitud del segundo modelo es mejor que la del primer modelo, eso indica que el rendimiento en los parciales en conjunto con el taller nos permite obtener una prediccion mas exacta en contraste a tomar directamente la firma del alumno y el taller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-security",
   "metadata": {},
   "source": [
    "<h1>Modelo #3</h1>\n",
    "Ahora se crea un nuevo modelo nuevo en donde solo se tendra en cuenta el rendimiento en los parciales para determinar si el alumno pasa o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo #3\n",
    "X3=df[['1P','2P']]\n",
    "X3=np.array(X3)\n",
    "#Como solo buscamos saber si es que paso o no (no su nota final), en el vector Y1 se carga la columna \"Aprobo\"\n",
    "y3=df[['Aprobo']]\n",
    "y3=np.array(y3)\n",
    "y3=np.ravel(y3)\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.6,random_state=101)\n",
    "\n",
    "logreg3 = LogisticRegression()\n",
    "logreg3.fit(X3_train,y3_train)\\\n",
    "\n",
    "y3_pred=logreg3.predict(X3_test)\n",
    "\n",
    "matriz3=confusion_matrix(y3_test,y3_pred)\n",
    "display('Matriz de Confusion:')\n",
    "print(matriz3)\n",
    "\n",
    "exactitud3=accuracy_score(y3_test,y3_pred)*100\n",
    "print('Exactitud del modelo: ',exactitud3,' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-tokyo",
   "metadata": {},
   "source": [
    "Como se puede apreciar, el rendimiento en el taller nos permitio obtener una mayor exactitud en los otros modelos, por ende, es un factor clave para determinar si el alumno pasa o no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-debate",
   "metadata": {},
   "source": [
    "<h1>Modelo #4</h1>\n",
    "Como se demostro que los datos del taller influyen en la prediccion que el alumno pase, se empleara un dataset que contiene exclusivamente los datos alumnos que tengan puntaje en su taller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui se crea el nuevo dataframe a utilizar, y se lo edita para que el procesamiento de sus datos ea mas sencillo\n",
    "dft = pd.read_csv(\"ResumidoTaller.csv\")\n",
    "\n",
    "del dft['Unnamed: 0']\n",
    "dft['Aprobo' ] =dft['Aprobado'].replace(['N','S'],['0','1'])\n",
    "dft['Derecho a Recuperatorio' ] =dft['Derecho a Recuperatorio'].replace([False,True],['0','1'])\n",
    "dft['Derecho a Final' ] =dft['Derecho a Final'].replace([False,True],['0','1'])\n",
    "\n",
    "display(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo #4\n",
    "X4=dft[['1P','2P','Taller']]\n",
    "X4=np.array(X4)\n",
    "#Como solo buscamos saber si es que paso o no (no su nota final), en el vector Y1 se carga la columna \"Aprobo\"\n",
    "y4=dft[['Aprobo']]\n",
    "y4=np.array(y4)\n",
    "y4=np.ravel(y4)\n",
    "\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.6,random_state=101)\n",
    "\n",
    "logreg4 = LogisticRegression()\n",
    "logreg4.fit(X4_train,y4_train)\\\n",
    "\n",
    "y4_pred=logreg4.predict(X4_test)\n",
    "\n",
    "matriz4=confusion_matrix(y4_test,y4_pred)\n",
    "display('Matriz de Confusion:')\n",
    "print(matriz4)\n",
    "\n",
    "exactitud4=accuracy_score(y4_test,y4_pred)*100\n",
    "print('Exactitud del modelo: ',exactitud4,' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-macintosh",
   "metadata": {},
   "source": [
    "Como se puede apreciar, al trabajar unicamente con los alumnos que tenian puntaje de taller, la exactitud del modelo incremento significativamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-lending",
   "metadata": {},
   "source": [
    "<h1>Modelo #5</h1>\n",
    "Como todos los alumnos con puntaje de taller son del 2019, se realizara una modelo que incluya a todos los alumnos de ese anho para comprobar si es posible aumentar la exactitud en la prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui se crea el nuevo dataframe a utilizar, y se lo edita para que el procesamiento de sus datos ea mas sencillo\n",
    "df019 = pd.read_csv(\"Resumido2019.csv\")\n",
    "\n",
    "del df019['Unnamed: 0']\n",
    "df019['Aprobo' ] =df019['Aprobado'].replace(['N','S'],['0','1'])\n",
    "df019['Derecho a Recuperatorio' ] =df019['Derecho a Recuperatorio'].replace([False,True],['0','1'])\n",
    "df019['Derecho a Final' ] =df019['Derecho a Final'].replace([False,True],['0','1'])\n",
    "\n",
    "display(df019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo #5\n",
    "X5=df019[['1P','2P','Taller']]\n",
    "X5=np.array(X5)\n",
    "#Como solo buscamos saber si es que paso o no (no su nota final), en el vector Y1 se carga la columna \"Aprobo\"\n",
    "y5=df019[['Aprobo']]\n",
    "y5=np.array(y5)\n",
    "y5=np.ravel(y5)\n",
    "\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X5, y5, test_size=0.6,random_state=101)\n",
    "\n",
    "logreg5 = LogisticRegression()\n",
    "logreg5.fit(X5_train,y5_train)\\\n",
    "\n",
    "y5_pred=logreg5.predict(X5_test)\n",
    "\n",
    "matriz5=confusion_matrix(y5_test,y5_pred)\n",
    "display('Matriz de Confusion:')\n",
    "print(matriz5)\n",
    "\n",
    "exactitud5=accuracy_score(y5_test,y5_pred)*100\n",
    "print('Exactitud del modelo: ',exactitud5,' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-mauritius",
   "metadata": {},
   "source": [
    "Al anhadir alumnos que no cumplen con el requisito de taller en el modelo, la exactitud del mismo disminuyo. Por ende, es necesario que se instroduzdan los datos de taller para mejorar la exactitud en la prediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-warrior",
   "metadata": {},
   "source": [
    "<h1>Conclusion</h1>\n",
    "Debido a su mayor exactitud y a lo sencillos que son los datos en la entrada, se selecciona el Modelo #4\n",
    "como el mejor modelo predictivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-screw",
   "metadata": {},
   "source": [
    "<h1>Graficos</h1>\n",
    "Para poder apreciar los resultados obtenidos, se pueden implementar librerias cuya finalidad es realizar graficos. La libreria 'seaborn' es una de ellas. Con esta libreria, se realizara el grafico de la regresion logistica como tambien el de la matriz de confusion del modelo mas eficaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(matriz4, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos=[X4_test,y4_pred]\n",
    "sns.lmplot(x=\"firma\", y=\"Aprobo\",data='Aprobo',logistic=True, y_jitter=.03);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-tucson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-start",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
